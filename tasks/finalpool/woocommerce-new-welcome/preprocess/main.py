#!/usr/bin/env python3
"""
WooCommerce New Welcome Task - Preprocess Setup
è®¾ç½®åˆå§‹å·¥ä½œç¯å¢ƒï¼šæ¸…ç©ºé‚®ç®±ã€è®¾ç½®WooCommerceè®¢å•æ•°æ®ã€å‡†å¤‡BigQueryç¯å¢ƒ
"""
import os
import sys
import json
import time
from argparse import ArgumentParser
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List

# Add parent directory to import token configuration
current_dir = os.path.dirname(os.path.abspath(__file__))
task_dir = os.path.dirname(current_dir)
project_root = os.path.dirname(os.path.dirname(os.path.dirname(task_dir)))
sys.path.insert(0, task_dir)  # For token_key_session
sys.path.insert(0, project_root)  # For utils


def clear_mailbox() -> Dict:
    """
    æ¸…ç©ºé‚®ç®± - ä½¿ç”¨é€šç”¨é‚®ç®±å·¥å…·æ¸…ç† INBOX, Sent, Drafts æ–‡ä»¶å¤¹

    Returns:
        æ¸…ç†ç»“æœå­—å…¸
    """
    print("ğŸ“§ å¼€å§‹æ¸…ç©ºé‚®ç®±...")

    try:
        # å¯¼å…¥é…ç½®
        from token_key_session import all_token_key_session

        # è¯»å–é‚®ä»¶é…ç½®æ–‡ä»¶
        try:
            with open(all_token_key_session.emails_config_file, 'r', encoding='utf-8') as f:
                email_config = json.load(f)
        except Exception as e:
            print(f"âŒ æ— æ³•è¯»å–é‚®ä»¶é…ç½®æ–‡ä»¶: {e}")
            return {
                "success": False,
                "error": f"æ— æ³•è¯»å–é‚®ä»¶é…ç½®æ–‡ä»¶: {e}",
                "timestamp": datetime.now().isoformat()
            }

        # å»¶è¿Ÿå¯¼å…¥é‚®ç®±æ¸…ç†æ¨¡å—
        try:
            from utils.app_specific.poste.ops import setup_clean_mailbox_environment
        except ImportError as e:
            print(f"âŒ æ— æ³•å¯¼å…¥é‚®ç®±æ¸…ç†æ¨¡å—: {e}")
            return {
                "success": False,
                "error": f"æ— æ³•å¯¼å…¥é‚®ç®±æ¸…ç†æ¨¡å—: {e}",
                "timestamp": datetime.now().isoformat()
            }

        # ä½¿ç”¨é€šç”¨é‚®ç®±æ¸…ç†å‡½æ•°
        result = setup_clean_mailbox_environment(email_config)

        print(f"ğŸ“Š é‚®ç®±æ¸…ç†ç»“æœ:")
        if result["success"]:
            print(f"âœ… æˆåŠŸæ¸…ç†æ–‡ä»¶å¤¹: {', '.join(result['cleared_folders'])}")
        else:
            print(f"âš ï¸ éƒ¨åˆ†æ–‡ä»¶å¤¹æ¸…ç†å¤±è´¥:")
            for error in result.get("errors", []):
                print(f"   - {error}")

        return {
            "success": result["success"],
            "cleared_folders": result.get("cleared_folders", []),
            "failed_folders": result.get("failed_folders", []),
            "errors": result.get("errors", []),
            "timestamp": datetime.now().isoformat()
        }

    except Exception as e:
        error_result = {
            "success": False,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }
        print(f"âŒ é‚®ç®±æ¸…ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        return error_result


def setup_woocommerce_orders() -> Dict:
    """
    è®¾ç½®WooCommerceè®¢å•æ•°æ®ï¼šæ¸…ç©ºç°æœ‰è®¢å•å¹¶æ·»åŠ æ–°çš„é¦–æ¬¡è´­ä¹°è®¢å•

    Returns:
        è®¾ç½®ç»“æœå­—å…¸
    """
    print("ğŸ›ï¸ è®¾ç½®WooCommerceè®¢å•æ•°æ®...")

    try:
        # å¯¼å…¥é…ç½®
        from token_key_session import all_token_key_session

        # å»¶è¿Ÿå¯¼å…¥WooCommerceæ¨¡å—
        try:
            from utils.app_specific.woocommerce import (
                OrderManager,
                create_new_welcome_orders
            )
        except ImportError as e:
            print(f"âŒ æ— æ³•å¯¼å…¥WooCommerceæ¨¡å—: {e}")
            return {
                "success": False,
                "error": f"æ— æ³•å¯¼å…¥WooCommerceæ¨¡å—: {e}",
                "timestamp": datetime.now().isoformat()
            }

        # åˆå§‹åŒ–è®¢å•ç®¡ç†å™¨
        order_manager = OrderManager(
            all_token_key_session.woocommerce_site_url,
            all_token_key_session.woocommerce_api_key,
            all_token_key_session.woocommerce_api_secret
        )

        # ç¬¬ä¸€æ­¥ï¼šæ¸…ç©ºç°æœ‰è®¢å•
        print("ğŸ—‘ï¸ æ¸…ç©ºç°æœ‰è®¢å•...")
        clear_result = order_manager.clear_all_orders(confirm=True)

        if not clear_result['success']:
            error_msg = clear_result.get('error', 'æœªçŸ¥é”™è¯¯')
            print(f"âŒ æ¸…ç©ºè®¢å•å¤±è´¥: {error_msg}")
            return {
                "success": False,
                "error": f"æ¸…ç©ºè®¢å•å¤±è´¥: {error_msg}",
                "deleted_count": clear_result.get('deleted_count', 0)
            }

        deleted_count = clear_result.get('deleted_count', 0)
        print(f"âœ… æˆåŠŸåˆ é™¤ {deleted_count} ä¸ªç°æœ‰è®¢å•")

        # ç¬¬äºŒæ­¥ï¼šç”Ÿæˆæ–°è®¢å•æ•°æ®
        print("ğŸ“¦ ç”Ÿæˆæ–°è®¢å•æ•°æ®...")
        all_orders, first_time_orders = create_new_welcome_orders()

        # ç¬¬ä¸‰æ­¥ï¼šä¸Šä¼ æ–°è®¢å•åˆ°WooCommerce
        print("ğŸ“¤ ä¸Šä¼ æ–°è®¢å•åˆ°WooCommerce...")
        upload_result = order_manager.upload_orders(
            all_orders,
            virtual_product_id=1,
            batch_delay=0.8
        )

        if not upload_result['success']:
            error_msg = upload_result.get('error', 'æœªçŸ¥é”™è¯¯')
            print(f"âŒ ä¸Šä¼ è®¢å•å¤±è´¥: {error_msg}")
            return {
                "success": False,
                "error": f"ä¸Šä¼ è®¢å•å¤±è´¥: {error_msg}",
                "deleted_count": deleted_count,
                "generated_orders": len(all_orders)
            }

        successful_orders = upload_result.get('successful_orders', 0)
        failed_orders = upload_result.get('failed_orders', 0)

        print(f"ğŸ“Š è®¢å•è®¾ç½®ç»“æœ:")
        print(f"   åˆ é™¤æ—§è®¢å•: {deleted_count} ä¸ª")
        print(f"   ç”Ÿæˆæ–°è®¢å•: {len(all_orders)} ä¸ª")
        print(f"   æˆåŠŸä¸Šä¼ : {successful_orders} ä¸ª")
        print(f"   å¤±è´¥ä¸Šä¼ : {failed_orders} ä¸ª")
        print(f"   é¦–æ¬¡è´­ä¹°å®¢æˆ·: {len(first_time_orders)} ä¸ª")

        # ä¿å­˜è®¢å•æ•°æ®åˆ°æ–‡ä»¶ä¾›è¯„ä¼°ä½¿ç”¨
        current_dir = Path(__file__).parent
        orders_file = current_dir / "generated_orders.json"
        with open(orders_file, 'w', encoding='utf-8') as f:
            json.dump({
                "all_orders": all_orders,
                "first_time_orders": first_time_orders
            }, f, ensure_ascii=False, indent=2)

        print(f"ğŸ“„ è®¢å•æ•°æ®å·²ä¿å­˜åˆ°: {orders_file}")

        return {
            "success": failed_orders == 0,
            "deleted_count": deleted_count,
            "generated_orders": len(all_orders),
            "successful_uploads": successful_orders,
            "failed_uploads": failed_orders,
            "first_time_customers": len(first_time_orders),
            "orders_file": str(orders_file)
        }

    except Exception as e:
        error_msg = f"WooCommerceè®¢å•è®¾ç½®è¿‡ç¨‹ä¸­å‡ºé”™: {e}"
        print(f"âŒ {error_msg}")
        return {
            "success": False,
            "error": error_msg
        }


def main():
    """ä¸»é¢„å¤„ç†å‡½æ•°"""

    parser = ArgumentParser(description="Preprocess script - Set up the initial environment for the WooCommerce new welcome task")
    parser.add_argument("--agent_workspace", required=False, help="Agentå·¥ä½œç©ºé—´è·¯å¾„")
    parser.add_argument("--credentials_file", default="configs/gcp-service_account.keys.json", help="BigQueryå‡­è¯æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--launch_time", required=False, help="Launch time")
    args = parser.parse_args()

    print("=" * 80)
    print("WooCommerce New Welcome Task - Preprocessing")
    print("=" * 80)

    results = []

    try:
        # ç¬¬ä¸€æ­¥ï¼šæ¸…ç©ºé‚®ç®±
        print("\n" + "="*60)
        print("Step 1: Clear Mailbox")
        print("="*60)

        mailbox_result = clear_mailbox()
        results.append(("Mailbox Cleanup", mailbox_result["success"], mailbox_result))

        if mailbox_result["success"]:
            print("âœ… é‚®ç®±æ¸…ç†æˆåŠŸ")
        else:
            print("âš ï¸ é‚®ç®±æ¸…ç†éƒ¨åˆ†å¤±è´¥ï¼Œä½†ç»§ç»­åç»­æ“ä½œ...")

        # ç­‰å¾…é‚®ç®±æ“ä½œå®Œæˆ
        time.sleep(2)

        # ç¬¬äºŒæ­¥ï¼šè®¾ç½®WooCommerceè®¢å•
        print("\n" + "="*60)
        print("Step 2: Setup WooCommerce Orders")
        print("="*60)

        woocommerce_result = setup_woocommerce_orders()
        results.append(("WooCommerce Setup", woocommerce_result["success"], woocommerce_result))

        if woocommerce_result["success"]:
            print("âœ… WooCommerceè®¢å•è®¾ç½®æˆåŠŸ")
        else:
            print("âŒ WooCommerceè®¢å•è®¾ç½®å¤±è´¥")

        # ç¬¬ä¸‰æ­¥ï¼šè®¾ç½®BigQueryç¯å¢ƒ
        print("\n" + "="*60)
        print("Step 3: Setup BigQuery Environment")
        print("="*60)

        # è®¾ç½®BigQueryè·¯å¾„å’Œæ•°æ®
        credentials_path = Path(args.credentials_file)
        if not credentials_path.is_absolute():
            credentials_path = Path.cwd() / credentials_path

        if credentials_path.exists():
            # è¯»å–å®¢æˆ·æ•°æ®
            current_dir = Path(__file__).parent
            json_path = current_dir / "customers_data.json"
            if json_path.exists():
                json_data = read_json_data(str(json_path))

                project_id = get_project_id_from_key(str(credentials_path))
                if project_id:
                    try:
                        client, dataset_id = setup_bigquery_resources(str(credentials_path), project_id, json_data)
                        results.append(("BigQuery Setup", True, {"dataset_id": dataset_id}))
                        print("âœ… BigQueryç¯å¢ƒè®¾ç½®æˆåŠŸ")
                    except Exception as e:
                        results.append(("BigQuery Setup", False, {"error": str(e)}))
                        print(f"âŒ BigQueryè®¾ç½®å¤±è´¥: {e}")
                else:
                    results.append(("BigQuery Setup", False, {"error": "æ— æ³•è·å–é¡¹ç›®ID"}))
                    print("âŒ æ— æ³•ä»å‡­è¯æ–‡ä»¶è·å–é¡¹ç›®ID")
            else:
                results.append(("BigQuery Setup", False, {"error": "å®¢æˆ·æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨"}))
                print("âŒ å®¢æˆ·æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        else:
            results.append(("BigQuery Setup", False, {"error": "å‡­è¯æ–‡ä»¶ä¸å­˜åœ¨"}))
            print("âŒ BigQueryå‡­è¯æ–‡ä»¶ä¸å­˜åœ¨")

        # æ±‡æ€»ç»“æœ
        print("\n" + "="*80)
        print("PREPROCESSING SUMMARY")
        print("="*80)

        success_count = sum(1 for _, success, _ in results if success)
        total_count = len(results)

        for step_name, success, details in results:
            status = "âœ… PASSED" if success else "âŒ FAILED"
            print(f"{step_name}: {status}")
            if not success and "error" in details:
                print(f"  Error: {details['error']}")

        overall_success = success_count == total_count
        print(f"\nOverall: {success_count}/{total_count} steps completed successfully")

        if overall_success:
            print("\nğŸ‰ æ‰€æœ‰é¢„å¤„ç†æ­¥éª¤å®Œæˆï¼ä»»åŠ¡ç¯å¢ƒå·²å°±ç»ª")
            return True
        else:
            print("\nâš ï¸ é¢„å¤„ç†éƒ¨åˆ†å®Œæˆï¼Œè¯·æ£€æŸ¥å¤±è´¥çš„æ­¥éª¤")
            return False

    except Exception as e:
        print(f"âŒ é¢„å¤„ç†å¤±è´¥: {e}")
        return False


# ä»¥ä¸‹æ˜¯åŸæœ‰çš„BigQueryç›¸å…³å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰

import logging
from google.cloud import bigquery
from google.oauth2 import service_account
from google.api_core.exceptions import Conflict, GoogleAPICallError, NotFound

# Enable verbose logging for debugging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)


def read_json_data(json_path: str):
    """ä»JSONæ–‡ä»¶è¯»å–å®¢æˆ·æ•°æ®"""
    print(f"ğŸ“– æ­£åœ¨è¯»å–JSONæ•°æ®æ–‡ä»¶: {json_path}")
    
    if not Path(json_path).exists():
        print(f"âŒ JSONæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
        return []
    
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            customers = json.load(f)
        
        # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
        processed_customers = []
        for customer in customers:
            processed_customer = {
                'id': customer.get('id'),
                'woocommerce_id': customer.get('woocommerce_id'),
                'email': customer.get('email'),
                'first_name': customer.get('first_name'),
                'last_name': customer.get('last_name'),
                'phone': customer.get('phone', ''),
                'date_created': customer.get('date_created'),
                'first_order_date': customer.get('first_order_date'),
                'welcome_email_sent': customer.get('welcome_email_sent', False),
                'welcome_email_date': customer.get('welcome_email_date'),
                'sync_date': customer.get('sync_date'),
                'metadata': customer.get('metadata', '{}')
            }
            processed_customers.append(processed_customer)
        
        print(f"âœ… æˆåŠŸè¯»å– {len(processed_customers)} æ¡å®¢æˆ·è®°å½•")
        return processed_customers
        
    except (json.JSONDecodeError, IOError) as e:
        print(f"âŒ è¯»å–JSONæ•°æ®æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return []

def wait_for_table_availability(client: bigquery.Client, table_id: str, max_wait_time: int = 30):
    """
    Wait for BigQuery table to become fully available after creation
    """
    import time

    print(f"â³ ç­‰å¾…è¡¨ {table_id} å®Œå…¨å¯ç”¨...")
    start_time = time.time()

    while time.time() - start_time < max_wait_time:
        try:
            # Try to get the table - this verifies it's fully available
            table = client.get_table(table_id)
            # Also try a simple query to make sure it's really ready
            query = f"SELECT COUNT(*) as row_count FROM `{table_id}` LIMIT 1"
            query_job = client.query(query)
            list(query_job.result())
            print(f"âœ… è¡¨ {table_id} å·²å®Œå…¨å¯ç”¨")
            return table
        except Exception as e:
            print(f"   è¡¨ä»ä¸å¯ç”¨: {e}")
            time.sleep(2)

    print(f"âš ï¸  ç­‰å¾…è¡¨å¯ç”¨è¶…æ—¶ ({max_wait_time}ç§’)")
    return None

def wait_for_dataset_deletion(client: bigquery.Client, dataset_id: str, max_wait_time: int = 30):
    """
    Wait for BigQuery dataset deletion to complete
    """
    import time

    print(f"â³ ç­‰å¾…æ•°æ®é›† {dataset_id} å®Œå…¨åˆ é™¤...")
    start_time = time.time()

    while time.time() - start_time < max_wait_time:
        try:
            # Try to get the dataset - if it still exists, deletion isn't complete
            client.get_dataset(dataset_id)
            print(f"   æ•°æ®é›†ä»ç„¶å­˜åœ¨ï¼Œç»§ç»­ç­‰å¾…...")
            time.sleep(2)
        except NotFound:
            # Dataset is truly gone
            print(f"âœ… æ•°æ®é›† {dataset_id} å·²å®Œå…¨åˆ é™¤")
            return True
        except Exception as e:
            print(f"âš ï¸  æ£€æŸ¥æ•°æ®é›†çŠ¶æ€æ—¶å‡ºé”™: {e}")
            time.sleep(2)

    print(f"âš ï¸  ç­‰å¾…è¶…æ—¶ ({max_wait_time}ç§’)ï¼Œç»§ç»­æ‰§è¡Œ...")
    return False

def setup_or_clear_dataset(client: bigquery.Client, project_id: str):
    """
    Setup or clear existing woocommerce_crm dataset
    - If dataset exists: clear all table contents but keep the dataset and tables
    - If dataset doesn't exist: create it (tables will be created later)
    """
    dataset_id = f"{project_id}.woocommerce_crm"
    print(f"ğŸ§¹ æ£€æŸ¥å¹¶è®¾ç½®æ•°æ®é›†: {dataset_id}")

    try:
        # Try to get dataset info to see if it exists
        try:
            dataset = client.get_dataset(dataset_id)
            print(f"â„¹ï¸  æ‰¾åˆ°ç°æœ‰æ•°æ®é›†: {dataset_id}")

            # List all tables in the dataset
            tables = list(client.list_tables(dataset_id))
            if tables:
                print(f"â„¹ï¸  æ•°æ®é›†åŒ…å« {len(tables)} ä¸ªè¡¨:")
                for table in tables:
                    print(f"   - {table.table_id}")

                # Clear contents of all tables instead of deleting them
                for table in tables:
                    table_id = f"{dataset_id}.{table.table_id}"
                    print(f"ğŸ—‘ï¸  æ¸…ç©ºè¡¨ {table.table_id} çš„å†…å®¹...")

                    # Use DELETE query to clear table contents
                    delete_query = f"DELETE FROM `{table_id}` WHERE true"
                    query_job = client.query(delete_query)
                    query_job.result()  # Wait for completion

                    print(f"âœ… å·²æ¸…ç©ºè¡¨ {table.table_id}")
            else:
                print(f"â„¹ï¸  æ•°æ®é›†ä¸ºç©ºï¼Œæ— éœ€æ¸…ç†")

        except NotFound:
            print(f"â„¹ï¸  æ•°æ®é›† {dataset_id} ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ•°æ®é›†")
            # Create the dataset since it doesn't exist
            dataset = bigquery.Dataset(dataset_id)
            dataset.location = "US"
            dataset.description = "WooCommerce CRM dataset for customer management and welcome emails"
            client.create_dataset(dataset, timeout=30)
            print(f"âœ… æ•°æ®é›† '{dataset.dataset_id}' å·²æˆåŠŸåˆ›å»º")

    except Exception as e:
        print(f"âŒ æ•°æ®é›†è®¾ç½®è¿‡ç¨‹å‡ºé”™: {e}")
        logger.exception("Dataset setup failed")
        raise

def cleanup_existing_dataset(client: bigquery.Client, project_id: str):
    """
    Clean up existing woocommerce_crm dataset if it exists
    """
    dataset_id = f"{project_id}.woocommerce_crm"
    print(f"ğŸ§¹ æ£€æŸ¥å¹¶æ¸…ç†ç°æœ‰æ•°æ®é›†: {dataset_id}")
    
    try:
        # First try to get dataset info to see if it exists
        try:
            dataset = client.get_dataset(dataset_id)
            print(f"â„¹ï¸  æ‰¾åˆ°ç°æœ‰æ•°æ®é›†: {dataset_id}")
            
            # List all tables in the dataset
            tables = list(client.list_tables(dataset_id))
            if tables:
                print(f"â„¹ï¸  æ•°æ®é›†åŒ…å« {len(tables)} ä¸ªè¡¨:")
                for table in tables:
                    print(f"   - {table.table_id}")
        except NotFound:
            print(f"â„¹ï¸  æ•°æ®é›† {dataset_id} ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†")
            return
        
        # Delete dataset with all contents
        print(f"ğŸ—‘ï¸  åˆ é™¤æ•°æ®é›†åŠå…¶æ‰€æœ‰å†…å®¹...")
        client.delete_dataset(
            dataset_id, 
            delete_contents=True, 
            not_found_ok=True
        )
        print(f"âœ… å·²æˆåŠŸæ¸…ç†æ•°æ®é›† '{dataset_id}' åŠå…¶æ‰€æœ‰å†…å®¹")
        
        # Wait for deletion to propagate - BigQuery deletion is asynchronous
        wait_for_dataset_deletion(client, dataset_id)
        
    except NotFound:
        print(f"â„¹ï¸  æ•°æ®é›† {dataset_id} ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†")
    except Exception as e:
        print(f"âŒ æ•°æ®é›†æ¸…ç†è¿‡ç¨‹å‡ºé”™: {e}")
        logger.exception("Dataset cleanup failed")
        raise

def setup_bigquery_resources(credentials_path: str, project_id: str, json_data: list):
    """
    Setup BigQuery dataset and tables for WooCommerce CRM, then populate with JSON data
    """
    print("=" * 60)
    print("ğŸ›ï¸ å¼€å§‹è®¾ç½® BigQuery WooCommerce CRM èµ„æº")
    print("=" * 60)
    
    try:
        print(f"ğŸ”— æ­£åœ¨ä½¿ç”¨å‡­è¯ '{credentials_path}' è¿æ¥åˆ°é¡¹ç›® '{project_id}'...")
        
        # Use the newer authentication method
        credentials = service_account.Credentials.from_service_account_file(credentials_path)
        client = bigquery.Client(credentials=credentials, project=project_id)
        
        print("âœ… è¿æ¥æˆåŠŸï¼")
        
        # Test connection by listing datasets
        print("ğŸ” æµ‹è¯•è¿æ¥ - åˆ—å‡ºç°æœ‰æ•°æ®é›†...")
        try:
            datasets = list(client.list_datasets())
            print(f"â„¹ï¸  é¡¹ç›®ä¸­ç°æœ‰ {len(datasets)} ä¸ªæ•°æ®é›†")
            for dataset in datasets:
                print(f"   - {dataset.dataset_id}")
        except Exception as e:
            print(f"âš ï¸  åˆ—å‡ºæ•°æ®é›†æ—¶å‡ºé”™: {e}")

        # Setup or clear existing dataset (don't delete it)
        setup_or_clear_dataset(client, project_id)

        # Create dataset if needed (handled in setup_or_clear_dataset)
        dataset_id = f"{project_id}.woocommerce_crm"

        # Create customers table (or skip if exists)
        table_id_customers = f"{dataset_id}.customers"
        print(f"ğŸ—‚ï¸  æ£€æŸ¥å¹¶åˆ›å»ºè¡¨: {table_id_customers}")
        schema_customers = [
            bigquery.SchemaField("id", "INTEGER", mode="REQUIRED"),
            bigquery.SchemaField("woocommerce_id", "INTEGER", mode="REQUIRED"),
            bigquery.SchemaField("email", "STRING", mode="REQUIRED"),
            bigquery.SchemaField("first_name", "STRING", mode="NULLABLE"),
            bigquery.SchemaField("last_name", "STRING", mode="NULLABLE"),
            bigquery.SchemaField("phone", "STRING", mode="NULLABLE"),
            bigquery.SchemaField("date_created", "TIMESTAMP", mode="NULLABLE"),
            bigquery.SchemaField("first_order_date", "TIMESTAMP", mode="NULLABLE"),
            bigquery.SchemaField("welcome_email_sent", "BOOLEAN", mode="NULLABLE"),
            bigquery.SchemaField("welcome_email_date", "TIMESTAMP", mode="NULLABLE"),
            bigquery.SchemaField("sync_date", "TIMESTAMP", mode="NULLABLE"),
            bigquery.SchemaField("metadata", "STRING", mode="NULLABLE"),
        ]
        table_customers = bigquery.Table(table_id_customers, schema=schema_customers)
        try:
            client.create_table(table_customers)
            print(f"âœ… è¡¨ '{table_id_customers}' å·²æˆåŠŸåˆ›å»ºã€‚")
        except Conflict:
            print(f"â„¹ï¸  è¡¨ '{table_id_customers}' å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»ºã€‚")
        except Exception as e:
            print(f"âŒ åˆ›å»ºè¡¨ '{table_id_customers}' å¤±è´¥: {e}")
            raise

        # Get table reference for data insertion
        print(f"ğŸ“‹ è·å–è¡¨å¼•ç”¨...")
        table_ref = client.get_table(table_id_customers)
        print(f"âœ… è·å–åˆ°è¡¨å¼•ç”¨: {table_ref.table_id}")

        # Insert JSON data into BigQuery
        if json_data:
            print(f"ğŸ’¾ æ’å…¥ {len(json_data)} æ¡å®¢æˆ·æ•°æ®åˆ° BigQuery...")
            try:
                # Use the table reference we already verified is available
                print(f"âœ… ä½¿ç”¨å·²éªŒè¯çš„è¡¨å¼•ç”¨: {table_ref.table_id}")

                # **ALTERNATIVE APPROACH: Use load_table_from_json instead of insert_rows_json**
                # This bypasses potential caching issues with streaming inserts
                print("ğŸ”„ å°è¯•ä½¿ç”¨æ‰¹é‡åŠ è½½è€Œéæµå¼æ’å…¥...")

                # Convert JSON data for BigQuery
                bigquery_rows = []
                for customer in json_data:
                    # Convert datetime strings to proper format
                    def convert_timestamp(timestamp_str):
                        if not timestamp_str:
                            return None
                        try:
                            # Try to parse various timestamp formats
                            if 'T' in timestamp_str:
                                return datetime.fromisoformat(timestamp_str.replace('Z', '+00:00')).isoformat()
                            else:
                                return datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S').isoformat()
                        except ValueError:
                            return None

                    bigquery_row = {
                        "id": customer['id'],
                        "woocommerce_id": customer['woocommerce_id'],
                        "email": customer['email'],
                        "first_name": customer['first_name'],
                        "last_name": customer['last_name'],
                        "phone": customer['phone'],
                        "date_created": convert_timestamp(customer['date_created']),
                        "first_order_date": convert_timestamp(customer['first_order_date']),
                        "welcome_email_sent": customer['welcome_email_sent'],
                        "welcome_email_date": convert_timestamp(customer['welcome_email_date']),
                        "sync_date": convert_timestamp(customer['sync_date']),
                        "metadata": customer['metadata']
                    }
                    bigquery_rows.append(bigquery_row)

                # Use load_table_from_json instead of insert_rows_json
                job_config = bigquery.LoadJobConfig(
                    write_disposition="WRITE_TRUNCATE",  # Overwrite existing data
                    source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,
                )

                load_job = client.load_table_from_json(
                    bigquery_rows, table_ref, job_config=job_config
                )

                print(f"   å¼€å§‹æ‰¹é‡åŠ è½½ä½œä¸š: {load_job.job_id}")
                load_job.result()  # Wait for the job to complete

                print(f"ğŸ‰ æˆåŠŸæ‰¹é‡åŠ è½½ {len(bigquery_rows)} æ¡å®¢æˆ·æ•°æ®åˆ° customers è¡¨")
                
                # Verify data insertion
                print("ğŸ” éªŒè¯æ•°æ®æ’å…¥...")
                query = f"""
                SELECT COUNT(*) as total_rows, 
                       COUNT(DISTINCT woocommerce_id) as unique_customers,
                       COUNT(CASE WHEN welcome_email_sent = true THEN 1 END) as emails_sent
                FROM `{table_id_customers}`
                """
                query_job = client.query(query)
                results = list(query_job.result())
                if results:
                    result = results[0]
                    print(f"âœ… éªŒè¯æˆåŠŸ: {result.total_rows} è¡Œæ•°æ®, {result.unique_customers} ä¸ªç‹¬ç‰¹å®¢æˆ·, {result.emails_sent} å°é‚®ä»¶å·²å‘é€")
                else:
                    print("âš ï¸  éªŒè¯æŸ¥è¯¢æœªè¿”å›ç»“æœ")
                    
            except Exception as e:
                print(f"âŒ æ’å…¥æ•°æ®æ—¶å‡ºç°é”™è¯¯: {e}")
                logger.exception("Data insertion failed")
                raise Exception(f"æ’å…¥æ•°æ®å¤±è´¥: {e}")
        else:
            print("âš ï¸  æ²¡æœ‰JSONæ•°æ®å¯æ’å…¥")

        return client, dataset_id

    except GoogleAPICallError as e:
        print(f"âŒ Google Cloud API è°ƒç”¨å¤±è´¥: {e}")
        logger.exception("Google Cloud API call failed")
        raise
    except Exception as e:
        print(f"âŒ è®¾ç½®è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        logger.exception("Setup process failed")
        raise

def get_project_id_from_key(credentials_path: str) -> str | None:
    """ä»æœåŠ¡è´¦å·å¯†é’¥æ–‡ä»¶ä¸­è¯»å–é¡¹ç›®ID"""
    try:
        with open(credentials_path, 'r') as f:
            data = json.load(f)
            return data.get("project_id")
    except (FileNotFoundError, json.JSONDecodeError):
        return None

if __name__ == "__main__":
    main()