import asyncio
from argparse import ArgumentParser
from pathlib import Path
from utils.general.helper import run_command, get_module_path
import os
import json
import logging
from datetime import datetime, date, timedelta
from google.cloud import bigquery
from google.oauth2 import service_account
from google.api_core.exceptions import Conflict, GoogleAPICallError, NotFound

# Enable verbose logging for debugging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

def read_json_data(json_path: str):
    """ä»JSONæ–‡ä»¶è¯»å–å®¢æˆ·æ•°æ®"""
    print(f"ğŸ“– æ­£åœ¨è¯»å–JSONæ•°æ®æ–‡ä»¶: {json_path}")
    
    if not Path(json_path).exists():
        print(f"âŒ JSONæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
        return []
    
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            customers = json.load(f)
        
        # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
        processed_customers = []
        for customer in customers:
            processed_customer = {
                'id': customer.get('id'),
                'woocommerce_id': customer.get('woocommerce_id'),
                'email': customer.get('email'),
                'first_name': customer.get('first_name'),
                'last_name': customer.get('last_name'),
                'phone': customer.get('phone', ''),
                'date_created': customer.get('date_created'),
                'first_order_date': customer.get('first_order_date'),
                'welcome_email_sent': customer.get('welcome_email_sent', False),
                'welcome_email_date': customer.get('welcome_email_date'),
                'sync_date': customer.get('sync_date'),
                'metadata': customer.get('metadata', '{}')
            }
            processed_customers.append(processed_customer)
        
        print(f"âœ… æˆåŠŸè¯»å– {len(processed_customers)} æ¡å®¢æˆ·è®°å½•")
        return processed_customers
        
    except (json.JSONDecodeError, IOError) as e:
        print(f"âŒ è¯»å–JSONæ•°æ®æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return []

def cleanup_existing_dataset(client: bigquery.Client, project_id: str):
    """
    Clean up existing woocommerce_crm dataset if it exists
    """
    dataset_id = f"{project_id}.woocommerce_crm"
    print(f"ğŸ§¹ æ£€æŸ¥å¹¶æ¸…ç†ç°æœ‰æ•°æ®é›†: {dataset_id}")
    
    try:
        # First try to get dataset info to see if it exists
        try:
            dataset = client.get_dataset(dataset_id)
            print(f"â„¹ï¸  æ‰¾åˆ°ç°æœ‰æ•°æ®é›†: {dataset_id}")
            
            # List all tables in the dataset
            tables = list(client.list_tables(dataset_id))
            if tables:
                print(f"â„¹ï¸  æ•°æ®é›†åŒ…å« {len(tables)} ä¸ªè¡¨:")
                for table in tables:
                    print(f"   - {table.table_id}")
        except NotFound:
            print(f"â„¹ï¸  æ•°æ®é›† {dataset_id} ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†")
            return
        
        # Delete dataset with all contents
        print(f"ğŸ—‘ï¸  åˆ é™¤æ•°æ®é›†åŠå…¶æ‰€æœ‰å†…å®¹...")
        client.delete_dataset(
            dataset_id, 
            delete_contents=True, 
            not_found_ok=True
        )
        print(f"âœ… å·²æˆåŠŸæ¸…ç†æ•°æ®é›† '{dataset_id}' åŠå…¶æ‰€æœ‰å†…å®¹")
        
        # Wait a moment for deletion to propagate
        import time
        time.sleep(2)
        
    except NotFound:
        print(f"â„¹ï¸  æ•°æ®é›† {dataset_id} ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†")
    except Exception as e:
        print(f"âŒ æ•°æ®é›†æ¸…ç†è¿‡ç¨‹å‡ºé”™: {e}")
        logger.exception("Dataset cleanup failed")
        raise

def setup_bigquery_resources(credentials_path: str, project_id: str, json_data: list):
    """
    Setup BigQuery dataset and tables for WooCommerce CRM, then populate with JSON data
    """
    print("=" * 60)
    print("ğŸ›ï¸ å¼€å§‹è®¾ç½® BigQuery WooCommerce CRM èµ„æº")
    print("=" * 60)
    
    try:
        print(f"ğŸ”— æ­£åœ¨ä½¿ç”¨å‡­è¯ '{credentials_path}' è¿æ¥åˆ°é¡¹ç›® '{project_id}'...")
        
        # Use the newer authentication method
        credentials = service_account.Credentials.from_service_account_file(credentials_path)
        client = bigquery.Client(credentials=credentials, project=project_id)
        
        print("âœ… è¿æ¥æˆåŠŸï¼")
        
        # Test connection by listing datasets
        print("ğŸ” æµ‹è¯•è¿æ¥ - åˆ—å‡ºç°æœ‰æ•°æ®é›†...")
        try:
            datasets = list(client.list_datasets())
            print(f"â„¹ï¸  é¡¹ç›®ä¸­ç°æœ‰ {len(datasets)} ä¸ªæ•°æ®é›†")
            for dataset in datasets:
                print(f"   - {dataset.dataset_id}")
        except Exception as e:
            print(f"âš ï¸  åˆ—å‡ºæ•°æ®é›†æ—¶å‡ºé”™: {e}")

        # Clean up existing dataset first
        cleanup_existing_dataset(client, project_id)

        # Create dataset
        dataset_id = f"{project_id}.woocommerce_crm"
        print(f"ğŸ“Š åˆ›å»ºæ•°æ®é›†: {dataset_id}")
        try:
            dataset = bigquery.Dataset(dataset_id)
            dataset.location = "US"
            dataset.description = "WooCommerce CRM dataset for customer management and welcome emails"
            client.create_dataset(dataset, timeout=30)
            print(f"âœ… æ•°æ®é›† '{dataset.dataset_id}' å·²æˆåŠŸåˆ›å»ºã€‚")
        except Conflict:
            print(f"â„¹ï¸  æ•°æ®é›† '{dataset_id}' å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»ºã€‚")
        except Exception as e:
            print(f"âŒ åˆ›å»ºæ•°æ®é›†å¤±è´¥: {e}")
            logger.exception("Dataset creation failed")
            raise

        # Create customers table
        table_id_customers = f"{dataset_id}.customers"
        print(f"ğŸ—‚ï¸  åˆ›å»ºè¡¨: {table_id_customers}")
        schema_customers = [
            bigquery.SchemaField("id", "INTEGER", mode="REQUIRED"),
            bigquery.SchemaField("woocommerce_id", "INTEGER", mode="REQUIRED"),
            bigquery.SchemaField("email", "STRING", mode="REQUIRED"),
            bigquery.SchemaField("first_name", "STRING", mode="NULLABLE"),
            bigquery.SchemaField("last_name", "STRING", mode="NULLABLE"),
            bigquery.SchemaField("phone", "STRING", mode="NULLABLE"),
            bigquery.SchemaField("date_created", "TIMESTAMP", mode="NULLABLE"),
            bigquery.SchemaField("first_order_date", "TIMESTAMP", mode="NULLABLE"),
            bigquery.SchemaField("welcome_email_sent", "BOOLEAN", mode="NULLABLE"),
            bigquery.SchemaField("welcome_email_date", "TIMESTAMP", mode="NULLABLE"),
            bigquery.SchemaField("sync_date", "TIMESTAMP", mode="NULLABLE"),
            bigquery.SchemaField("metadata", "STRING", mode="NULLABLE"),
        ]
        table_customers = bigquery.Table(table_id_customers, schema=schema_customers)
        try:
            client.create_table(table_customers)
            print(f"âœ… è¡¨ '{table_id_customers}' å·²æˆåŠŸåˆ›å»ºã€‚")
        except Conflict:
            print(f"â„¹ï¸  è¡¨ '{table_id_customers}' å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»ºã€‚")
        except Exception as e:
            print(f"âŒ åˆ›å»ºè¡¨ '{table_id_customers}' å¤±è´¥: {e}")
            raise

        # Insert JSON data into BigQuery
        if json_data:
            print(f"ğŸ’¾ æ’å…¥ {len(json_data)} æ¡å®¢æˆ·æ•°æ®åˆ° BigQuery...")
            try:
                table_ref = client.get_table(table_id_customers)
                print(f"âœ… è·å–åˆ°è¡¨å¼•ç”¨: {table_ref.table_id}")
                
                # Convert JSON data for BigQuery
                bigquery_rows = []
                for customer in json_data:
                    # Convert datetime strings to proper format
                    def convert_timestamp(timestamp_str):
                        if not timestamp_str:
                            return None
                        try:
                            # Try to parse various timestamp formats
                            if 'T' in timestamp_str:
                                return datetime.fromisoformat(timestamp_str.replace('Z', '+00:00')).isoformat()
                            else:
                                return datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S').isoformat()
                        except ValueError:
                            return None
                    
                    bigquery_row = {
                        "id": customer['id'],
                        "woocommerce_id": customer['woocommerce_id'],
                        "email": customer['email'],
                        "first_name": customer['first_name'],
                        "last_name": customer['last_name'],
                        "phone": customer['phone'],
                        "date_created": convert_timestamp(customer['date_created']),
                        "first_order_date": convert_timestamp(customer['first_order_date']),
                        "welcome_email_sent": customer['welcome_email_sent'],
                        "welcome_email_date": convert_timestamp(customer['welcome_email_date']),
                        "sync_date": convert_timestamp(customer['sync_date']),
                        "metadata": customer['metadata']
                    }
                    bigquery_rows.append(bigquery_row)
                
                # Insert data in batches
                batch_size = 100
                total_inserted = 0
                for i in range(0, len(bigquery_rows), batch_size):
                    batch = bigquery_rows[i:i + batch_size]
                    print(f"   æ’å…¥æ‰¹æ¬¡ {i//batch_size + 1}: {len(batch)} æ¡è®°å½•...")
                    
                    errors = client.insert_rows_json(table_ref, batch)
                    if errors:
                        print(f"âŒ æ‰¹æ¬¡ {i//batch_size + 1} æ’å…¥é”™è¯¯: {errors}")
                        for error in errors:
                            logger.error(f"Insert error: {error}")
                        raise Exception(f"æ‰¹æ¬¡æ’å…¥å¤±è´¥: {errors}")
                    else:
                        total_inserted += len(batch)
                        print(f"   âœ… æ‰¹æ¬¡ {i//batch_size + 1} æˆåŠŸæ’å…¥ {len(batch)} æ¡è®°å½•")
                
                print(f"ğŸ‰ æˆåŠŸæ’å…¥æ€»è®¡ {total_inserted} æ¡å®¢æˆ·æ•°æ®åˆ° customers è¡¨")
                
                # Verify data insertion
                print("ğŸ” éªŒè¯æ•°æ®æ’å…¥...")
                query = f"""
                SELECT COUNT(*) as total_rows, 
                       COUNT(DISTINCT woocommerce_id) as unique_customers,
                       COUNT(CASE WHEN welcome_email_sent = true THEN 1 END) as emails_sent
                FROM `{table_id_customers}`
                """
                query_job = client.query(query)
                results = list(query_job.result())
                if results:
                    result = results[0]
                    print(f"âœ… éªŒè¯æˆåŠŸ: {result.total_rows} è¡Œæ•°æ®, {result.unique_customers} ä¸ªç‹¬ç‰¹å®¢æˆ·, {result.emails_sent} å°é‚®ä»¶å·²å‘é€")
                else:
                    print("âš ï¸  éªŒè¯æŸ¥è¯¢æœªè¿”å›ç»“æœ")
                    
            except Exception as e:
                print(f"âŒ æ’å…¥æ•°æ®æ—¶å‡ºç°é”™è¯¯: {e}")
                logger.exception("Data insertion failed")
                raise Exception(f"æ’å…¥æ•°æ®å¤±è´¥: {e}")
        else:
            print("âš ï¸  æ²¡æœ‰JSONæ•°æ®å¯æ’å…¥")

        return client, dataset_id

    except GoogleAPICallError as e:
        print(f"âŒ Google Cloud API è°ƒç”¨å¤±è´¥: {e}")
        logger.exception("Google Cloud API call failed")
        raise
    except Exception as e:
        print(f"âŒ è®¾ç½®è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        logger.exception("Setup process failed")
        raise

def get_project_id_from_key(credentials_path: str) -> str | None:
    """ä»æœåŠ¡è´¦å·å¯†é’¥æ–‡ä»¶ä¸­è¯»å–é¡¹ç›®ID"""
    try:
        with open(credentials_path, 'r') as f:
            data = json.load(f)
            return data.get("project_id")
    except (FileNotFoundError, json.JSONDecodeError):
        return None

if __name__ == "__main__":
    parser = ArgumentParser()
    parser.add_argument("--agent_workspace", required=False)
    parser.add_argument("--credentials_file", default="configs/gcp-service_account.keys.json")
    parser.add_argument("--launch_time", required=False, help="Launch time (can contain spaces)")
    args = parser.parse_args()

    print("ğŸ›ï¸ å¼€å§‹è®¾ç½® BigQuery WooCommerce CRM èµ„æº...")
    print("=" * 60)
    
    # Get credentials file path
    credentials_path = Path(args.credentials_file)
    
    # Make sure the path is absolute
    if not credentials_path.is_absolute():
        credentials_path = Path.cwd() / credentials_path
    
    if not credentials_path.exists():
        print(f"âŒ é”™è¯¯ï¼šå‡­è¯æ–‡ä»¶ä¸å­˜åœ¨: {credentials_path}")
        print("è¯·ç¡®ä¿æœåŠ¡è´¦å·å¯†é’¥æ–‡ä»¶å­˜åœ¨äºæŒ‡å®šè·¯å¾„")
        exit(1)
    else:
        print(f"âœ… æ‰¾åˆ°å‡­è¯æ–‡ä»¶: {credentials_path}")
    
    # Get JSON data file path
    json_path = Path(os.path.join(os.path.dirname(__file__), "customers_data.json"))
    if not json_path.is_absolute():
        json_path = Path.cwd() / json_path
        
    print(f"ğŸ“– JSONæ•°æ®æ–‡ä»¶è·¯å¾„: {json_path}")
    
    # Read JSON data
    json_data = read_json_data(str(json_path))
    
    project_id = get_project_id_from_key(str(credentials_path))
    
    if project_id:
        print(f"ğŸ†” ä»å‡­è¯æ–‡ä»¶ä¸­æˆåŠŸè¯»å–é¡¹ç›®ID: {project_id}")
        try:
            client, dataset_id = setup_bigquery_resources(str(credentials_path), project_id, json_data)
            print("\n" + "=" * 60)
            print("ğŸ‰ æ‰€æœ‰ BigQuery èµ„æºè®¾ç½®å®Œæ¯•ï¼")
            print("ğŸ“Š å·²å°†JSONæ•°æ®è¿ç§»åˆ°BigQuery")
            print("ğŸ¯ ä»»åŠ¡ï¼šä»£ç†éœ€è¦åŒæ­¥æ–°å®¢æˆ·æ•°æ®å¹¶å‘é€æ¬¢è¿é‚®ä»¶")
            print("=" * 60)
        except Exception as e:
            print(f"\nâŒ è®¾ç½®å¤±è´¥: {e}")
            exit(1)
    else:
        print(f"âŒ æ— æ³•ä»å‡­è¯æ–‡ä»¶ä¸­è¯»å–é¡¹ç›®IDã€‚")
        exit(1)