#!/usr/bin/env python3
"""
å¯ç–‘äº¤æ˜“è°ƒæŸ¥æ•°æ®æŸ¥è¯¢è„šæœ¬

æ¨¡æ‹Ÿå®æ—¶äº¤æ˜“ç›‘æ§ç³»ç»Ÿä¸­æ£€æµ‹åˆ°å¯ç–‘äº¤æ˜“åçš„æ•°æ®æ”¶é›†å’Œè°ƒæŸ¥æµç¨‹ã€‚
æ ¹æ®å¯ç–‘äº¤æ˜“IDæŸ¥è¯¢æ‰€æœ‰ç›¸å…³æ•°æ®ï¼Œå¹¶ç”Ÿæˆå®Œæ•´çš„è°ƒæŸ¥æ¡£æ¡ˆã€‚
"""

import json
import os
import argparse
import pandas as pd
import csv
from typing import Dict, List, Any, Optional
from datetime import datetime

class SuspiciousTransactionInvestigator:
    """å¯ç–‘äº¤æ˜“è°ƒæŸ¥å™¨ - è´Ÿè´£æ”¶é›†å’Œåˆ†æä¸å¯ç–‘äº¤æ˜“ç›¸å…³çš„æ‰€æœ‰æ•°æ®"""
    
    def __init__(self, dataset_file: str = "live_transactions_dataset.json"):
        """
        åˆå§‹åŒ–è°ƒæŸ¥å™¨
        
        Args:
            dataset_file: æ•°æ®é›†æ–‡ä»¶è·¯å¾„
        """
        self.dataset_file = dataset_file
        self.dataset = self._load_dataset()
        
    def _load_dataset(self) -> Dict[str, Any]:
        """åŠ è½½æ•°æ®é›†"""
        if not os.path.exists(self.dataset_file):
            raise FileNotFoundError(f"æ•°æ®é›†æ–‡ä»¶æœªæ‰¾åˆ°: {self.dataset_file}")
            
        with open(self.dataset_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _load_from_jsonl_tables(self, tables_dir: str) -> Dict[str, Any]:
        """ä»JSONLè¡¨æ–‡ä»¶åŠ è½½æ•°æ®é›†"""
        dataset = {"tables": {}}
        
        # åŠ è½½æ‰€æœ‰JSONLè¡¨æ–‡ä»¶
        for filename in os.listdir(tables_dir):
            if filename.endswith('.jsonl'):
                table_name = filename[:-6]  # å»æ‰.jsonlåç¼€
                table_data = []
                
                with open(os.path.join(tables_dir, filename), 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            table_data.append(json.loads(line))
                
                dataset["tables"][table_name] = table_data
        
        # åŠ è½½å…ƒæ•°æ®
        metadata_file = os.path.join(tables_dir, "metadata.json")
        if os.path.exists(metadata_file):
            with open(metadata_file, 'r', encoding='utf-8') as f:
                dataset["metadata"] = json.load(f)
        
        return dataset
    
    def _load_from_csv_tables(self, tables_dir: str) -> Dict[str, Any]:
        """ä»CSVè¡¨æ–‡ä»¶åŠ è½½æ•°æ®é›†"""
        dataset = {"tables": {}}
        
        # åŠ è½½æ‰€æœ‰CSVè¡¨æ–‡ä»¶
        for filename in os.listdir(tables_dir):
            if filename.endswith('.csv'):
                table_name = filename[:-4]  # å»æ‰.csvåç¼€
                file_path = os.path.join(tables_dir, filename)
                
                try:
                    # ä½¿ç”¨pandasè¯»å–CSV
                    df = pd.read_csv(file_path, encoding='utf-8')
                    
                    # å°†DataFrameè½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                    table_data = []
                    for _, row in df.iterrows():
                        record = {}
                        for col, value in row.items():
                            # å¤„ç†NaNå€¼
                            if pd.isna(value):
                                record[col] = None
                            elif isinstance(value, str) and value.startswith(('[', '{')):
                                # å°è¯•è§£æJSONå­—ç¬¦ä¸²
                                try:
                                    record[col] = json.loads(value)
                                except (json.JSONDecodeError, ValueError):
                                    record[col] = value
                            else:
                                record[col] = value
                        table_data.append(record)
                    
                    dataset["tables"][table_name] = table_data
                    print(f"  ğŸ“„ åŠ è½½ {table_name}: {len(table_data)} æ¡è®°å½•")
                    
                except Exception as e:
                    print(f"âŒ åŠ è½½CSVæ–‡ä»¶å¤±è´¥ {filename}: {str(e)}")
        
        # åŠ è½½å…ƒæ•°æ®
        metadata_file = os.path.join(tables_dir, "metadata.json")
        if os.path.exists(metadata_file):
            with open(metadata_file, 'r', encoding='utf-8') as f:
                dataset["metadata"] = json.load(f)
        
        return dataset
    
    def find_suspicious_transaction(self, transaction_id: str) -> Optional[Dict[str, Any]]:
        """æŸ¥æ‰¾å¯ç–‘äº¤æ˜“è®°å½•"""
        transactions = self.dataset["tables"]["live_transactions"]
        
        # å¤„ç†ä¸åŒçš„æ•°æ®æ ¼å¼
        if isinstance(transactions, dict):
            return transactions.get(transaction_id)
        elif isinstance(transactions, list):
            for tx in transactions:
                if tx.get("transaction_id") == transaction_id:
                    return tx
        
        return None
    
    def get_related_user_data(self, user_id: str) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·ç›¸å…³æ•°æ®"""
        users = self.dataset["tables"]["users"]
        
        # å¤„ç†ä¸åŒçš„æ•°æ®æ ¼å¼
        if isinstance(users, dict):
            user_data = users.get(user_id, {})
        else:
            user_data = next((u for u in users if u.get("user_id") == user_id), {})
        
        return user_data
    
    def get_related_account_data(self, account_id: str) -> Dict[str, Any]:
        """è·å–è´¦æˆ·ç›¸å…³æ•°æ®"""
        accounts = self.dataset["tables"]["accounts"]
        
        if isinstance(accounts, dict):
            return accounts.get(account_id, {})
        else:
            return next((a for a in accounts if a.get("account_id") == account_id), {})
    
    def get_related_merchant_data(self, merchant_id: str) -> Dict[str, Any]:
        """è·å–å•†æˆ·ç›¸å…³æ•°æ®"""
        merchants = self.dataset["tables"]["merchants"]
        
        if isinstance(merchants, dict):
            return merchants.get(merchant_id, {})
        else:
            return next((m for m in merchants if m.get("merchant_id") == merchant_id), {})
    
    def get_related_card_data(self, card_id: str) -> Dict[str, Any]:
        """è·å–é“¶è¡Œå¡ç›¸å…³æ•°æ®"""
        cards = self.dataset["tables"]["cards"]
        
        if isinstance(cards, dict):
            return cards.get(card_id, {})
        else:
            return next((c for c in cards if c.get("card_id") == card_id), {})
    
    def get_related_device_data(self, device_id: str) -> Dict[str, Any]:
        """è·å–è®¾å¤‡ç›¸å…³æ•°æ®"""
        devices = self.dataset["tables"]["devices"]
        
        if isinstance(devices, dict):
            return devices.get(device_id, {})
        else:
            return next((d for d in devices if d.get("device_id") == device_id), {})
    
    def get_location_data(self, location_id: str) -> Dict[str, Any]:
        """è·å–åœ°ç†ä½ç½®æ•°æ®"""
        locations = self.dataset["tables"]["locations"]
        
        if isinstance(locations, dict):
            return locations.get(location_id, {})
        else:
            return next((l for l in locations if l.get("location_id") == location_id), {})
    
    def get_related_transactions(self, user_id: str, exclude_transaction_id: str) -> List[Dict[str, Any]]:
        """è·å–ç”¨æˆ·çš„å…¶ä»–ç›¸å…³äº¤æ˜“"""
        transactions = self.dataset["tables"]["live_transactions"]
        related_txs = []
        
        if isinstance(transactions, dict):
            for tx_id, tx_data in transactions.items():
                if (tx_data.get("user_id") == user_id and 
                    tx_id != exclude_transaction_id):
                    related_txs.append(tx_data)
        else:
            for tx in transactions:
                if (tx.get("user_id") == user_id and 
                    tx.get("transaction_id") != exclude_transaction_id):
                    related_txs.append(tx)
        
        # æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        related_txs.sort(key=lambda x: x.get("timestamp", ""), reverse=True)
        return related_txs
    
    def get_risk_score_data(self, user_id: str) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·é£é™©è¯„åˆ†æ•°æ®"""
        risk_scores = self.dataset["tables"]["risk_scores"]
        
        if isinstance(risk_scores, dict):
            return risk_scores.get(user_id, {})
        else:
            return next((r for r in risk_scores if r.get("user_id") == user_id), {})
    
    def get_fraud_alerts(self, transaction_id: str) -> List[Dict[str, Any]]:
        """è·å–ç›¸å…³çš„æ¬ºè¯ˆå‘Šè­¦"""
        fraud_alerts = self.dataset["tables"]["fraud_alerts"]
        alerts = []
        
        if isinstance(fraud_alerts, dict):
            # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼ŒæŸ¥æ‰¾åŒ…å«è¯¥äº¤æ˜“IDçš„å‘Šè­¦
            for alert_data in fraud_alerts.values():
                if isinstance(alert_data, dict):
                    if alert_data.get("transaction_id") == transaction_id:
                        alerts.append(alert_data)
                elif isinstance(alert_data, list):
                    alerts.extend([a for a in alert_data if a.get("transaction_id") == transaction_id])
        else:
            # å¦‚æœæ˜¯åˆ—è¡¨æ ¼å¼
            alerts = [a for a in fraud_alerts if a.get("transaction_id") == transaction_id]
        
        return alerts
    
    def get_blacklist_matches(self, investigation_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ£€æŸ¥é»‘åå•åŒ¹é…"""
        blacklist = self.dataset["tables"]["blacklist"]
        matches = []
        
        # æå–éœ€è¦æ£€æŸ¥çš„å€¼
        check_values = {
            "user_email": investigation_data.get("user_data", {}).get("email"),
            "merchant_id": investigation_data.get("merchant_data", {}).get("merchant_id"),
            "ip_address": investigation_data.get("device_data", {}).get("ip_address"),
            "card_bin": investigation_data.get("card_data", {}).get("card_number_masked", "")[:6]
        }
        
        if isinstance(blacklist, dict):
            blacklist_items = blacklist.get("blacklisted_entities", [])
        else:
            blacklist_items = blacklist
        
        for item in blacklist_items:
            item_value = item.get("value", "")
            for check_key, check_value in check_values.items():
                if check_value and str(check_value).startswith(str(item_value)):
                    matches.append({
                        "matched_field": check_key,
                        "matched_value": check_value,
                        "blacklist_entry": item
                    })
        
        return matches
    
    def calculate_investigation_summary(self, investigation_data: Dict[str, Any]) -> Dict[str, Any]:
        """è®¡ç®—è°ƒæŸ¥æ€»ç»“"""
        transaction = investigation_data["transaction_data"]
        
        # é£é™©ç­‰çº§è¯„ä¼°
        risk_score = transaction.get("risk_score", 0)
        if risk_score >= 9.0:
            risk_level = "CRITICAL"
        elif risk_score >= 7.0:
            risk_level = "HIGH"
        elif risk_score >= 5.0:
            risk_level = "MEDIUM"
        else:
            risk_level = "LOW"
        
        # ç»Ÿè®¡ç›¸å…³äº¤æ˜“
        related_count = len(investigation_data.get("related_transactions", []))
        
        # ç»Ÿè®¡é£é™©æ ‡è¯†
        flags = transaction.get("flags", [])
        flag_count = len(flags)
        
        # æ£€æŸ¥è®¾å¤‡é£é™©
        device_data = investigation_data.get("device_data", {})
        device_risks = []
        if device_data.get("vpn_detected"):
            device_risks.append("VPN_DETECTED")
        if device_data.get("tor_detected"):
            device_risks.append("TOR_DETECTED")
        if device_data.get("proxy_detected"):
            device_risks.append("PROXY_DETECTED")
        
        # åœ°ç†é£é™©
        geo_data = transaction.get("geographic_data", {})
        geo_risk = geo_data.get("unusual_location", False)
        
        # å•†æˆ·é£é™©
        merchant_data = investigation_data.get("merchant_data", {})
        merchant_risk = merchant_data.get("risk_rating", "LOW")
        
        return {
            "investigation_id": f"INV_{transaction['transaction_id']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "risk_assessment": {
                "overall_risk_level": risk_level,
                "risk_score": risk_score,
                "total_risk_flags": flag_count,
                "device_risk_count": len(device_risks),
                "geographic_risk": geo_risk,
                "merchant_risk_level": merchant_risk
            },
            "transaction_pattern": {
                "related_transactions_count": related_count,
                "transaction_amount": transaction.get("amount", 0),
                "transaction_type": transaction.get("transaction_type", ""),
                "velocity_flags": len(transaction.get("velocity_checks", {}))
            },
            "blacklist_matches": len(investigation_data.get("blacklist_matches", [])),
            "fraud_alerts_count": len(investigation_data.get("fraud_alerts", [])),
            "investigation_priority": "URGENT" if risk_level == "CRITICAL" else "HIGH" if risk_level == "HIGH" else "NORMAL",
            "recommended_actions": self._get_recommended_actions(risk_level, investigation_data),
            "investigation_timestamp": datetime.now().isoformat(),
            "estimated_fraud_probability": transaction.get("ml_fraud_score", 0) / 100.0 if transaction.get("ml_fraud_score") else None
        }
    
    def _get_recommended_actions(self, risk_level: str, investigation_data: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ¨èçš„è°ƒæŸ¥è¡ŒåŠ¨"""
        actions = []
        
        if risk_level == "CRITICAL":
            actions.extend([
                "IMMEDIATE_ACCOUNT_FREEZE",
                "CONTACT_LAW_ENFORCEMENT",
                "REGULATORY_REPORTING_REQUIRED",
                "ENHANCED_DUE_DILIGENCE"
            ])
        elif risk_level == "HIGH":
            actions.extend([
                "ACCOUNT_MONITORING_ENHANCED",
                "MANUAL_REVIEW_REQUIRED",
                "CUSTOMER_CONTACT_VERIFICATION"
            ])
        
        # åŸºäºå…·ä½“é£é™©å› ç´ çš„è¡ŒåŠ¨
        device_data = investigation_data.get("device_data", {})
        if device_data.get("tor_detected") or device_data.get("vpn_detected"):
            actions.append("DEVICE_ANALYSIS_REQUIRED")
        
        if investigation_data.get("blacklist_matches"):
            actions.append("SANCTIONS_SCREENING_REVIEW")
        
        merchant_data = investigation_data.get("merchant_data", {})
        if merchant_data.get("license_status") == "SUSPENDED":
            actions.append("MERCHANT_RELATIONSHIP_REVIEW")
        
        return actions
    
    def investigate_transaction(self, transaction_id: str) -> Dict[str, Any]:
        """
        å®Œæ•´çš„å¯ç–‘äº¤æ˜“è°ƒæŸ¥æµç¨‹
        
        Args:
            transaction_id: å¯ç–‘äº¤æ˜“ID
            
        Returns:
            å®Œæ•´çš„è°ƒæŸ¥æ¡£æ¡ˆJSONå¯¹è±¡
        """
        print(f"ğŸ” å¼€å§‹è°ƒæŸ¥å¯ç–‘äº¤æ˜“: {transaction_id}")
        
        # 1. æŸ¥æ‰¾ä¸»è¦äº¤æ˜“è®°å½•
        transaction_data = self.find_suspicious_transaction(transaction_id)
        if not transaction_data:
            raise ValueError(f"æœªæ‰¾åˆ°äº¤æ˜“ID: {transaction_id}")
        
        print(f"âœ… æ‰¾åˆ°äº¤æ˜“è®°å½•ï¼Œé‡‘é¢: ${transaction_data.get('amount', 0):,.2f}")
        
        # 2. æ”¶é›†ç›¸å…³å®ä½“æ•°æ®
        user_id = transaction_data.get("user_id")
        account_id = transaction_data.get("account_id")
        merchant_id = transaction_data.get("merchant_id")
        card_id = transaction_data.get("card_id")
        device_id = transaction_data.get("device_id")
        location_id = transaction_data.get("location_id")
        
        print(f"ğŸ“Š æ”¶é›†ç›¸å…³æ•°æ®: ç”¨æˆ·({user_id}), å•†æˆ·({merchant_id}), è®¾å¤‡({device_id})")
        
        # 3. æ„å»ºå®Œæ•´çš„è°ƒæŸ¥æ¡£æ¡ˆ
        investigation_data = {
            # ä¸»è¦äº¤æ˜“æ•°æ®
            "transaction_data": transaction_data,
            
            # ç”¨æˆ·æ•°æ®
            "user_data": self.get_related_user_data(user_id) if user_id else {},
            
            # è´¦æˆ·æ•°æ®
            "account_data": self.get_related_account_data(account_id) if account_id else {},
            
            # å•†æˆ·æ•°æ®
            "merchant_data": self.get_related_merchant_data(merchant_id) if merchant_id else {},
            
            # é“¶è¡Œå¡æ•°æ®
            "card_data": self.get_related_card_data(card_id) if card_id else {},
            
            # è®¾å¤‡æ•°æ®
            "device_data": self.get_related_device_data(device_id) if device_id else {},
            
            # åœ°ç†ä½ç½®æ•°æ®
            "location_data": self.get_location_data(location_id) if location_id else {},
            
            # ç›¸å…³äº¤æ˜“è®°å½•ï¼ˆæœ€è¿‘30å¤©ï¼‰
            "related_transactions": self.get_related_transactions(user_id, transaction_id) if user_id else [],
            
            # é£é™©è¯„åˆ†å†å²
            "risk_score_data": self.get_risk_score_data(user_id) if user_id else {},
            
            # ç›¸å…³æ¬ºè¯ˆå‘Šè­¦
            "fraud_alerts": self.get_fraud_alerts(transaction_id),
        }
        
        # 4. é»‘åå•åŒ¹é…æ£€æŸ¥
        investigation_data["blacklist_matches"] = self.get_blacklist_matches(investigation_data)
        
        # 5. ç”Ÿæˆè°ƒæŸ¥æ€»ç»“
        investigation_data["investigation_summary"] = self.calculate_investigation_summary(investigation_data)
        
        print(f"âš ï¸  é£é™©ç­‰çº§: {investigation_data['investigation_summary']['risk_assessment']['overall_risk_level']}")
        print(f"ğŸš¨ æ¬ºè¯ˆæ¦‚ç‡: {investigation_data['investigation_summary'].get('estimated_fraud_probability', 'N/A')}")
        print(f"ğŸ“‹ æ¨èè¡ŒåŠ¨: {len(investigation_data['investigation_summary']['recommended_actions'])} é¡¹")
        
        return investigation_data
    
    def save_investigation_report(self, investigation_data: Dict[str, Any], output_file: str = None) -> str:
        """ä¿å­˜è°ƒæŸ¥æŠ¥å‘Š"""
        transaction_id = investigation_data["transaction_data"]["transaction_id"]
        
        if not output_file:
            output_file = f"{transaction_id}_investigation_report.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(investigation_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ è°ƒæŸ¥æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
        return output_file

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¯ç–‘äº¤æ˜“è°ƒæŸ¥å·¥å…·')
    parser.add_argument('--transaction-id', type=str, default='T8492XJ3', 
                       help='å¯ç–‘äº¤æ˜“ID (é»˜è®¤: T8492XJ3)')
    parser.add_argument('--dataset', type=str, default='live_transactions_dataset.json',
                       help='æ•°æ®é›†æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--tables-dir', type=str, 
                       help='JSONLè¡¨æ–‡ä»¶ç›®å½• (å¦‚æœä½¿ç”¨åˆ†ç¦»çš„è¡¨æ–‡ä»¶)')
    parser.add_argument('--csv-dir', type=str,
                       help='CSVè¡¨æ–‡ä»¶ç›®å½• (å¦‚æœä½¿ç”¨CSVæ ¼å¼çš„è¡¨æ–‡ä»¶)')
    parser.add_argument('--output', type=str,
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--show-summary', action='store_true',
                       help='æ˜¾ç¤ºè°ƒæŸ¥æ‘˜è¦')
    
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–è°ƒæŸ¥å™¨
        if args.csv_dir:
            print(f"ğŸ“ ä»CSVç›®å½•åŠ è½½æ•°æ®: {args.csv_dir}")
            investigator = SuspiciousTransactionInvestigator.__new__(SuspiciousTransactionInvestigator)
            investigator.dataset = investigator._load_from_csv_tables(args.csv_dir)
        elif args.tables_dir:
            print(f"ğŸ“ ä»JSONLç›®å½•åŠ è½½æ•°æ®: {args.tables_dir}")
            investigator = SuspiciousTransactionInvestigator.__new__(SuspiciousTransactionInvestigator)
            investigator.dataset = investigator._load_from_jsonl_tables(args.tables_dir)
        else:
            print(f"ğŸ“ ä»JSONæ–‡ä»¶åŠ è½½æ•°æ®: {args.dataset}")
            investigator = SuspiciousTransactionInvestigator(args.dataset)
        
        # æ‰§è¡Œè°ƒæŸ¥
        investigation_data = investigator.investigate_transaction(args.transaction_id)
        
        # æ˜¾ç¤ºæ‘˜è¦
        if args.show_summary:
            summary = investigation_data["investigation_summary"]
            print(f"\nğŸ“‹ è°ƒæŸ¥æ‘˜è¦:")
            print(f"  ğŸ†” è°ƒæŸ¥ID: {summary['investigation_id']}")
            print(f"  âš ï¸  é£é™©ç­‰çº§: {summary['risk_assessment']['overall_risk_level']}")
            print(f"  ğŸ“Š é£é™©è¯„åˆ†: {summary['risk_assessment']['risk_score']}/10")
            print(f"  ğŸ’° äº¤æ˜“é‡‘é¢: ${summary['transaction_pattern']['transaction_amount']:,.2f}")
            print(f"  ğŸ”— ç›¸å…³äº¤æ˜“: {summary['transaction_pattern']['related_transactions_count']} ç¬”")
            print(f"  ğŸš¨ æ¬ºè¯ˆå‘Šè­¦: {summary['fraud_alerts_count']} ä¸ª")
            print(f"  âš–ï¸ æ¨èä¼˜å…ˆçº§: {summary['investigation_priority']}")
            
            print(f"\nğŸ“ æ¨èè¡ŒåŠ¨:")
            for action in summary['recommended_actions']:
                print(f"    â€¢ {action}")
        
        # ä¿å­˜æŠ¥å‘Š
        output_file = investigator.save_investigation_report(investigation_data, args.output)
        
        print(f"\nâœ… è°ƒæŸ¥å®Œæˆï¼å®Œæ•´çš„è°ƒæŸ¥æ¡£æ¡ˆå·²ç”Ÿæˆã€‚")
        print(f"ğŸ“„ æ–‡ä»¶å¤§å°: {os.path.getsize(output_file) / 1024:.1f} KB")
        
        return investigation_data
        
    except Exception as e:
        print(f"âŒ è°ƒæŸ¥å¤±è´¥: {str(e)}")
        return None

if __name__ == "__main__":
    main() 