# ğŸ“Š Live Transactions CSVæ ¼å¼æŒ‡å—

## ğŸ¯ ä»€ä¹ˆæ˜¯CSVæ ¼å¼ï¼Ÿ

CSVå°±åƒExcelè¡¨æ ¼ï¼Œä½†æ›´ç®€å•ã€æ›´é€šç”¨ï¼š
- **C**omma **S**eparated **V**alues = ç”¨é€—å·åˆ†éš”çš„æ•°å€¼
- æ¯ä¸€è¡Œæ˜¯ä¸€æ¡è®°å½•ï¼Œæ¯ä¸€åˆ—æ˜¯ä¸€ä¸ªå­—æ®µ
- ç¬¬ä¸€è¡Œé€šå¸¸æ˜¯åˆ—åï¼ˆè¡¨å¤´ï¼‰
- å°±åƒé“¶è¡Œæµæ°´å•ï¼Œä¸€è¡Œä¸€ç¬”äº¤æ˜“

## ğŸ—ï¸ ç³»ç»Ÿæ”¹é€ è¯´æ˜

### åŸæ¥çš„JSONæ ¼å¼ VS ç°åœ¨çš„CSVæ ¼å¼

#### ğŸ“‹ JSONæ ¼å¼ï¼ˆåŸæ¥ï¼‰
```json
{
  "tables": {
    "live_transactions": [
      {
        "transaction_id": "T8492XJ3",
        "amount": 487392.85,
        "flags": ["LARGE_AMOUNT", "VPN_DETECTED"]
      }
    ]
  }
}
```

#### ğŸ“Š CSVæ ¼å¼ï¼ˆç°åœ¨ï¼‰
```csv
transaction_id,amount,flags
T8492XJ3,487392.85,"[""LARGE_AMOUNT"", ""VPN_DETECTED""]"
```

### ğŸ”„ æ”¹é€ å†…å®¹

1. **æ•°æ®ç”Ÿæˆè„šæœ¬ (construct_data.py)**
   - âœ… æ·»åŠ äº† `--export-csv` å‚æ•°
   - âœ… æ–°å¢ `export_to_csv_format()` æ–¹æ³•
   - âœ… è‡ªåŠ¨å¤„ç†å¤æ‚å­—æ®µï¼ˆæ•°ç»„ã€å¯¹è±¡è½¬JSONå­—ç¬¦ä¸²ï¼‰

2. **æŸ¥è¯¢è„šæœ¬ (query_suspicious_transaction.py)**
   - âœ… æ·»åŠ äº† `--csv-dir` å‚æ•°  
   - âœ… æ–°å¢ `_load_from_csv_tables()` æ–¹æ³•
   - âœ… è‡ªåŠ¨è§£æJSONå­—ç¬¦ä¸²å›åŸå§‹æ•°æ®

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### ç¬¬ä¸€æ­¥ï¼šç”ŸæˆCSVæ•°æ®
```bash
# åŸºç¡€ç‰ˆæœ¬
python construct_data.py --export-csv

# å¤§è§„æ¨¡ç‰ˆæœ¬ï¼ˆ10å€æ•°æ®ï¼‰
python construct_data.py --scale 10 --export-csv --output-dir big_csv

# å¤šä¸ªå¯ç–‘äº¤æ˜“
python construct_data.py --suspicious-count 5 --export-csv
```

### ç¬¬äºŒæ­¥ï¼šæŸ¥è¯¢åˆ†æ
```bash
# ä»CSVæ–‡ä»¶æŸ¥è¯¢å¯ç–‘äº¤æ˜“
python query_suspicious_transaction.py \
  --transaction-id T8492XJ3 \
  --csv-dir csv_tables \
  --show-summary
```

### ç¬¬ä¸‰æ­¥ï¼šæ•°æ®åˆ†æ
```python
import pandas as pd
import json

# è¯»å–äº¤æ˜“æ•°æ®
df = pd.read_csv('csv_tables/live_transactions.csv')

# è§£æJSONå­—æ®µ
df['flags_list'] = df['flags'].apply(json.loads)
df['velocity_data'] = df['velocity_checks'].apply(json.loads)

# åˆ†æé«˜é£é™©äº¤æ˜“
high_risk = df[df['risk_score'] >= 8.0]
print(f"é«˜é£é™©äº¤æ˜“: {len(high_risk)} ç¬”")
```

## ğŸ’¡ CSVæ ¼å¼çš„ä¼˜åŠ¿

### 1. ğŸ“Š **Excelç›´æ¥æ‰“å¼€**
```
åŒå‡» .csv æ–‡ä»¶ â†’ Excelè‡ªåŠ¨æ‰“å¼€ â†’ ç«‹å³åˆ†æ
```
- ä¸éœ€è¦ä»»ä½•é¢å¤–è½¯ä»¶
- æ”¯æŒæ•°æ®é€è§†è¡¨ã€å›¾è¡¨
- ä¸šåŠ¡äººå‘˜å¯ä»¥ç›´æ¥ä½¿ç”¨

### 2. ğŸ—„ï¸ **æ•°æ®åº“å‹å¥½**
```sql
-- MySQL
LOAD DATA INFILE 'live_transactions.csv' INTO TABLE transactions;

-- PostgreSQL  
COPY transactions FROM 'live_transactions.csv' WITH CSV HEADER;

-- SQLite
.import live_transactions.csv transactions
```

### 3. ğŸ **æ•°æ®ç§‘å­¦å·¥å…·æ”¯æŒ**
```python
# pandas
df = pd.read_csv('live_transactions.csv')

# Rè¯­è¨€
df <- read.csv('live_transactions.csv')

# Apache Spark
spark.read.csv('live_transactions.csv')
```

### 4. ğŸ’¾ **å­˜å‚¨æ•ˆç‡**
- CSVæ–‡ä»¶æ¯”JSONå° **76.5%**
- å‹ç¼©åä½“ç§¯æ›´å°
- ä¼ è¾“é€Ÿåº¦æ›´å¿«

## ğŸ” æ•°æ®æ¢ç´¢ç¤ºä¾‹

### é£é™©äº¤æ˜“åˆ†æ
```python
import pandas as pd
import matplotlib.pyplot as plt

# è¯»å–æ•°æ®
df = pd.read_csv('csv_tables/live_transactions.csv')

# æŒ‰é£é™©ç­‰çº§åˆ†ç»„
risk_analysis = df.groupby(pd.cut(df['risk_score'], bins=[0,3,6,8,10]))['amount'].agg(['count', 'sum'])

# å¯è§†åŒ–
risk_analysis['count'].plot(kind='bar', title='ä¸åŒé£é™©ç­‰çº§çš„äº¤æ˜“æ•°é‡')
plt.show()
```

### åœ°ç†åˆ†å¸ƒåˆ†æ
```python
# è¯»å–ä½ç½®æ•°æ®
locations = pd.read_csv('csv_tables/locations.csv')
transactions = pd.read_csv('csv_tables/live_transactions.csv')

# åˆå¹¶æ•°æ®
geo_data = transactions.merge(locations, on='location_id')

# æŒ‰å›½å®¶ç»Ÿè®¡
country_stats = geo_data.groupby('country')['amount'].agg(['count', 'sum', 'mean'])
print(country_stats)
```

## ğŸ“ˆ å®é™…åº”ç”¨åœºæ™¯

### ğŸ¦ é“¶è¡Œé£æ§éƒ¨é—¨
```python
# æ¯æ—¥é£é™©æŠ¥å‘Š
daily_risk = df[df['timestamp'].str.contains('2024-01-15')]
high_risk_count = len(daily_risk[daily_risk['risk_score'] >= 8.0])
total_risk_amount = daily_risk[daily_risk['risk_score'] >= 8.0]['amount'].sum()

print(f"ä»Šæ—¥é«˜é£é™©äº¤æ˜“: {high_risk_count} ç¬”")
print(f"æ¶‰åŠé‡‘é¢: ${total_risk_amount:,.2f}")
```

### ğŸ“Š ç›‘ç®¡æŠ¥å‘Š
```python
# ç”Ÿæˆç›‘ç®¡æŠ¥å‘Š
report_data = {
    'æ€»äº¤æ˜“æ•°': len(df),
    'å¯ç–‘äº¤æ˜“æ•°': len(df[df['risk_score'] >= 8.0]),
    'å¯ç–‘æ¯”ä¾‹': f"{len(df[df['risk_score'] >= 8.0]) / len(df) * 100:.2f}%",
    'æ¶‰åŠé‡‘é¢': f"${df[df['risk_score'] >= 8.0]['amount'].sum():,.2f}"
}

# è¾“å‡ºä¸ºExcelæŠ¥å‘Š
pd.DataFrame([report_data]).to_excel('ç›‘ç®¡æŠ¥å‘Š.xlsx', index=False)
```

### ğŸ¤– æœºå™¨å­¦ä¹ è®­ç»ƒ
```python
# å‡†å¤‡æœºå™¨å­¦ä¹ æ•°æ®
features = ['amount', 'risk_score', 'ml_fraud_score']
target = 'is_fraud'  # éœ€è¦æ ¹æ®ä¸šåŠ¡è§„åˆ™å®šä¹‰

# è®­ç»ƒæ•°æ®
X = df[features]
y = (df['risk_score'] >= 8.0).astype(int)  # ç®€å•çš„æ¬ºè¯ˆæ ‡ç­¾

# ä½¿ç”¨scikit-learnè®­ç»ƒæ¨¡å‹
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier()
model.fit(X, y)
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. **æ–‡ä»¶å‘½åè§„èŒƒ**
```
csv_tables/
  â”œâ”€â”€ live_transactions.csv    # ä¸»äº¤æ˜“è¡¨
  â”œâ”€â”€ users.csv               # ç”¨æˆ·è¡¨
  â”œâ”€â”€ merchants.csv           # å•†æˆ·è¡¨
  â””â”€â”€ metadata.json          # å…ƒæ•°æ®ï¼ˆä¿æŒJSONæ ¼å¼ï¼‰
```

### 2. **JSONå­—æ®µå¤„ç†**
```python
# å¤æ‚å­—æ®µç»Ÿä¸€å¤„ç†å‡½æ•°
def parse_json_field(field_value):
    if pd.isna(field_value):
        return None
    try:
        return json.loads(field_value)
    except:
        return field_value

# æ‰¹é‡è§£æ
df['flags_parsed'] = df['flags'].apply(parse_json_field)
df['velocity_parsed'] = df['velocity_checks'].apply(parse_json_field)
```

### 3. **æ€§èƒ½ä¼˜åŒ–**
```python
# å¤§æ–‡ä»¶åˆ†å—è¯»å–
chunk_size = 10000
for chunk in pd.read_csv('large_transactions.csv', chunksize=chunk_size):
    # å¤„ç†æ¯ä¸ªæ•°æ®å—
    process_chunk(chunk)
```

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜1ï¼šCSVæ–‡ä»¶æŸå
```bash
# æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§
wc -l csv_tables/*.csv
head -1 csv_tables/live_transactions.csv
```

### é—®é¢˜2ï¼šJSONå­—æ®µè§£æé”™è¯¯
```python
# å®‰å…¨è§£æJSON
def safe_json_loads(text):
    try:
        return json.loads(text)
    except (json.JSONDecodeError, TypeError):
        return text  # è¿”å›åŸå§‹å€¼
```

### é—®é¢˜3ï¼šç¼–ç é—®é¢˜
```python
# æŒ‡å®šç¼–ç è¯»å–
df = pd.read_csv('file.csv', encoding='utf-8')
```

## ğŸ“ ä½¿ç”¨æ”¯æŒ

å¦‚æœåœ¨ä½¿ç”¨CSVæ ¼å¼æ—¶é‡åˆ°é—®é¢˜ï¼š

1. **æ£€æŸ¥æ–‡ä»¶æ ¼å¼**: ç¡®ä¿æ˜¯æœ‰æ•ˆçš„CSVæ ¼å¼
2. **éªŒè¯æ•°æ®**: ä½¿ç”¨ `head` å‘½ä»¤æŸ¥çœ‹æ–‡ä»¶å¤´éƒ¨
3. **æµ‹è¯•å°æ ·æœ¬**: å…ˆç”¨å°æ•°æ®é›†æµ‹è¯•
4. **æŸ¥çœ‹æ—¥å¿—**: æ³¨æ„ç¨‹åºè¾“å‡ºçš„é”™è¯¯ä¿¡æ¯

---

**æ€»ç»“**: CSVæ ¼å¼è®©æˆ‘ä»¬çš„é‡‘èäº¤æ˜“ç›‘æ§ç³»ç»Ÿæ›´åŠ å®ç”¨å’Œé€šç”¨ï¼Œæ— è®ºæ˜¯ä¸šåŠ¡åˆ†æã€æŠ€æœ¯å¼€å‘è¿˜æ˜¯ç›‘ç®¡æŠ¥å‘Šï¼Œéƒ½èƒ½è½»æ¾åº”å¯¹ï¼ 