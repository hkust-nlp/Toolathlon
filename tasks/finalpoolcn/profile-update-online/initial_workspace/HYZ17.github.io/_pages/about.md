---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi, I am a second-year PhD student in [The Hong Kong University of Science and Technology](https://hkust.edu.hk), [Department of Computer Science and Engineering](https://cse.hkust.edu.hk). I am fortunate to be advised by Prof. [Junxian He](https://jxhe.github.io/). Before that, I received the bachelor degree in Computer Science in [Shanghai Jiao Tong University](https://en.sjtu.edu.cn/) in 2023. 

## Research Interests
I am primarily focused on large language models, particularly in advancing their reasoning capabilities and multimodal understanding. To achieve this, my research interests lie in: 
* Enhancing reasoning and planning abilities through self-improvement and RL techniques. (**B-STaR**, **SimpleRL**)
* Developing reliable evaluation methods for language models. (**C-Eval**, **LLM-Compression-Intelligence**)
* Improving the architecture and training methods of multimodal models to strengthen their understanding across multiple modalities.

I am open to any collaboration ðŸ¤—

## Publications
Most recent publications on [Google Scholar](https://scholar.google.com/citations?user=XZK8cewAAAAJ&hl=en).\\
\* denotes co-first authors



**Compression Represents Intelligence Linearly** \\
*<ins>Yuzhen Huang</ins>* \*, Jinghan Zhang *, Zifei Shan, Junxian He\\
COLM 2024. [[arxiv]](https://arxiv.org/abs/2404.09937) [[github]](https://github.com/hkust-nlp/llm-compression-intelligence) [[dataset]](https://huggingface.co/datasets/hkust-nlp/llm-compression)
* Investigate the linear correlation between compression and intelligence in LLMs.
* Provide evidence for the belief that superior compression is indicative of greater intelligence.
* Propose compression efficiency serves as an unsupervised and reliable metric to assess LLMsâ€™ abilities.


**C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models**\\
*<ins>Yuzhen Huang</ins>* \*, Yuzhuo Bai *, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu, Chuancheng Lv, Yikai Zhang, Jiayi Lei, Yao Fu, Maosong Sun, Junxian He\\
NeurIPS 2023 (Datasets and Benchmarks track). [[arxiv]](https://arxiv.org/abs/2305.08322) [[github]](https://github.com/hkust-nlp/ceval) [[website]](https://cevalbenchmark.com) [[dataset]](https://huggingface.co/datasets/ceval/ceval-exam)
* The first comprehensive Chinese evaluation suite for LLMs.
* Conduct a thorough evaluation of the most advanced LLMs.
* Over 9.8M downloads on Hugging Face and more than 100 models on leaderboard.



## Experiences
### Academia
- *2024.02 - now* PhD student, Department of CSE, [HKUST](https://hkust.edu.hk), Hong Kong SAR, China.
- *2019.09 - 2023.06* Undergraduate, Computer Science, [Shanghai Jiao Tong University](https://en.sjtu.edu.cn/), Shanghai, China.


## Service
Reviewer: NeurIPS 2024, ICLR 2025, ICML 2025, ARR

