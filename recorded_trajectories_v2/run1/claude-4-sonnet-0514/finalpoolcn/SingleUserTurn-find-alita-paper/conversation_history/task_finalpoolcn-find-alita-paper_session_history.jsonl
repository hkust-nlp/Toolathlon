{"in_turn_steps": 0, "turn": 1, "timestamp": "2025-07-14T21:47:17.121395", "type": "user_input", "content": "我在找一篇arxiv上和agentic reasoning有关的论文，我只记得它的标题中包含\"Alita\"，发表日期是2025年6月或者更早。请你帮我找一下我说的这篇论文，并帮我下载到本地(以alita_{arxiv_id}.pdf命名)，最后以以下格式返回它的标题，arxiv abs url，以及其代码仓库链接，无需使用markdown格式且无需进行多余的换行。\n\ntitle: {title}\narxiv_abs_url: {arxiv_abs_url}\ncode_url: {code_url}"}
{"in_turn_steps": 0, "turn": 2, "timestamp": "2025-07-14T21:47:22.212237", "agent": "Assistant", "item_type": "message_output_item", "raw_content": {"id": "__fake_id__", "content": [{"annotations": [], "text": "我来帮您找这篇关于agentic reasoning且标题包含\"Alita\"的论文。", "type": "output_text"}], "role": "assistant", "status": "completed", "type": "message"}}
{"in_turn_steps": 1, "turn": 2, "timestamp": "2025-07-14T21:47:22.212322", "agent": "Assistant", "item_type": "tool_call_item", "raw_content": {"arguments": "{\"date_to\":\"2025-06-30\",\"max_results\":20,\"query\":\"Alita agentic reasoning\"}", "call_id": "toolu_bdrk_01QjF3r3ExRQtUC9SxLNDs8z", "name": "arxiv_local-search_papers", "type": "function_call", "id": "__fake_id__", "status": null}}
{"in_turn_steps": 2, "turn": 2, "timestamp": "2025-07-14T21:47:22.212345", "agent": "Assistant", "item_type": "tool_call_output_item", "raw_content": {"call_id": "toolu_bdrk_01QjF3r3ExRQtUC9SxLNDs8z", "output": "{\"type\":\"text\",\"text\":\"{\\n  \\\"total_results\\\": 0,\\n  \\\"papers\\\": []\\n}\",\"annotations\":null}", "type": "function_call_output"}}
{"in_turn_steps": 0, "turn": 3, "timestamp": "2025-07-14T21:47:26.117559", "agent": "Assistant", "item_type": "message_output_item", "raw_content": {"id": "__fake_id__", "content": [{"annotations": [], "text": "让我尝试更宽泛的搜索，只用\"Alita\"作为关键词：", "type": "output_text"}], "role": "assistant", "status": "completed", "type": "message"}}
{"in_turn_steps": 1, "turn": 3, "timestamp": "2025-07-14T21:47:26.117647", "agent": "Assistant", "item_type": "tool_call_item", "raw_content": {"arguments": "{\"date_to\":\"2025-06-30\",\"max_results\":20,\"query\":\"Alita\"}", "call_id": "toolu_bdrk_01XY5Qy4x3g6mfu5ch4DLKo1", "name": "arxiv_local-search_papers", "type": "function_call", "id": "__fake_id__", "status": null}}
{"in_turn_steps": 2, "turn": 3, "timestamp": "2025-07-14T21:47:26.117676", "agent": "Assistant", "item_type": "tool_call_output_item", "raw_content": {"call_id": "toolu_bdrk_01XY5Qy4x3g6mfu5ch4DLKo1", "output": "{\"type\":\"text\",\"text\":\"{\\n  \\\"total_results\\\": 4,\\n  \\\"papers\\\": [\\n    {\\n      \\\"id\\\": \\\"2505.20286v1\\\",\\n      \\\"title\\\": \\\"Alita: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self-Evolution\\\",\\n      \\\"authors\\\": [\\n        \\\"Jiahao Qiu\\\",\\n        \\\"Xuan Qi\\\",\\n        \\\"Tongcheng Zhang\\\",\\n        \\\"Xinzhe Juan\\\",\\n        \\\"Jiacheng Guo\\\",\\n        \\\"Yifu Lu\\\",\\n        \\\"Yimin Wang\\\",\\n        \\\"Zixin Yao\\\",\\n        \\\"Qihan Ren\\\",\\n        \\\"Xun Jiang\\\",\\n        \\\"Xing Zhou\\\",\\n        \\\"Dongrui Liu\\\",\\n        \\\"Ling Yang\\\",\\n        \\\"Yue Wu\\\",\\n        \\\"Kaixuan Huang\\\",\\n        \\\"Shilong Liu\\\",\\n        \\\"Hongru Wang\\\",\\n        \\\"Mengdi Wang\\\"\\n      ],\\n      \\\"abstract\\\": \\\"Recent advances in large language models (LLMs) have enabled agents to\\\\nautonomously perform complex, open-ended tasks. However, many existing\\\\nframeworks depend heavily on manually predefined tools and workflows, which\\\\nhinder their adaptability, scalability, and generalization across domains. In\\\\nthis work, we introduce Alita--a generalist agent designed with the principle\\\\nof \\\\\\\"Simplicity is the ultimate sophistication,\\\\\\\" enabling scalable agentic\\\\nreasoning through minimal predefinition and maximal self-evolution. For minimal\\\\npredefinition, Alita is equipped with only one component for direct\\\\nproblem-solving, making it much simpler and neater than previous approaches\\\\nthat relied heavily on hand-crafted, elaborate tools and workflows. This clean\\\\ndesign enhances its potential to generalize to challenging questions, without\\\\nbeing limited by tools. For Maximal self-evolution, we enable the creativity of\\\\nAlita by providing a suite of general-purpose components to autonomously\\\\nconstruct, refine, and reuse external capabilities by generating task-related\\\\nmodel context protocols (MCPs) from open source, which contributes to scalable\\\\nagentic reasoning. Notably, Alita achieves 75.15% pass@1 and 87.27% pass@3\\\\naccuracy, which is top-ranking among general-purpose agents, on the GAIA\\\\nbenchmark validation dataset, 74.00% and 52.00% pass@1, respectively, on\\\\nMathvista and PathVQA, outperforming many agent systems with far greater\\\\ncomplexity. More details will be updated at\\\\n$\\\\\\\\href{https://github.com/CharlesQ9/Alita}{https://github.com/CharlesQ9/Alita}$.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.AI\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-05-26T17:58:53+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2505.20286v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2505.20286v1\\\"\\n    },\\n    {\\n      \\\"id\\\": \\\"2304.04236v1\\\",\\n      \\\"title\\\": \\\"Asymmetric networks, clientelism and their impacts: households' access to workfare employment in rural India\\\",\\n      \\\"authors\\\": [\\n        \\\"Anindya Bhattacharya\\\",\\n        \\\"Anirban Kar\\\",\\n        \\\"Alita Nandi\\\"\\n      ],\\n      \\\"abstract\\\": \\\"In this paper we explore two intertwined issues. First, using primary data we\\\\nexamine the impact of asymmetric networks, built on rich relational information\\\\non several spheres of living, on access to workfare employment in rural India.\\\\nWe find that unidirectional relations, as opposed to reciprocal relations, and\\\\nthe concentration of such unidirectional relations increase access to workfare\\\\njobs. Further in-depth exploration provides evidence that patron-client\\\\nrelations are responsible for this differential access to such employment for\\\\nrural households. Complementary to our empirical exercises, we construct and\\\\nanalyse a game-theoretical model supporting our findings.\\\",\\n      \\\"categories\\\": [\\n        \\\"econ.GN\\\",\\n        \\\"q-fin.EC\\\"\\n      ],\\n      \\\"published\\\": \\\"2023-04-09T13:34:50+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2304.04236v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2304.04236v1\\\"\\n    },\\n    {\\n      \\\"id\\\": \\\"2208.05002v1\\\",\\n      \\\"title\\\": \\\"Patronage and power in rural India: a study based on interaction networks\\\",\\n      \\\"authors\\\": [\\n        \\\"Anindya Bhattacharya\\\",\\n        \\\"Anirban Kar\\\",\\n        \\\"Sunil Kumar\\\",\\n        \\\"Alita Nandi\\\"\\n      ],\\n      \\\"abstract\\\": \\\"This work has two intertwined components: first, as part of a research\\\\nprogramme it introduces a new methodology for identifying `power-centres' in\\\\nrural societies of developing countries in general and then applies that in the\\\\nspecific context of contemporary rural India for addressing some debates on the\\\\ndynamics of power in rural India. We identify the nature of `local' rural\\\\ninstitutions based on primary data collected by ourselves (in 2013 and 2014).\\\\nWe took 36 villages in the states of Maharashtra, Odisha and Uttar Pradesh - 12\\\\nin each of these states - as the sites for our observation and data collection.\\\\nWe quantify nature of institutions from data on the day-to-day interactions of\\\\nhouseholds in the spheres of economy, society and politics. Our household\\\\nsurvey shows that there is substantial variation in power structure across\\\\nregions. We identified the presence of `local elites' in 22 villages out of 36\\\\nsurveyed. We conducted a follow-up survey, called `elite survey', to get\\\\ndetailed information about the identified elite households. We observe that\\\\nlandlordism has considerably weakened, land has ceased to be the sole source of\\\\npower and new power-centres have emerged. Despite these changes, caste,\\\\nlandownership and patron-client relation continue to be three important pillars\\\\nof rural power structure.\\\",\\n      \\\"categories\\\": [\\n        \\\"econ.GN\\\",\\n        \\\"q-fin.EC\\\"\\n      ],\\n      \\\"published\\\": \\\"2022-08-09T19:09:23+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2208.05002v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2208.05002v1\\\"\\n    },\\n    {\\n      \\\"id\\\": \\\"2205.10737v2\\\",\\n      \\\"title\\\": \\\"ALITA: A Large-scale Incremental Dataset for Long-term Autonomy\\\",\\n      \\\"authors\\\": [\\n        \\\"Peng Yin\\\",\\n        \\\"Shiqi Zhao\\\",\\n        \\\"Ruohai Ge\\\",\\n        \\\"Ivan Cisneros\\\",\\n        \\\"Ruijie Fu\\\",\\n        \\\"Ji Zhang\\\",\\n        \\\"Howie Choset\\\",\\n        \\\"Sebastian Scherer\\\"\\n      ],\\n      \\\"abstract\\\": \\\"For long-term autonomy, most place recognition methods are mainly evaluated\\\\non simplified scenarios or simulated datasets, which cannot provide solid\\\\nevidence to evaluate the readiness for current Simultaneous Localization and\\\\nMapping (SLAM). In this paper, we present a long-term place recognition dataset\\\\nfor use in mobile localization under large-scale dynamic environments. This\\\\ndataset includes a campus-scale track and a city-scale track: 1) the\\\\ncampus-track focuses the long-term property, we record LiDAR device and an\\\\nomnidirectional camera on 10 trajectories, and each trajectory are repeatly\\\\nrecorded 8 times under variant illumination conditions. 2) the city-track\\\\nfocuses the large-scale property, we mount the LiDAR device on the vehicle and\\\\ntraversing through a 120km trajectories, which contains open streets,\\\\nresidential areas, natural terrains, etc. They includes 200 hours of raw data\\\\nof all kinds scenarios within urban environments. The ground truth position for\\\\nboth tracks are provided on each trajectory, which is obtained from the Global\\\\nPosition System with an additional General ICP based point cloud refinement. To\\\\nsimplify the evaluation procedure, we also provide the Python-API with a set of\\\\nplace recognition metrics is proposed to quickly load our dataset and evaluate\\\\nthe recognition performance against different methods. This dataset targets at\\\\nfinding methods with high place recognition accuracy and robustness, and\\\\nproviding real robotic system with long-term autonomy. The dataset and the\\\\nprovided tools can be accessed from https://github.com/MetaSLAM/ALITA.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.RO\\\"\\n      ],\\n      \\\"published\\\": \\\"2022-05-22T04:25:00+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2205.10737v2\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2205.10737v2\\\"\\n    }\\n  ]\\n}\",\"annotations\":null}", "type": "function_call_output"}}
{"in_turn_steps": 0, "turn": 4, "timestamp": "2025-07-14T21:47:33.348466", "agent": "Assistant", "item_type": "message_output_item", "raw_content": {"id": "__fake_id__", "content": [{"annotations": [], "text": "找到了！第一个结果正是您要找的论文。这篇论文标题为\"Alita: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self-Evolution\"，发表于2025年5月26日，符合您的要求。现在我来下载这篇论文：", "type": "output_text"}], "role": "assistant", "status": "completed", "type": "message"}}
{"in_turn_steps": 1, "turn": 4, "timestamp": "2025-07-14T21:47:33.348559", "agent": "Assistant", "item_type": "tool_call_item", "raw_content": {"arguments": "{\"paper_id\":\"2505.20286v1\"}", "call_id": "toolu_bdrk_01X2k2Hj1q5Z2ZPsGQ7p4fZ5", "name": "arxiv_local-download_paper", "type": "function_call", "id": "__fake_id__", "status": null}}
{"in_turn_steps": 2, "turn": 4, "timestamp": "2025-07-14T21:47:33.348586", "agent": "Assistant", "item_type": "tool_call_output_item", "raw_content": {"call_id": "toolu_bdrk_01X2k2Hj1q5Z2ZPsGQ7p4fZ5", "output": "{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"converting\\\", \\\"message\\\": \\\"Paper downloaded, conversion started\\\", \\\"started_at\\\": \\\"2025-07-14T21:47:32.480539\\\"}\",\"annotations\":null}", "type": "function_call_output"}}
{"in_turn_steps": 0, "turn": 5, "timestamp": "2025-07-14T21:47:37.534271", "agent": "Assistant", "item_type": "message_output_item", "raw_content": {"id": "__fake_id__", "content": [{"annotations": [], "text": "现在我来检查转换状态并读取论文内容以获取代码仓库链接：", "type": "output_text"}], "role": "assistant", "status": "completed", "type": "message"}}
{"in_turn_steps": 1, "turn": 5, "timestamp": "2025-07-14T21:47:37.534358", "agent": "Assistant", "item_type": "tool_call_item", "raw_content": {"arguments": "{\"check_status\":true,\"paper_id\":\"2505.20286v1\"}", "call_id": "toolu_bdrk_01HrPtpUzyTG3CfjwUn5Lt6r", "name": "arxiv_local-download_paper", "type": "function_call", "id": "__fake_id__", "status": null}}
{"in_turn_steps": 2, "turn": 5, "timestamp": "2025-07-14T21:47:37.534381", "agent": "Assistant", "item_type": "tool_call_output_item", "raw_content": {"call_id": "toolu_bdrk_01HrPtpUzyTG3CfjwUn5Lt6r", "output": "{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"success\\\", \\\"started_at\\\": \\\"2025-07-14T21:47:32.480539\\\", \\\"completed_at\\\": \\\"2025-07-14T21:47:37.325790\\\", \\\"error\\\": null, \\\"message\\\": \\\"Paper conversion success\\\"}\",\"annotations\":null}", "type": "function_call_output"}}
{"in_turn_steps": 0, "turn": 6, "timestamp": "2025-07-14T21:47:42.067580", "agent": "Assistant", "item_type": "message_output_item", "raw_content": {"id": "__fake_id__", "content": [{"annotations": [], "text": "转换成功！现在我来读取论文内容以确认代码仓库链接：", "type": "output_text"}], "role": "assistant", "status": "completed", "type": "message"}}
{"in_turn_steps": 1, "turn": 6, "timestamp": "2025-07-14T21:47:42.067688", "agent": "Assistant", "item_type": "tool_call_item", "raw_content": {"arguments": "{\"paper_id\":\"2505.20286v1\"}", "call_id": "toolu_bdrk_01BxuYp8FYfZpMmH8yUJ7qWL", "name": "arxiv_local-read_paper", "type": "function_call", "id": "__fake_id__", "status": null}}
{"in_turn_steps": 2, "turn": 6, "timestamp": "2025-07-14T21:47:42.067718", "agent": "Assistant", "item_type": "tool_call_output_item", "raw_content": {"call_id": "toolu_bdrk_01BxuYp8FYfZpMmH8yUJ7qWL", "output": "{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"success\\\", \\\"paper_id\\\": \\\"2505.20286v1\\\", \\\"content\\\": \\\"## A LITA : G ENERALIST A GENT E NABLING S CALABLE A GENTIC R EASONING WITH M INIMAL P REDEFINITION AND M AXIMAL S ELF -E VOLUTION\\\\n\\\\nJiahao Qiu *[\\\\u2217]* [1], Xuan Qi *[\\\\u2217]* [2], Tongcheng Zhang *[\\\\u2217]* [3], Xinzhe Juan [3] *[,]* [4], Jiacheng Guo [1], Yifu Lu [1], Yimin Wang [3] *[,]* [4], Zixin Yao [1],\\\\nQihan Ren [3], Xun Jiang [5], Xing Zhou [5], Dongrui Liu [3], Ling Yang [1], Yue Wu [1], Kaixuan Huang [1], Shilong Liu [1],\\\\nHongru Wang [6], Mengdi Wang [1]\\\\n\\\\n1 AI Lab, Princeton University 2 IIIS, Tsinghua University 3 Shanghai Jiao Tong University\\\\n4 University of Michigan 5 Tianqiao and Chrissy Chen Institute 6 The Chinese University of Hong Kong\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n|Col1|47.|57.<br>6%|7%|6|Col6|74.3<br>.1%<br>%|%<br>76.9|%|86.5|88.7<br>%<br>89|%<br>.5%|\\\\n|---|---|---|---|---|---|---|---|---|---|---|---|\\\\n||47.|57.<br>6%|7%|6|70|.1|.1|.1|.1|.1|.1|\\\\n||47.|57.<br>6%|7%|6|9.1|9.1|9.1|9.1|9.1|9.1|9.1|\\\\n|||||67.4|%|73.3%|||87.|3%||\\\\n\\\\n\\\\nFigure 1: Performance of Alita, manus.ai, and OpenAI DeepResearch[1]\\\\n\\\\n**A** **BSTRACT**\\\\n\\\\nRecent advances in large language models (LLMs) have enabled agents to autonomously perform\\\\ncomplex, open-ended tasks. However, many existing frameworks depend heavily on manually\\\\npredefined tools and workflows, which hinder their adaptability, scalability, and generalization\\\\nacross domains. In this work, we introduce **Alita** \\\\u2014a generalist agent designed with the principle\\\\nof *\\\\\\\"Simplicity is the ultimate sophistication,\\\\\\\"* enabling scalable agentic reasoning through *minimal*\\\\n*predefinition* and *maximal self-evolution* . For minimal predefinition, Alita is equipped with only one\\\\ncomponent for direct problem-solving, making it much simpler and neater than previous approaches\\\\nthat relied heavily on hand-crafted, elaborate tools and workflows. This clean design enhances\\\\nits potential to generalize to challenging questions, without being limited by tools. For *Maximal*\\\\n*self-evolution*, we enable the creativity of Alita by providing a suite of general-purpose components\\\\nto autonomously construct, refine, and reuse external capabilities by generating task-related model\\\\ncontext protocols (MCPs) from open source, which contributes to scalable agentic reasoning. Notably,\\\\nAlita achieves 75.15% pass@1 and 87.27% pass@3 accuracy, which is top-ranking among generalpurpose agents, on the GAIA benchmark validation dataset, 74.00% and 52.00% pass@1, respectively,\\\\non Mathvista and PathVQA, outperforming many agent systems with far greater complexity. More\\\\n[details will be updated at https://github.com/CharlesQ9/Alita.](https://github.com/CharlesQ9/Alita)\\\\n\\\\n*\\\\u2217* These authors contributed equally to this work.\\\\n\\\\n**1** **Introduction**\\\\n\\\\n*\\\\\\\"Simplicity is the ultimate sophistication.\\\\\\\"* \\\\u2014 Leonardo da Vinci\\\\n\\\\nLarge language models (LLMs) have rapidly evolved from merely generating text to autonomous agents capable of\\\\nindependently planning and executing complex tasks on behalf of users with limited human oversight [ 2 ]. These\\\\ncapabilities have enabled a wide range of applications, ranging from travel planning [ 3 ], computer use [ 4, 5, 6 ],\\\\nto the multi-step research tasks [ 7 ]. To support such diverse and demanding tasks, a new class of systems called\\\\ngeneralist agents has emerged. These agents are designed to handle a wide range of domains and tasks through a unified\\\\narchitecture, allowing them to generalize beyond task-specific solutions, such as OpenAI Deep Research [ 1 ] and Manus.\\\\n\\\\nHowever, most of the current general-purpose agents heavily rely on large-scale manual engineering, including tediously\\\\ndesigned workflows, considerable pre-defined tools, and hardcoded components [ 8, 9 ]. This reliance introduces several\\\\ncritical limitations: i) It is impractical, if not impossible, to predefine all the tools required for the wide variety of\\\\nreal-world tasks an agent might encounter ( *imcomplete coverage* ); ii) Many complex tasks require agents to creatively\\\\ncompose new tools or leverage existing ones in novel ways while pre-designed workflow and hardcoded components\\\\nconstrain this compositional flexibility and inhibit the development of adaptive behaviors ( *limited creativity and*\\\\n*flexibility* ); iii) It is not always the case that the interface or environment of different tools are compatible with the agent\\\\n( *mismatch* ). For example, many useful tools are not written in Python, which makes it difficult, though not entirely\\\\nimpossible, for them to be pre-connected to the mainstream agent frameworks that are primarily written in Python.\\\\nTogether, these challenges ultimately hinder the scalability, adaptability, and generalization of existing generalist agents.\\\\n\\\\nIn contrast to the prevailing trend of growing complexity, we propose a radically simple design philosophy built on two\\\\nprinciples: i) *Minimal Predefinition* : Equip the agent with only a minimal set of core capabilities, avoiding manually\\\\nengineered components for specific tasks or modalities; ii) *Maximal Self-Evolution* : Empower the agent to autonomously\\\\ncreate, refine, and reuse external capabilities as needed. We instantiate this vision through Alita, a generalist agent built\\\\nwith a single core capability (i.e., the web agent) and a small set of general-purpose modules that enable self-directed\\\\ncapability expansion. Specifically, we take advantage of the Model Context Protocols (MCPs) [1] which is an open\\\\nprotocol that standardizes how different systems provide context to LLMs, and empower Alita to dynamically generate,\\\\nadapt, and reuse MCPs based on the demands of each task rather than relying on static, predefined tools. This shift from\\\\nmanually designed capabilities to on-the-fly MCP construction unlocks a new path for building agents that are simple\\\\nyet profoundly capable.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n|Col1|Col2|\\\\n|---|---|\\\\n||MCP Creation|\\\\n\\\\n\\\\n\\\\n|Col1|Col2|\\\\n|---|---|\\\\n|Self Evolving||\\\\n|||\\\\n\\\\n\\\\n\\\\nFigure 2: Comparison between Traditional Generalist Agents and Alita. Traditional generalist agents heavily rely on\\\\nlarge-scale manual engineering while Alita adheres to minimal predefinition and maximal self-evolution.\\\\n\\\\nWe conduct comprehensive experiments on several benchmarks to assess Alita in real-world applications, especially\\\\non the most popular GAIA [ 10 ]. Alita proves that simplicity is not a constraint, but a strength, and that creative agent\\\\nbehavior can emerge from a design that prioritizes autonomy over manual engineering. To sum up, our key contributions\\\\ncan be summarized as follows.\\\\n\\\\n    - We propose a new agent architecture centered on minimal predefinition and maximal self-evolution, challenging\\\\nconventional design norms in generalist agents, aiming to call for a more scalable and generalizable agent\\\\nframework.\\\\n\\\\n1 `https://www.anthropic.com/news/model-context-protocol`\\\\n\\\\n2\\\\n\\\\n    - We present Alita, a generalist agent that achieves scalable agentic reasoning with a radically simple design.\\\\n\\\\n    - We empirically demonstrate that Alita, despite using no complex predefined tools and workflows for specific\\\\ntasks, outperforms many systems with significantly more handcrafted complexity on the GAIA benchmark.\\\\nWe achieve 75.15% pass@1 and 87.27% pass@3, surpassing OpenAI\\\\u2019s Deep Research with 67.36% pass@1\\\\nand ranking top among all general-purpose agents.\\\\n\\\\n**2** **Related Works**\\\\n\\\\n**2.1** **Generalist Agent**\\\\n\\\\nThe concept of a Generalist Agent aims to construct an AI agent system capable of collaboratively completing a variety\\\\nof complex tasks in a real-world environment. OWL [ 8 ] introduces a method that decomposes complex tasks into\\\\nsubtasks and dynamically allocates them to worker nodes with specialized toolkits. Omne [ 11 ] proposes a multiagent collaborative development framework, where each agent possesses an independent system structure, enabling\\\\nautonomous learning and the storage of a comprehensive world model to build an independent understanding of the\\\\nenvironment. OpenAI Deep Research [2] employs reinforcement learning for training on real-world tasks, aiming to\\\\nprovide precise and reliable research reports for knowledge-intensive tasks. A-World [ 12 ] offers a highly configurable,\\\\nmodular, and scalable simulation environment, allowing developers to flexibly define and integrate different types of AI\\\\nagents. The Magentic-One [ 13 ] framework merges the Magentic and Autogen systems, distinguishing between the\\\\nmicro-level LLM-driven function generation and the macro-level multi-agent orchestration, resulting in a clearer and\\\\nmore efficient construction of agent systems. Alita, also a Generalist Agent, allows for the minimal use of predefined\\\\ntools and workflows for direct problem-solving, yet still achieves impressive performance across diverse tasks.\\\\n\\\\n**2.2** **Auto Generating Agent**\\\\n\\\\nAuto-generating agents aim to enhance the versatility of agents by enabling them to autonomously generate tools,\\\\nagents, or workflows tailored to specific tasks. AutoAgents [ 14 ], for instance, generate multiple agents, each playing a\\\\ndistinct role, to handle the corresponding subtasks. OpenHands [ 15 ] offers an event-driven architecture that allows\\\\nagents to interact with the environment like human developers, thereby enabling the creation of custom workflows.\\\\nAFlow [ 16 ] redefines workflow optimization as a search problem, where each workflow consists of several nodes\\\\ninvoking large LLMs, and the optimal workflow is identified and executed through a search process. AutoAgent [ 17 ], as\\\\nan autonomous agent operating system, permits agents to manage system-level operations and file data autonomously.\\\\nIn Alita, agents are empowered to automatically generate diverse, specialized, and highly accurate MCPs to aid in the\\\\ncompletion of specific tasks, while also providing resources for future executions.\\\\n\\\\n**2.3** **Tool Creation**\\\\n\\\\nTool Creation enables agents to autonomously create tools to assist in task execution, either on their own or with external\\\\nsupport. CRAFT [ 18 ] utilizes GPT-4 to generate a set of code snippets that function as tools, which are then retrieved\\\\nand used in the system. TroVE [19] maintains a collection of high-level functions, which are automatically generated,\\\\nextended, and periodically pruned to optimize program generation. CREATOR [ 20 ] decouples the abstraction of tool\\\\ncreation from the actual execution, allowing LLMs to address tasks at different levels of granularity. AutoAgent [ 17 ]\\\\nenables agents to autonomously create new tools based on task requirements, incorporating information gathered\\\\nthrough web searches and integrating these tools into their workflow. OpenHands [ 15 ] allows agents to create code\\\\nscripts in a human-like manner during interaction with the environment to assist in task completion. In comparison,\\\\nAlita enables MCP creation, which provides additional benefits, including better reusability and easy environment\\\\nmanagement over tool creation.\\\\n\\\\n**2.4** **MCP**\\\\n\\\\nThe Model Context Protocol (MCP) is a standard proposed by Anthropic, designed to unify the connection between AI\\\\nsystems and external data sources and services. RAG-MCP [ 21 ] enhances the efficiency and accuracy of agents by\\\\nretrieving the most relevant tools from a large collection, based on the task description, within the database composed\\\\nof MCP descriptions. After tool generation, Alita wraps the generated valid tools into MCPs for subsequent use,\\\\nfacilitating reuse by itself and other agents.\\\\n\\\\n2 https://openai.com/index/introducing-deep-research/\\\\n\\\\n3\\\\n\\\\n**3** **Methods**\\\\n\\\\nWe propose Alita, a generalist agent enabling scalable agentic reasoning with minimal predefinition and maximal\\\\nself-evolution to tackle diverse and complex tasks. Figure **3** illustrates the framework of Alita. In contrast to generalist\\\\nagents that typically depend on extensive manually-designed tools and workflows [ 8, 9 ], the manager agent in Alita\\\\nsolely orchestrates the web agent using only basic tools. Through this approach, our framework enables Alita to plan\\\\ntask-specific tools through brainstorming. It then utilizes a Web Agent to search for helpful open-source libraries\\\\nand other resources related to these tools. Leveraging the search results, Alita autonomously generates new tools and\\\\nconfigures the necessary environments to enhance its capabilities and effectively solve tasks. During this process, if\\\\nany issues arise with the newly generated tools or their environments, Alita can provide feedback and self-correct,\\\\nimproving the quality of the generated tools. Furthermore, the new tools can be encapsulated as MCP servers for future\\\\nreuse. With the aid of MCPs, Alita can generate increasingly powerful, diverse, and complex MCPs, thus establishing a\\\\nself-reinforcing cycle. Therefore, Alita autonomously expands its capabilities through continuous MCP integration.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nFigure 3: The architecture of Alita. Upon receiving a question, the Manager Agent initiates an iterative CodeReAct\\\\nloop to analyze tasks, identify functional gaps, and trigger MCP Brainstorming for creative synthesis. The system\\\\ndynamically performs open-source searching, script generation, and virtual environment execution to construct taskrelated functions. Useful ones are encapsulated into reusable MCPs and stored in the MCP Box. Throughout this\\\\nprocess, the Manager Agent collaborates with the Web Agent for external information retrieval and continuously\\\\nintegrates intermediate results until a final output is produced. This process enables Alita to self-evolve without relying\\\\non a huge hand-crafted, elaborate tools and workflows.\\\\n\\\\n**3.1** **Execution Pipeline**\\\\n\\\\nEach task commences with the construction of an augmented prompt that incorporates the original query. The manager\\\\nagent (Sec. 3.2) then initiates a multi-step reasoning process to address the task at hand. Throughout this process, the\\\\nagent may query external sources via the web agent (Sec. 3.3), plan and synthesize new tools (Sec. 3.4), and execute\\\\nthem within isolated environments (Sec. 3.4.4).\\\\n\\\\nUpon successful tool generation and accurate result formulation, the corresponding script is transformed into an MCP\\\\nand stored in the internal tool registry for future reuse. All reasoning steps, intermediate code, and final outputs are\\\\nsystematically logged to facilitate comprehensive analysis.\\\\n\\\\n**3.2** **Manager Agent**\\\\n\\\\nThe Manager Agent functions as the central coordinator within framework of Alita. When receiving a task prompt, the\\\\nmanager agent initially calls the `MCP Brainstorming` to determine whether additional tools are needed and which\\\\nspecific tools are required. Then the manager agent decomposes the task into subtasks and dispatches them to web\\\\nagent or generates the required external tools to complete the subtask. When necessary, the manager agent utilizes the\\\\ninformation retrieved by the web agent to generate the required new tools along with their corresponding environment\\\\nconfiguration instructions. After collecting all intermediate results, the manager performs final aggregation and response\\\\nformulation.\\\\n\\\\n4\\\\n\\\\n**Tool Usage** . In contrast to traditional systems that rely on extensive predefined toolkits, the manager agent embraces Alita\\\\u2019s minimal philosophy by employing concise but powerful toolkits, including `MCP Brainstorming`,\\\\n`ScriptGeneratingTool` and `CodeRunningTool` . Specifically, `MCP Brainstorming` detects functional gaps, identifies necessary supplementary tools and outlines tool specifications; `ScriptGeneratingTool` obtains tool specification\\\\noutlines and then generates appropriate tools tailored to the task requirements; `CodeRunningTool` executes generated\\\\ncode in isolated environments and caches the output for potential MCP servers generation. These tools are intelligently\\\\ninvoked in response to the task\\\\u2019s evolving demands, ensuring adaptive and efficient problem-solving.\\\\n\\\\n**3.3** **Web Agent**\\\\n\\\\nThe web agent retrieves relevant information from external sources when internal knowledge is insufficient. It is\\\\nparticularly effective for tasks requiring the retrieval of domain-specific code or documentation. With a lightweight,\\\\ntext-based web interface and modular navigation tools, the web agent traverses multiple websites, extract relevant\\\\nsegments, and return reasonable URLs or raw content.\\\\n\\\\n**Tool Usage** . The agent utilizes `SimpleTextBrowser` as its web interface and page-level control tools: `VisitTool`,\\\\n`PageUpTool`, and `PageDownTool` to navigate webpages. For query-based lookups, it applies `GoogleSearchTool` for\\\\nopen web search and `GithubSearchTool` to identify reusable open-source tools. This design supports real-time code\\\\nretrieval and context-aware tool planning.\\\\n\\\\n**3.4** **MCP Creation Component**\\\\n\\\\nTo enable the creativity of the agent, we design three tools collaboratively contributing to the MCP creation process.\\\\n\\\\n**3.4.1** **MCP Brainstorming**\\\\n\\\\nSince LLMs often exhibit overconfidence in their capabilities [ 22 ], we introduce `MCP Brainstorming` to conduct\\\\npreliminary capability assessment by providing both the task and the description of current framework. We designed specialized prompts to facilitate accurate self-assessment of the agent\\\\u2019s capabilities. Moreover, when `MCP Brainstorming`\\\\nidentifies insufficient capabilities of the framework to complete the task, it provides references for tool generation to\\\\nbridge the capability gap. This provides prior guidance for subsequent tool selection and task planning required to\\\\naccomplish given objectives.\\\\n\\\\n**3.4.2** **ScriptGeneratingTool**\\\\n\\\\nThe `ScriptGeneratingTool` is a code-building utility designed for constructing external tools. It receives explicit\\\\nsubtask descriptions and suggestions for code construction from the manager agent, and potentially useful GitHub links\\\\nobtained via the web agent, which can provide information such as `README.md` files or code snippets from GitHub to\\\\nguide the script generation process. Furthermore, `ScriptGeneratingTool` generates the environment script to create\\\\nthe required environment for the code running and the cleaning script to clean up redundant files and environments\\\\ngenerated after script execution. Therefore, `ScriptGeneratingTool` ensures that the generated scripts are valid,\\\\nself-contained, and executable, making them suitable for deployment in the given task, and reusable in the future.\\\\n\\\\n**3.4.3** **CodeRunningTool**\\\\n\\\\nThe `CodeRunningTool` validates the functionality of the generated script by executing it within an isolated environment.\\\\nIf the execution produces the expected results, the tool is registered in the system as a reusable MCP. This process also\\\\nsupports iterative refinement, allowing for error inspection and subsequent code regeneration to improve the script\\\\u2019s\\\\nperformance.\\\\n\\\\n**3.4.4** **Environment Management**\\\\n\\\\nUpon retrieving or generating a candidate tool, the system activates the environment planner module. This module\\\\nparses the relevant repository or script metadata such as `README.md`, `requirements.txt`, and shell scripts using\\\\nthe `TextInspectorTool` . It extracts and validates the dependencies and setup instructions to construct an isolated\\\\nexecution profile. Subsequently, a new Conda environment is created with a unique name (typically derived from the\\\\ntask ID or a hash of the repository path), and dependencies are installed using `conda install` or `pip install` .\\\\n\\\\nAll runtime environments are initialized locally in parallel, obviating the need for administrative privileges or containerization technologies. This approach ensures high compatibility across various tasks while preserving the portability\\\\n\\\\n5\\\\n\\\\nof the system. During execution, the environment is explicitly activated prior to invoking the code interpreter, thus\\\\nensuring both isolation and reproducibility.\\\\n\\\\nIn the event of a failure during environment initialization\\\\u2014due to issues such as missing packages, syntax errors in setup\\\\nscripts, or unavailable dependencies\\\\u2014Alita activates an automated recovery procedure. This procedure attempts various\\\\nfallback strategies, including relaxing version constraints or identifying the minimal set of dependencies required for\\\\nfunctionality. If these recovery attempts are unsuccessful, the tool is discarded, and the failure is logged for offline\\\\nanalysis and future investigation. This enables Alita to self-correct its designed tools, thereby generating more accurate\\\\nand robust solutions.\\\\n\\\\n**4** **Experiments**\\\\n\\\\n**4.1** **Experiment Setting**\\\\n\\\\n**4.1.1** **Benchmarks**\\\\n\\\\nTo evaluate the general task-handling capabilities of Alita, we conducted extensive testing across multiple agent\\\\nbenchmarks.\\\\n\\\\n**GAIA [** **10** **]:** GAIA is a benchmark designed to assess the capabilities of general-purpose AI assistants. It consists of\\\\n466 real-world scenario-based questions covering daily tasks, scientific reasoning, web browsing, and tool usage. While\\\\nthese tasks are conceptually simple for humans, they are challenging for most advanced AI systems.\\\\n\\\\n**Mathvista [** **23** **]:** MathVista is a comprehensive benchmark designed to evaluate the mathematical reasoning capabilities\\\\nof foundation models within visual contexts. It can effectively evaluate the model\\\\u2019s capabilities in visual comprehension,\\\\nmathematical reasoning, programming, and other related skills. Due to limitations in resources, we randomly selected\\\\n100 samples from the dataset.\\\\n\\\\n**Pathvqa [** **24** **]:** PathVQA is a medical visual question answering dataset. It can effectively assess the agent\\\\u2019s capabilities\\\\nacross multiple dimensions, including visual understanding, spatial Reasoning, medical Knowledge search or integration,\\\\nand natural language processing. Due to limitations in resources, we randomly selected 100 samples from the dataset.\\\\n\\\\n**4.1.2** **Baselines**\\\\n\\\\nWe include a variety of baselines for comparison. For the GAIA benchmark, there are more baselines available on the\\\\nGAIA leaderboard [3] .\\\\n\\\\n**Octotools [** **9** **]:** OctoTools is a recent framework designed to streamline multi-tool workflows in complex computational\\\\ntasks. With over 10 standardized tool cards encapsulating various functionalities, the agent gains powerful capabilities\\\\nto handle multi-domain tasks.\\\\n\\\\n**Open Deep Research-smolagents** [4] **[** **25** **]:** Open Deep Research is an open-source agent developed under Hugging\\\\nFace\\\\u2019s Smolagents project, designed to automate complex multi-step research tasks. Alita\\\\u2019s development is largely\\\\nbased on the framework of Open Deep Research-smolagents. However, we remove many pre-defined tools and also add\\\\nthe MCP creation component to follow the design principle of minimal predefinition and maximal self-evolution.\\\\n\\\\n**AutoAgent [** **17** **]:** AutoAgent is a zero-code platform designed to facilitate the creation, customization, and deployment\\\\nof agents powered by LLMs. By providing a natural language interface, it allows users to develop multi-agent systems,\\\\ndesign workflows, and integrate tools without requiring technical expertise.\\\\n\\\\n**OWL [** **8** **]:** OWL is an open-source, multi-agent framework built on the CAMEL-AI platform, designed to support the\\\\nautomation of complex real-world tasks through dynamic agent collaboration. OWL decomposes tasks into specialized\\\\nsub-tasks, each of which is managed by a distinct agent type\\\\u2014such as UserAgents, AssistantAgents, and ToolAgents.\\\\n\\\\n**A-World [** **12** **]:** A-World is an open-source multi-agent system framework designed to simplify the construction,\\\\nevaluation, and deployment of general multi-agent tasks. Through its modular design, the framework supports\\\\nautonomous decision-making, tool usage, and collaboration among agents.\\\\n\\\\n**OpenAI Deep Research** [5] **:** OpenAI\\\\u2019s Deep Research is an advanced AI agent integrated with ChatGPT, designed to\\\\nautonomously perform multi-step research tasks by synthesizing information from diverse online sources. This agentic\\\\n\\\\n3 https://huggingface.co/spaces/gaia-benchmark/leaderboard\\\\n4 https://huggingface.co/blog/open-deep-research\\\\n5 https://openai.com/index/introducing-deep-research/\\\\n\\\\n6\\\\n\\\\nframework excels in generating comprehensive reports on complex topics and has shown superior performance on\\\\nbenchmarks.\\\\n\\\\n**4.2** **Results**\\\\n\\\\nWe run three rounds of testing on GAIA and achieved the best performance on the GAIA leaderboard, surpassing\\\\nother agent systems. Alita with Claude-Sonnet-4 and GPT-4o achieves 75.15% pass@1 and 87.27% pass@3 accuracy,\\\\nwhich is top-ranking on the GAIA benchmark validation dataset, outperforming many agent systems with far greater\\\\ncomplexity. Alita with Claude 3.7 Sonnet + GPT-4o achieves 72.73% pass@1 and 86.06% pass@3 on GAIA, and\\\\nfurther attains 74.00% and 52.00% pass@1 on the Mathvista and PathVQA benchmarks, respectively, outperforming\\\\nOctotools and Open Deep Research by smolagents. More detailed results are shown in Table 1.\\\\n\\\\nGAIA\\\\nMathvista PathVQA\\\\n**Agent** level1 level2 level3 total\\\\n\\\\n*Alita (Claude-3.7-Sonnet, GPT-4o) (%)*\\\\n\\\\npass@1 81.13 75.58 46.15 72.73 **74** **52**\\\\npass@2 88.68 80.23 53.85 78.79      -      pass@3 96.23 86.04 65.38 **86.06**      -      \\\\n*Alita (Claude-Sonnet-4, GPT-4o) (%)*\\\\n\\\\npass@1 77.36 76.74 65.38 75.15      -      pass@3 88.68 89.53 76.92 **87.27**      -      \\\\n*Baselines (%)*\\\\n\\\\nOctotools       -       -       - 18.40 68 47\\\\nODR-smolagents 67.92 53.49 34.62 55.15 65 42\\\\nAutoAgent 71.70 53.49 26.92 55.15      -      OWL 84.91 67.44 42.31 69.09    -    A-World 86.79 69.77 34.62 69.70      -      OpenAI-DR 74.29 69.06 47.60 67.36      -      \\\\nTable 1: Performance comparison of Alita and baseline agent systems on the GAIA, Mathvista, and PathVQA\\\\nbenchmarks. ODR-Smolagents refers to the Open Deep Research agent in the Smolagents framework. OpenAI-DR\\\\nrefers to OpenAI\\\\u2019s Deep Research. The table presents the accuracy at different levels of difficulty for GAIA, as well as\\\\nthe overall performance on Mathvista and PathVQA. The pass@1, pass@2, and pass@3 denote the accuracy achieved\\\\nby running the Alita framework 1, 2, and 3 times, respectively, and selecting the best answer. Alita outperforms all\\\\nbaseline agents across the GAIA levels, achieving the highest total accuracy.\\\\n\\\\n**5** **Analysis**\\\\n\\\\n**5.1** **Reuse of Alita-Generated MCPs**\\\\n\\\\n**5.1.1** **Overview**\\\\n\\\\nWe collect the MCPs generated from running the GAIA dataset using Alita in conjunction with powerful models\\\\n(Claude-3.7-Sonnet and GPT-4o). The benefits of reusing Alita-generated MCPs are **two-fold** . First, these MCPs can be\\\\nreused by other agent frameworks and improve their performance since Alita, instead of human developers, designs a\\\\nset of useful MCPs fit to GAIA by trial and error. Second, these MCPs can be reused by agents with smaller LLMs\\\\nand **significantly** improve the performance. The reuse of auto-generated MCPs for agents with smaller LLMs can be\\\\nviewed as a new way of distillation from larger LLMs. Traditionally, distillation might be fine-tuning smaller LLMs on\\\\ndata generated by larger LLMs. In comparison, the reuse of MCPs generated from agents with larger LLMs is much\\\\neasier, cheaper, and faster than traditional distillation.\\\\n\\\\n7\\\\n\\\\n**5.1.2** **Reuse by Open Deep Research-smolagents**\\\\n\\\\nWe run open Deep Research-smolagents [ 25 ] on GAIA with and without Alita-generated MCPs based on GPT-4o. The\\\\nresults are presented in Table 2. From this experiment, we observe that the reuse of Alita-generated MCPs results in\\\\nbetter performance compared to the base framework for all difficulty levels. This demonstrates that Alita can generate\\\\nvery useful MCPs, which can be provided to other agents, helping them enhance their capabilities and solve problems\\\\nthat would otherwise be unsolvable. Additionally, the consistent improvement across all difficulty levels indicates that\\\\nAlita\\\\u2019s MCPs provide generalizable utility rather than just addressing specific edge cases in the dataset.\\\\n\\\\n**Model Configuration** **Level 1** **Level 2** **Level 3** **Total**\\\\n\\\\nODR-smolagents + GPT-4o(No Alita MCPs) 33.96% 29.07% 11.54% 27.88%\\\\n\\\\nODR-smolagents + GPT-4o(With Alita MCPs) 39.62% 36.05% 15.38% **33.94%**\\\\n\\\\nTable 2: Comparison of performance between ODR-smolagents with and without Alita-generated MCPs. The results\\\\nare reported at different GAIA levels: Level 1, Level 2, Level 3, and the average. Each column corresponds to the\\\\nperformance at the respective GAIA levels. The reuse of Alita-generated MCPs can enhance the performance of other\\\\nagents.\\\\n\\\\n**5.1.3** **Reuse by Base Agent on Smaller LLM**\\\\n\\\\nWe reuse MCPs in the base framework, i.e., ODR-smolagents [ 25 ], without the MCP creation component in Alita, and\\\\nalso with some extra pre-defined tools used in ODR-smolagents based on GPT-4o-mini. The results are presented in\\\\nTable 3.\\\\n\\\\n**Model Configuration** **Level 1** **Level 2** **Level 3** **Average**\\\\n\\\\nBase Framework + GPT-4o-mini (No Alita MCP) 32.08% 20.93% 3.85% 21.82%\\\\n\\\\nBase Framework + GPT-4o-mini (With Alita MCP) 39.62% 27.91% 11.54% **29.09%**\\\\n\\\\nTable 3: Comparison of performance between the base framework on GPT-4o-mini, with and without Alita-generated\\\\nMCPs. The results are reported at different GAIA levels: Level 1, Level 2, Level 3, and the average. Each column\\\\ncorresponds to the performance at the respective GAIA levels. The reuse of Alita-generated MCPs significantly\\\\nenhances the performance of agents on smaller LLMs.\\\\n\\\\nFrom this experiment, we observe that the reuse of Alita-generated MCPs significantly improves performance over the\\\\nbase framework based on a smaller LLM. This is because the Alita-generated MCPs can be considered MCPs distilled\\\\nfrom powerful models (Claude-3.7-Sonnet), which are made available for agents on smaller LLMs. This helps bridge\\\\nthe gap between the agents on smaller LLMs and agents on larger LLMs in certain domains, thereby enhancing its\\\\ntask-processing capabilities. Especially for Level 3, we observe a particularly dramatic improvement with the accuracy\\\\ntripling from **3.85** % to **11.54** %. This substantial improvement on the most challenging problems demonstrates that\\\\nAlita-generated MCPs are especially valuable for complex reasoning tasks where agents on smaller LLMs typically\\\\nstruggle the most. The MCPs effectively encapsulate sophisticated problem-solving capabilities that the smaller model\\\\ncan leverage without needing to develop the full reasoning chain independently.\\\\n\\\\n**5.2** **Alita on Smaller LLM**\\\\n\\\\nWe hypothesize that **Alita will be even stronger with the increasing coding and reasoning capabilities of LLMs in**\\\\n**the future** . To validate our performance, we run Alita on GAIA using GPT-4o-mini instead of Claude-3.7-Sonnet. The\\\\nresults can be found in Table 4. Different to the experiment in Section 5.1.3, the agent doesn\\\\u2019t have distilled MCPs - the\\\\nagent on GPT-4o-mini model must generate its own MCPs. The results are presented in Table 4.\\\\n\\\\nFrom this experiment, on one hand, we observe that Alita, after replacing the models with GPT-4o-mini, performs\\\\nsignificantly worse on GAIA. This substantial performance gap highlights the critical role of the underlying models\\\\u2019\\\\ncoding capabilities. On the other hand, the performance of Alita increases rapidly as the capabilities of the underlying\\\\nmodels improve. We can expect that with future updates to the LLMs, Alita\\\\u2019s performance will continue to strengthen,\\\\nsurpassing its current capabilities. The design of future generalist agents might be much simpler in the future, without\\\\nany predefined tools and workflows for direct problem-solving. Instead, human developers might focus on designing\\\\nmodules for enabling and stimulating the creativity and evolution of generalist agents.\\\\n\\\\n8\\\\n\\\\n**Model Configuration** **Level 1** **Level 2** **Level 3** **Total**\\\\n\\\\nAlita (Claude-3.7-Sonnet, GPT-4o) 81.13% 75.58% 46.15% **72.73%**\\\\n\\\\nAlita (GPT-4o-mini) 54.72% 44.19% 19.23% 43.64%\\\\n\\\\nTable 4: Comparison of performance between Alita(Claude-3.7-Sonnet,GPT-4o) and Alita(GPT-4o-mini). The results\\\\nare reported at different GAIA levels: Level 1, Level 2, Level 3, and the average. Each column corresponds to the\\\\nperformance at the respective GAIA levels. The integration of a smaller model significantly reduces the performance.\\\\n\\\\n**5.3** **Case Study**\\\\n\\\\nTo investigate Alita\\\\u2019s workflow when tackling tasks, we conducted a case study on its approach to solving a Level 3\\\\ndifficult problem in GAIA. The details of this process are presented in Appendix A. From the case study, we observe\\\\nthat Alita is able to perform a structured MCP brainstorming session based on the task at hand, effectively identifying\\\\nand utilizing relevant resources to implement a feasible MCP that aids in completing the task.\\\\n\\\\n**6** **Conclusion**\\\\n\\\\nIn this work, we introduced **Alita**, a generalist agent designed with the principles of minimal predefinition and maximal\\\\nself-evolution. By significantly reducing reliance on manually predefined tools and workflows for direct solving,\\\\nAlita leverages creative, autonomous capabilities in real time, facilitating scalable agentic reasoning. Our approach\\\\ndemonstrates that simplicity in design does not undermine, but rather enhances, the performance and adaptability of\\\\ngeneralist agents.\\\\n\\\\n9\\\\n\\\\n**References**\\\\n\\\\n[1] OpenAI. Introducing deep research.\\\\n\\\\n[2] Noam Kolt. Governing ai agents. *arXiv preprint arXiv:2501.07913*, 2025.\\\\n\\\\n[3] Jian Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou, Yuandong Tian, Yanghua Xiao, and Yu Su.\\\\nTravelplanner: A benchmark for real-world planning with language agents. *arXiv preprint arXiv:2402.01622*,\\\\n2024.\\\\n\\\\n[4] Tianbao Xie, Danyang Zhang, Jixuan Chen, Xiaochuan Li, Siheng Zhao, Ruisheng Cao, Toh J Hua, Zhoujun\\\\nCheng, Dongchan Shin, Fangyu Lei, et al. Osworld: Benchmarking multimodal agents for open-ended tasks in\\\\nreal computer environments. *Advances in Neural Information Processing Systems*, 37:52040\\\\u201352094, 2024.\\\\n\\\\n[5] Hongru Wang, Rui Wang, Boyang Xue, Heming Xia, Jingtao Cao, Zeming Liu, Jeff Z. Pan, and Kam-Fai Wong.\\\\nAppBench: Planning of multiple APIs from various APPs for complex user instruction. In Yaser Al-Onaizan,\\\\nMohit Bansal, and Yun-Nung Chen, editors, *Proceedings of the 2024 Conference on Empirical Methods in Natural*\\\\n*Language Processing*, pages 15322\\\\u201315336, Miami, Florida, USA, November 2024. Association for Computational\\\\nLinguistics.\\\\n\\\\n[6] Yujia Qin, Yining Ye, Junjie Fang, Haoming Wang, Shihao Liang, Shizuo Tian, Junda Zhang, Jiahao Li, Yunxin\\\\nLi, Shijue Huang, Wanjun Zhong, Kuanye Li, Jiale Yang, Yu Miao, Woyu Lin, Longxiang Liu, Xu Jiang, Qianli\\\\nMa, Jingyu Li, Xiaojun Xiao, Kai Cai, Chuang Li, Yaowei Zheng, Chaolin Jin, Chen Li, Xiao Zhou, Minchao\\\\nWang, Haoli Chen, Zhaojian Li, Haihua Yang, Haifeng Liu, Feng Lin, Tao Peng, Xin Liu, and Guang Shi. Ui-tars:\\\\nPioneering automated gui interaction with native agents, 2025.\\\\n\\\\n[7] Junde Wu, Jiayuan Zhu, and Yuyuan Liu. Agentic reasoning: Reasoning llms with tools for the deep research.\\\\n*arXiv preprint arXiv:2502.04644*, 2025.\\\\n\\\\n[8] Mengkang Hu, Yuhang Zhou, Wendong Fan, Yuzhou Nie, Bowei Xia, Tao Sun, Ziyu Ye, Zhaoxuan Jin, Yingru\\\\nLi, Zeyu Zhang, Yifeng Wang, Qianshuo Ye, Ping Luo, and Guohao Li. Owl: Optimized workforce learning for\\\\ngeneral multi-agent assistance in real-world task automation, 2025.\\\\n\\\\n[9] Pan Lu, Bowen Chen, Sheng Liu, Rahul Thapa, Joseph Boen, and James Zou. Octotools: An agentic framework\\\\nwith extensible tools for complex reasoning. *arXiv preprint arXiv:2502.11271*, 2025.\\\\n\\\\n[10] Gr\\\\u00e9goire Mialon, Cl\\\\u00e9mentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom. Gaia: a benchmark for\\\\ngeneral ai assistants. In *The Twelfth International Conference on Learning Representations*, 2023.\\\\n\\\\n[11] Xun Jiang, Feng Li, Han Zhao, Jiaying Wang, Jun Shao, Shihao Xu, Shu Zhang, Weiling Chen, Xavier Tang, Yize\\\\nChen, et al. Long term memory: The foundation of ai self-evolution. *arXiv preprint arXiv:2410.15665*, 2024.\\\\n\\\\n[12] Agent Team at Ant Group. Aworld: A unified agent playground for computer and phone use tasks, 2025.\\\\n\\\\n[13] Adam Fourney, Gagan Bansal, Hussein Mozannar, Cheng Tan, Eduardo Salinas, Erkang, Zhu, Friederike Niedtner,\\\\nGrace Proebsting, Griffin Bassman, Jack Gerrits, Jacob Alber, Peter Chang, Ricky Loynd, Robert West, Victor\\\\nDibia, Ahmed Awadallah, Ece Kamar, Rafah Hosn, and Saleema Amershi. Magentic-one: A generalist multi-agent\\\\nsystem for solving complex tasks, 2024.\\\\n\\\\n[14] Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay, B\\\\u00f6rje F Karlsson, Jie Fu, and Yemin Shi.\\\\nAutoagents: A framework for automatic agent generation. *arXiv preprint arXiv:2309.17288*, 2023.\\\\n\\\\n[15] Xingyao Wang, Boxuan Li, Yufan Song, Frank F Xu, Xiangru Tang, Mingchen Zhuge, Jiayi Pan, Yueqi Song,\\\\nBowen Li, Jaskirat Singh, et al. Openhands: An open platform for ai software developers as generalist agents. In\\\\n*The Thirteenth International Conference on Learning Representations*, 2024.\\\\n\\\\n[16] Jiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng, Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng,\\\\nSirui Hong, Jinlin Wang, et al. Aflow: Automating agentic workflow generation. *arXiv preprint arXiv:2410.10762*,\\\\n2024.\\\\n\\\\n[17] Jiabin Tang, Tianyu Fan, and Chao Huang. Autoagent: A fully-automated and zero-code framework for llm agents.\\\\n*arXiv e-prints*, pages arXiv\\\\u20132502, 2025.\\\\n\\\\n[18] Lifan Yuan, Yangyi Chen, Xingyao Wang, Yi R Fung, Hao Peng, and Heng Ji. Craft: Customizing llms by creating\\\\nand retrieving from specialized toolsets. *arXiv preprint arXiv:2309.17428*, 2023.\\\\n\\\\n[19] Zhiruo Wang, Daniel Fried, and Graham Neubig. Trove: Inducing verifiable and efficient toolboxes for solving\\\\nprogrammatic tasks. *arXiv preprint arXiv:2401.12869*, 2024.\\\\n\\\\n[20] Cheng Qian, Chi Han, Yi R Fung, Yujia Qin, Zhiyuan Liu, and Heng Ji. Creator: Tool creation for disentangling\\\\nabstract and concrete reasoning of large language models. *arXiv preprint arXiv:2305.14318*, 2023.\\\\n\\\\n10\\\\n\\\\n[21] Tiantian Gan and Qiyao Sun. Rag-mcp: Mitigating prompt bloat in llm tool selection via retrieval-augmented\\\\ngeneration. *arXiv preprint arXiv:2505.03275*, 2025.\\\\n\\\\n[22] Fengfei Sun, Ningke Li, Kailong Wang, and Lorenz Goette. Large language models are overconfident and amplify\\\\nhuman bias. 2025.\\\\n\\\\n[23] Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chunyuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-Wei Chang,\\\\nMichel Galley, and Jianfeng Gao. Mathvista: Evaluating mathematical reasoning of foundation models in visual\\\\ncontexts. In *International Conference on Learning Representations (ICLR)*, 2024.\\\\n\\\\n[24] Xuehai He, Yichen Zhang, Luntian Mou, Eric P. Xing, and Pengtao Xie. Pathvqa: 30000+ questions for medical\\\\nvisual question answering. *ArXiv*, abs/2003.10286, 2020.\\\\n\\\\n[25] Aymeric Roucher, Albert Villanova del Moral, Thomas Wolf, Leandro von Werra, and Erik Kaunism\\\\u00e4ki. \\\\u2018smolagents\\\\u2018: a smol library to build great agentic systems. `https://github.com/huggingface/smolagents`,\\\\n2025.\\\\n\\\\n11\\\\n\\\\n**A** **Detailed Case Study**\\\\n\\\\n\\\\n\\\\n**B** **Limitations**\\\\n\\\\nAlita highly relies on the coding capability of LLM. When the LLM\\\\u2019s coding capability is really poor, our method will\\\\nperform worse than traditional generalist agent.\\\\n\\\\n12\\\\n\\\\n\\\"}\",\"annotations\":null}", "type": "function_call_output"}}
{"in_turn_steps": 0, "turn": 7, "timestamp": "2025-07-14T21:47:47.019228", "agent": "Assistant", "item_type": "message_output_item", "raw_content": {"id": "__fake_id__", "content": [{"annotations": [], "text": "现在我需要将论文下载到本地并重命名为指定格式。首先让我检查工作区目录：", "type": "output_text"}], "role": "assistant", "status": "completed", "type": "message"}}
{"in_turn_steps": 1, "turn": 7, "timestamp": "2025-07-14T21:47:47.019301", "agent": "Assistant", "item_type": "tool_call_item", "raw_content": {"arguments": "{}", "call_id": "toolu_bdrk_01At8zqBd8w6GMWbQi8NMJ5m", "name": "filesystem-list_allowed_directories", "type": "function_call", "id": "__fake_id__", "status": null}}
{"in_turn_steps": 2, "turn": 7, "timestamp": "2025-07-14T21:47:47.019323", "agent": "Assistant", "item_type": "tool_call_output_item", "raw_content": {"call_id": "toolu_bdrk_01At8zqBd8w6GMWbQi8NMJ5m", "output": "{\"type\":\"text\",\"text\":\"Allowed directories:\\n/ssddata/junlong/projects/mcpbench_finalpool_dev/recorded_trajectories_v2/run1/claude-4-sonnet-0514/finalpoolcn/SingleUserTurn-find-alita-paper/workspace\",\"annotations\":null}", "type": "function_call_output"}}
{"in_turn_steps": 0, "turn": 8, "timestamp": "2025-07-14T21:47:52.648842", "agent": "Assistant", "item_type": "message_output_item", "raw_content": {"id": "__fake_id__", "content": [{"annotations": [], "text": "现在我需要找到已下载的PDF文件并重命名。让我查看工作区目录的内容：", "type": "output_text"}], "role": "assistant", "status": "completed", "type": "message"}}
{"in_turn_steps": 1, "turn": 8, "timestamp": "2025-07-14T21:47:52.648894", "agent": "Assistant", "item_type": "tool_call_item", "raw_content": {"arguments": "{\"path\":\"/ssddata/junlong/projects/mcpbench_finalpool_dev/recorded_trajectories_v2/run1/claude-4-sonnet-0514/finalpoolcn/SingleUserTurn-find-alita-paper/workspace\"}", "call_id": "toolu_bdrk_012AvULZiq6MfAzXsNr7izW2", "name": "filesystem-list_directory", "type": "function_call", "id": "__fake_id__", "status": null}}
{"in_turn_steps": 2, "turn": 8, "timestamp": "2025-07-14T21:47:52.648917", "agent": "Assistant", "item_type": "tool_call_output_item", "raw_content": {"call_id": "toolu_bdrk_012AvULZiq6MfAzXsNr7izW2", "output": "{\"type\":\"text\",\"text\":\"[DIR] arxiv_local_storage\",\"annotations\":null}", "type": "function_call_output"}}
{"in_turn_steps": 0, "turn": 9, "timestamp": "2025-07-14T21:47:57.723403", "agent": "Assistant", "item_type": "message_output_item", "raw_content": {"id": "__fake_id__", "content": [{"annotations": [], "text": "让我查看arxiv_local_storage目录：", "type": "output_text"}], "role": "assistant", "status": "completed", "type": "message"}}
{"in_turn_steps": 1, "turn": 9, "timestamp": "2025-07-14T21:47:57.723468", "agent": "Assistant", "item_type": "tool_call_item", "raw_content": {"arguments": "{\"path\":\"/ssddata/junlong/projects/mcpbench_finalpool_dev/recorded_trajectories_v2/run1/claude-4-sonnet-0514/finalpoolcn/SingleUserTurn-find-alita-paper/workspace/arxiv_local_storage\"}", "call_id": "toolu_bdrk_01CmoErxvNp55KekoGaSJTtW", "name": "filesystem-list_directory", "type": "function_call", "id": "__fake_id__", "status": null}}
{"in_turn_steps": 2, "turn": 9, "timestamp": "2025-07-14T21:47:57.723491", "agent": "Assistant", "item_type": "tool_call_output_item", "raw_content": {"call_id": "toolu_bdrk_01CmoErxvNp55KekoGaSJTtW", "output": "{\"type\":\"text\",\"text\":\"[FILE] 2505.20286v1.md\\n[FILE] 2505.20286v1.pdf\",\"annotations\":null}", "type": "function_call_output"}}
{"in_turn_steps": 0, "turn": 10, "timestamp": "2025-07-14T21:48:08.499624", "agent": "Assistant", "item_type": "message_output_item", "raw_content": {"id": "__fake_id__", "content": [{"annotations": [], "text": "太好了！PDF文件已经下载了。现在我需要将其重命名为`alita_2505.20286v1.pdf`：", "type": "output_text"}], "role": "assistant", "status": "completed", "type": "message"}}
{"in_turn_steps": 1, "turn": 10, "timestamp": "2025-07-14T21:48:08.499683", "agent": "Assistant", "item_type": "tool_call_item", "raw_content": {"arguments": "{\"destination\":\"/ssddata/junlong/projects/mcpbench_finalpool_dev/recorded_trajectories_v2/run1/claude-4-sonnet-0514/finalpoolcn/SingleUserTurn-find-alita-paper/workspace/alita_2505.20286v1.pdf\",\"source\":\"/ssddata/junlong/projects/mcpbench_finalpool_dev/recorded_trajectories_v2/run1/claude-4-sonnet-0514/finalpoolcn/SingleUserTurn-find-alita-paper/workspace/arxiv_local_storage/2505.20286v1.pdf\"}", "call_id": "toolu_bdrk_01799EzqNtKYYVrEWAZ1G5a6", "name": "filesystem-move_file", "type": "function_call", "id": "__fake_id__", "status": null}}
{"in_turn_steps": 2, "turn": 10, "timestamp": "2025-07-14T21:48:08.499706", "agent": "Assistant", "item_type": "tool_call_output_item", "raw_content": {"call_id": "toolu_bdrk_01799EzqNtKYYVrEWAZ1G5a6", "output": "{\"type\":\"text\",\"text\":\"Successfully moved /ssddata/junlong/projects/mcpbench_finalpool_dev/recorded_trajectories_v2/run1/claude-4-sonnet-0514/finalpoolcn/SingleUserTurn-find-alita-paper/workspace/arxiv_local_storage/2505.20286v1.pdf to /ssddata/junlong/projects/mcpbench_finalpool_dev/recorded_trajectories_v2/run1/claude-4-sonnet-0514/finalpoolcn/SingleUserTurn-find-alita-paper/workspace/alita_2505.20286v1.pdf\",\"annotations\":null}", "type": "function_call_output"}}
{"in_turn_steps": 0, "turn": 11, "timestamp": "2025-07-14T21:48:20.418753", "agent": "Assistant", "item_type": "message_output_item", "raw_content": {"id": "__fake_id__", "content": [{"annotations": [], "text": "完美！现在根据论文内容，我可以提供您要求的信息。从论文内容中我看到代码仓库链接是 https://github.com/CharlesQ9/Alita。\n\ntitle: Alita: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self-Evolution\narxiv_abs_url: https://arxiv.org/abs/2505.20286\ncode_url: https://github.com/CharlesQ9/Alita", "type": "output_text"}], "role": "assistant", "status": "completed", "type": "message"}}
