{"kind": "ObservationEvent", "id": "612d139f-d357-4636-86d0-ae327c975420", "timestamp": "2025-10-06T11:51:15.174228", "source": "environment", "tool_name": "fetch_fetch_markdown", "tool_call_id": "toolu_bdrk_015HH1v7ccSPVpbL2WoWCg6X", "observation": {"kind": "MCPToolObservation", "content": [{"cache_prompt": false, "type": "text", "text": "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models | OpenReview\n\nToggle navigation[**OpenReview**.net](/)\n\n*   [Login](/login)\n\n\u00d7\n\n(self.\\_\\_next\\_s=self.\\_\\_next\\_s||\\[\\]).push(\\[\"https://challenges.cloudflare.com/turnstile/v0/api.js\",{}\\])\n\n[![back arrow](/images/arrow_left.svg)Go to **ICLR 2024 Conference** homepage](/group?id=ICLR.cc/2024/Conference \"Venue Homepage\")\n\nScaling Relationship on Learning Mathematical Reasoning with Large Language Models\n----------------------------------------------------------------------------------\n\n[![Download PDF](/images/pdf_icon_blue.svg)](/pdf?id=cijO0f8u35 \"Download PDF\")\n\n### [Zheng Yuan](/profile?id=~Zheng_Yuan2 \"~Zheng_Yuan2\"), [Hongyi Yuan](/profile?id=~Hongyi_Yuan1 \"~Hongyi_Yuan1\"), [Chengpeng Li](/profile?id=~Chengpeng_Li1 \"~Chengpeng_Li1\"), [Guanting Dong](/profile?id=~Guanting_Dong1 \"~Guanting_Dong1\"), [Keming Lu](/profile?id=~Keming_Lu1 \"~Keming_Lu1\"), [Chuanqi Tan](/profile?id=~Chuanqi_Tan3 \"~Chuanqi_Tan3\"), [Chang Zhou](/profile?id=~Chang_Zhou2 \"~Chang_Zhou2\"), [Jingren Zhou](/profile?id=~Jingren_Zhou1 \"~Jingren_Zhou1\")\n\n18 Sept 2023 (modified: 11 Feb 2024)Submitted to ICLR 2024Everyone[Revisions](/revisions?id=cijO0f8u35)[BibTeX](#)\n\n**Primary Area:** representation learning for computer vision, audio, language, and other modalities\n\n**Code Of Ethics:** I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.\n\n**Keywords:** Mathematical Reasoning, Scaling Relationship, Large Language Model\n\n**Submission Guidelines:** I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.\n\n**Abstract:** Mathematical reasoning is a challenging task for large language models (LLMs), while the scaling relationship of it with respect to LLM capacity is under-explored. In this paper, we investigate how the pre-training loss, supervised data amount, and augmented data amount influence the reasoning performances of a supervised LLM. We find that pre-training loss is a better indicator of the model's performance than the model's parameter count. We apply supervised fine-tuning (SFT) with different amounts of supervised data and empirically find a log-linear relation between data amount and model performance, and we find better models improve less with enlarged supervised datasets. To augment more data samples for improving model performances without any human effort, we propose to apply Rejection sampling Fine-Tuning (RFT). RFT uses supervised models to generate and collect correct reasoning paths as augmented fine-tuning datasets. We find with augmented samples containing more distinct reasoning paths, RFT improves mathematical reasoning performance more for LLMs. We also find RFT brings more improvement for less performant LLMs. Furthermore, we combine rejection samples from multiple models which push LLaMA-7B to an accuracy of 49.3\\\\% on GSM8K which outperforms the supervised fine-tuning (SFT) accuracy of 35.9\\\\% significantly.\n\n**Anonymous Url:** I certify that there is no URL (e.g., github page) that could be used to find authors' identity.\n\n**Supplementary Material:** [zip](/attachment?id=cijO0f8u35&name=supplementary_material \"Download Supplementary Material\")\n\n**No Acknowledgement Section:** I certify that there is no acknowledgement section in this submission for double blind review.\n\n**Submission Number:** 1254\n\nLoading\n\n*   [About OpenReview](/about)\n*   [Hosting a Venue](/group?id=OpenReview.net/Support)\n*   [All Venues](/venues)\n\n*   [Contact](/contact)\n*   [Sponsors](/sponsors)\n*   [**Donate**](https://donate.stripe.com/eVqdR8fP48bK1R61fi0oM00)\n\n*   [Frequently Asked Questions](https://docs.openreview.net/getting-started/frequently-asked-questions)\n*   [Terms of Use](/legal/terms)\n*   [Privacy Policy](/legal/privacy)\n\n*   [About OpenReview](/about)\n*   [Hosting a Venue](/group?id=OpenReview.net/Support)\n*   [All Venues](/venues)\n*   [Sponsors](/sponsors)\n\n*   [Frequently Asked Questions](https://docs.openreview.net/getting-started/frequently-asked-questions)\n*   [Contact](/contact)\n*   [**Donate**](https://donate.stripe.com/eVqdR8fP48bK1R61fi0oM00)\n*   [Terms of Use](/legal/terms)\n*   [Privacy Policy](/legal/privacy)\n\n[OpenReview](/about) is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the [OpenReview Sponsors](/sponsors). \u00a9 2025 OpenReview\n\n(self.\\_\\_next\\_f=self.\\_\\_next\\_f||\\[\\]).push(\\[0\\])self.\\_\\_next\\_f.push(\\[1,\"1:\\\\\"$Sreact.fragment\\\\\"\\\\n2:I\\[64818,\\[\\\\\"4935\\\\\",\\\\\"static/chunks/e37a0b60-86dcf540460bd9a6.js\\\\\",\\\\\"3740\\\\\",\\\\\"static/chunks/7ce798d6-3eb8122476a3f2e5.js\\\\\",\\\\\"6874\\\\\",\\\\\"static/chunks/6874-b5228efe8b8455fa.js\\\\\",\\\\\"3697\\\\\",\\\\\"static/chunks/3697-c0092b2c69fd8d8c.js\\\\\",\\\\\"1141\\\\\",\\\\\"static/chunks/1141-fb44a30f239c6063.js\\\\\",\\\\\"4540\\\\\",\\\\\"static/chunks/4540-d4d9759f532dbe01.js\\\\\",\\\\\"6325\\\\\",\\\\\"static/chunks/6325-93a1b42c84bba41c.js\\\\\",\\\\\"1990\\\\\",\\\\\"static/chunks/1990-a202dc60dde3ccdf.js\\\\\",\\\\\"9353\\\\\",\\\\\"static/chunks/9353-dde6849b3fe442fa.js\\\\\",\\\\\"7370\\\\\",\\\\\"static/chunks/7370-1df77422f0c6dcbf.js\\\\\",\\\\\"9433\\\\\",\\\\\"static/chunks/9433-2895bfe8ab854f41.js\\\\\",\\\\\"7177\\\\\",\\\\\"static/chunks/app/layout-916462f9a8993d1c.js\\\\\"\\],\\\\\"default\\\\\"\\]\\\\n3:I\\[6874,\\[\\\\\"4935\\\\\",\\\\\"static/chunks/e37a0b60-86dcf540460bd9a6.js\\\\\",\\\\\"6874\\\\\",\\\\\"static/chunks/6874-b5228efe8b8455fa.js\\\\\",\\\\\"3697\\\\\",\\\\\"static/chunks/3697-c0092b2c69fd8d8c.js\\\\\",\\\\\"1141\\\\\",\\\\\"static/chunks/1141-fb44a30f239c6063.js\\\\\",\\\\\"4540\\\\\",\\\\\"static/chunks/4540-d4d9759f532dbe01.js\\\\\",\\\\\"6846\\\\\",\\\\\"static/chunks/6846-e00ebe4cf4673031.js\\\\\",\\\\\"1592\\\\\",\\\\\"static/chunks/1592-be14089f9df98c98.js\\\\\",\\\\\"6325\\\\\",\\\\\"static/chunks/6325-93a1b42c84bba41c.js\\\\\",\\\\\"9032\\\\\",\\\\\"static/chunks/9032-c4156b261f2c50b7.js\\\\\",\\\\\"6504\\\\\",\\\\\"static/chunks/6504-00ef5b949820536b.js\\\\\",\\\\\"3882\\\\\",\\\\\"static/chunks/3882-68311d71c6e6d2c2.js\\\\\",\\\\\"9433\\\\\",\\\\\"static/chunks/9433-2895bfe8ab854f41.js\\\\\",\\\\\"2882\\\\\",\\\\\"static/chunks/2882-44eb1c7e8844e014.js\\\\\",\\\\\"4745\\\\\",\\\\\"static/chunks/4745-b7bef6bfd1f2ca78.js\\\\\",\\\\\"1399\\\\\",\\\\\"static/chunks/1399-1fff5e65c29b20ed.js\\\\\",\\\\\"4757\\\\\",\\\\\"static/chunks/4757-809c6800572665a9.js\\\\\",\\\\\"3474\\\\\",\\\\\"static/chunks/3474-b41b675fe285039e.js\\\\\",\\\\\"5262\\\\\",\\\\\"static/chunks/5262-c565f8d56db6f340.js\\\\\",\\\\\"5300\\\\\",\\\\\"static/chunks/app/forum/page-e528e5f0f4f935b7.js\\\\\"\\],\\\\\"\\\\\"\\]\\\\n4:I\\[41316,\\[\\\\\"4935\\\\\",\\\\\"static/chunks/e37a0b60-86dcf540460bd9a6.js\\\\\",\\\\\"3740\\\\\",\\\\\"static/chunks/7ce798d6-3eb8122476a3f2e5.js\\\\\",\\\\\"6874\\\\\",\\\\\"static/chunks/6874-b5228efe8b8455fa.js\\\\\",\\\\\"3697\\\\\",\\\\\"static/chunks/3697-c0092b2c69fd8d8c.js\\\\\",\\\\\"1141\\\\\",\\\\\"static/chunks/1141-fb44a30f239c6063.js\\\\\",\\\\\"4540\\\\\",\\\\\"static/chunks/4540-d4d9759f532dbe01.js\\\\\",\\\\\"6325\\\\\",\\\\\"static/chunks/6325-93a1b42c84bba41c.js\\\\\",\\\\\"1990\\\\\",\\\\\"static/chunks/1990-a202dc60dde3ccdf.js\\\\\",\\\\\"9353\\\\\",\\\\\"static/chunks/9353-dde6849b3fe442fa.js\\\\\",\\\\\"7370\\\\\",\\\\\"static/chunks/\"\\])self.\\_\\_next\\_f.push(\\[1,\"7370-1df77422f0c6dcbf.js\\\\\",\\\\\"9433\\\\\",\\\\\"static/chunks/9433-2895bfe8ab854f41.js\\\\\",\\\\\"7177\\\\\",\\\\\"static/chunks/app/layout-916462f9a8993d1c.js\\\\\"\\],\\\\\"default\\\\\"\\]\\\\n6:I\\[33977,\\[\\\\\"4935\\\\\",\\\\\"static/chunks/e37a0b60-86dcf540460bd9a6.js\\\\\",\\\\\"3740\\\\\",\\\\\"static/chunks/7ce798d6-3eb8122476a3f2e5.js\\\\\",\\\\\"6874\\\\\",\\\\\"static/chunks/6874-b5228efe8b8455fa.js\\\\\",\\\\\"3697\\\\\",\\\\\"static/chunks/3697-c0092b2c69fd8d8c.js\\\\\",\\\\\"1141\\\\\",\\\\\"static/chunks/1141-fb44a30f239c6063.js\\\\\",\\\\\"4540\\\\\",\\\\\"static/chunks/4540-d4d9759f532dbe01.js\\\\\",\\\\\"6325\\\\\",\\\\\"static/chunks/6325-93a1b42c84bba41c.js\\\\\",\\\\\"1990\\\\\",\\\\\"static/chunks/1990-a202dc60dde3ccdf.js\\\\\",\\\\\"9353\\\\\",\\\\\"static/chunks/9353-dde6849b3fe442fa.js\\\\\",\\\\\"7370\\\\\",\\\\\"static/chunks/7370-1df77422f0c6dcbf.js\\\\\",\\\\\"9433\\\\\",\\\\\"static/chunks/9433-2895bfe8ab854f41.js\\\\\",\\\\\"7177\\\\\",\\\\\"static/chunks/app/layout-916462f9a8993d1c.js\\\\\"\\],\\\\\"default\\\\\"\\]\\\\n7:I\\[87555,\\[\\],\\\\\"\\\\\"\\]\\\\n8:I\\[31702,\\[\\\\\"6874\\\\\",\\\\\"static/chunks/6874-b5228efe8b8455fa.js\\\\\",\\\\\"3697\\\\\",\\\\\"static/chunks/3697-c0092b2c69fd8d8c.js\\\\\",\\\\\"1141\\\\\",\\\\\"static/chunks/1141-fb44a30f239c6063.js\\\\\",\\\\\"4540\\\\\",\\\\\"static/chunks/4540-d4d9759f532dbe01.js\\\\\",\\\\\"6325\\\\\",\\\\\"static/chunks/6325-93a1b42c84bba41c.js\\\\\",\\\\\"9433\\\\\",\\\\\"static/chunks/9433-2895bfe8ab854f41.js\\\\\",\\\\\"4757\\\\\",\\\\\"static/chunks/4757-809c6800572665a9.js\\\\\",\\\\\"8039\\\\\",\\\\\"static/chunks/app/error-ac9fc3fd38a040ee.js\\\\\"\\],\\\\\"default\\\\\"\\]\\\\n9:I\\[31295,\\[\\],\\\\\"\\\\\"\\]\\\\na:I\\[64757,\\[\\\\\"4935\\\\\",\\\\\"static/chunks/e37a0b60-86dcf540460bd9a6.js\\\\\",\\\\\"6874\\\\\",\\\\\"static/chunks/6874-b5228efe8b8455fa.js\\\\\",\\\\\"3697\\\\\",\\\\\"static/chunks/3697-c0092b2c69fd8d8c.js\\\\\",\\\\\"1141\\\\\",\\\\\"static/chunks/1141-fb44a30f239c6063.js\\\\\",\\\\\"4540\\\\\",\\\\\"static/chunks/4540-d4d9759f532dbe01.js\\\\\",\\\\\"6846\\\\\",\\\\\"static/chunks/6846-e00ebe4cf4673031.js\\\\\",\\\\\"1592\\\\\",\\\\\"static/chunks/1592-be14089f9df98c98.js\\\\\",\\\\\"6325\\\\\",\\\\\"static/chunks/6325-93a1b42c84bba41c.js\\\\\",\\\\\"9032\\\\\",\\\\\"static/chunks/9032-c4156b261f2c50b7.js\\\\\",\\\\\"6504\\\\\",\\\\\"static/chunks/6504-00ef5b949820536b.js\\\\\",\\\\\"3882\\\\\",\\\\\"static/chunks/3882-68311d71c6e6d2c2.js\\\\\",\\\\\"9433\\\\\",\\\\\"static/chunks/9433-2895bfe8ab854f41.js\\\\\",\\\\\"2882\\\\\",\\\\\"static/chunks/2882-44eb1c7e8844e014.js\\\\\",\\\\\"4745\\\\\",\\\\\"static/chunks/4745-b7bef6bfd1f2ca78.js\\\\\",\\\\\"1399\\\\\",\\\\\"static/chunks/1399-1fff5e65c29b20ed.js\\\\\",\\\\\"4757\\\\\",\\\\\"static/chunks/4757-809c6800572665a9.js\\\\\",\\\\\"3474\\\\\",\\\\\"static/chunks/3474-b41b675fe285039e.js\\\\\",\\\\\"5262\\\\\",\\\\\"static/chu\"\\])self.\\_\\_next\\_f.push(\\[1,\"nks/5262-c565f8d56db6f340.js\\\\\",\\\\\"5300\\\\\",\\\\\"static/chunks/app/forum/page-e528e5f0f4f935b7.js\\\\\"\\],\\\\\"default\\\\\"\\]\\\\nb:I\\[69243,\\[\\\\\"4935\\\\\",\\\\\"static/chunks/e37a0b60-86dcf540460bd9a6.js\\\\\",\\\\\"3740\\\\\",\\\\\"static/chunks/7ce798d6-3eb8122476a3f2e5.js\\\\\",\\\\\"6874\\\\\",\\\\\"static/chunks/6874-b5228efe8b8455fa.js\\\\\",\\\\\"3697\\\\\",\\\\\"static/chunks/3697-c0092b2c69fd8d8c.js\\\\\",\\\\\"1141\\\\\",\\\\\"static/chunks/1141-fb44a30f239c6063.js\\\\\",\\\\\"4540\\\\\",\\\\\"static/chunks/4540-d4d9759f532dbe01.js\\\\\",\\\\\"6325\\\\\",\\\\\"static/chunks/6325-93a1b42c84bba41c.js\\\\\",\\\\\"1990\\\\\",\\\\\"static/chunks/1990-a202dc60dde3ccdf.js\\\\\",\\\\\"9353\\\\\",\\\\\"static/chunks/9353-dde6849b3fe442fa.js\\\\\",\\\\\"7370\\\\\",\\\\\"static/chunks/7370-1df77422f0c6dcbf.js\\\\\",\\\\\"9433\\\\\",\\\\\"static/chunks/9433-2895bfe8ab854f41.js\\\\\",\\\\\"7177\\\\\",\\\\\"static/chunks/app/layout-916462f9a8993d1c.js\\\\\"\\],\\\\\"\\\\\"\\]\\\\nd:I\\[59665,\\[\\],\\\\\"OutletBoundary\\\\\"\\]\\\\n10:I\\[59665,\\[\\],\\\\\"ViewportBoundary\\\\\"\\]\\\\n12:I\\[59665,\\[\\],\\\\\"MetadataBoundary\\\\\"\\]\\\\n14:I\\[89340,\\[\\\\\"6874\\\\\",\\\\\"static/chunks/6874-b5228efe8b8455fa.js\\\\\",\\\\\"4219\\\\\",\\\\\"static/chunks/app/global-error-f023f9ed1562f572.js\\\\\"\\],\\\\\"default\\\\\"\\]\\\\n:HL\\[\\\\\"/\\_next/static/media/1755441e3a2fa970-s.p.woff2\\\\\",\\\\\"font\\\\\",{\\\\\"crossOrigin\\\\\":\\\\\"\\\\\",\\\\\"type\\\\\":\\\\\"font/woff2\\\\\"}\\]\\\\n:HL\\[\\\\\"/\\_next/static/media/f8783467cccb7b8a-s.p.woff2\\\\\",\\\\\"font\\\\\",{\\\\\"crossOrigin\\\\\":\\\\\"\\\\\",\\\\\"type\\\\\":\\\\\"font/woff2\\\\\"}\\]\\\\n:HL\\[\\\\\"/\\_next/static/css/623ec4d945fb0950.css\\\\\",\\\\\"style\\\\\"\\]\\\\n:HL\\[\\\\\"/\\_next/static/css/7efbc204b5b07ee6.css\\\\\",\\\\\"style\\\\\"\\]\\\\n:HL\\[\\\\\"/\\_next/static/css/01fe169d2e2b269f.css\\\\\",\\\\\"style\\\\\"\\]\\\\n:HL\\[\\\\\"/\\_next/static/css/615a8b855b6a8b37.css\\\\\",\\\\\"style\\\\\"\\]\\\\n:HL\\[\\\\\"/\\_next/static/css/db97134c9c085326.css\\\\\",\\\\\"style\\\\\"\\]\\\\n:HL\\[\\\\\"/\\_next/static/css/3ca9945321ffa69b.css\\\\\",\\\\\"style\\\\\"\\]\\\\n\"\\])self.\\_\\_next\\_f.push(\\[1,\"0:{\\\\\"P\\\\\":null,\\\\\"b\\\\\":\\\\\"v1.14.24\\\\\",\\\\\"p\\\\\":\\\\\"\\\\\",\\\\\"c\\\\\":\\[\\\\\"\\\\\",\\\\\"forum?id=cijO0f8u35\\\\\"\\],\\\\\"i\\\\\":false,\\\\\"f\\\\\":\\[\\[\\[\\\\\"\\\\\",{\\\\\"children\\\\\":\\[\\\\\"forum\\\\\",{\\\\\"children\\\\\":\\[\\\\\"\\_\\_PAGE\\_\\_?{\\\\\\\\\\\\\"id\\\\\\\\\\\\\":\\\\\\\\\\\\\"cijO0f8u35\\\\\\\\\\\\\"}\\\\\",{}\\]}\\]},\\\\\"$undefined\\\\\",\\\\\"$undefined\\\\\",true\\],\\[\\\\\"\\\\\",\\[\\\\\"$\\\\\",\\\\\"$1\\\\\",\\\\\"c\\\\\",{\\\\\"children\\\\\":\\[\\[\\[\\\\\"$\\\\\",\\\\\"link\\\\\",\\\\\"0\\\\\",{\\\\\"rel\\\\\":\\\\\"stylesheet\\\\\",\\\\\"href\\\\\":\\\\\"/\\_next/static/css/623ec4d945fb0950.css\\\\\",\\\\\"precedence\\\\\":\\\\\"next\\\\\",\\\\\"crossOrigin\\\\\":\\\\\"$undefined\\\\\",\\\\\"nonce\\\\\":\\\\\"$undefined\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"link\\\\\",\\\\\"1\\\\\",{\\\\\"rel\\\\\":\\\\\"stylesheet\\\\\",\\\\\"href\\\\\":\\\\\"/\\_next/static/css/7efbc204b5b07ee6.css\\\\\",\\\\\"precedence\\\\\":\\\\\"next\\\\\",\\\\\"crossOrigin\\\\\":\\\\\"$undefined\\\\\",\\\\\"nonce\\\\\":\\\\\"$undefined\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"link\\\\\",\\\\\"2\\\\\",{\\\\\"rel\\\\\":\\\\\"stylesheet\\\\\",\\\\\"href\\\\\":\\\\\"/\\_next/static/css/01fe169d2e2b269f.css\\\\\",\\\\\"precedence\\\\\":\\\\\"next\\\\\",\\\\\"crossOrigin\\\\\":\\\\\"$undefined\\\\\",\\\\\"nonce\\\\\":\\\\\"$undefined\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"link\\\\\",\\\\\"3\\\\\",{\\\\\"rel\\\\\":\\\\\"stylesheet\\\\\",\\\\\"href\\\\\":\\\\\"/\\_next/static/css/615a8b855b6a8b37.css\\\\\",\\\\\"precedence\\\\\":\\\\\"next\\\\\",\\\\\"crossOrigin\\\\\":\\\\\"$undefined\\\\\",\\\\\"nonce\\\\\":\\\\\"$undefined\\\\\"}\\]\\],\\[\\\\\"$\\\\\",\\\\\"html\\\\\",null,{\\\\\"lang\\\\\":\\\\\"en\\\\\",\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"head\\\\\",null,{\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"link\\\\\",null,{\\\\\"rel\\\\\":\\\\\"icon\\\\\",\\\\\"href\\\\\":\\\\\"/favicon.ico\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"link\\\\\",null,{\\\\\"rel\\\\\":\\\\\"manifest\\\\\",\\\\\"href\\\\\":\\\\\"/manifest.json\\\\\"}\\]\\]}\\],\\[\\\\\"$\\\\\",\\\\\"$L2\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"body\\\\\",null,{\\\\\"className\\\\\":\\\\\"\\_\\_className\\_006ac8\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"id\\\\\":\\\\\"\\_\\_next\\\\\",\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"nav\\\\\",null,{\\\\\"className\\\\\":\\\\\"navbar navbar-inverse\\\\\",\\\\\"role\\\\\":\\\\\"navigation\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"container\\\\\",\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"navbar-header\\\\\",\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"button\\\\\",null,{\\\\\"type\\\\\":\\\\\"button\\\\\",\\\\\"className\\\\\":\\\\\"navbar-toggle collapsed\\\\\",\\\\\"data-toggle\\\\\":\\\\\"collapse\\\\\",\\\\\"data-target\\\\\":\\\\\"#navbar\\\\\",\\\\\"aria-expanded\\\\\":\\\\\"false\\\\\",\\\\\"aria-controls\\\\\":\\\\\"navbar\\\\\",\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"span\\\\\",null,{\\\\\"className\\\\\":\\\\\"sr-only\\\\\",\\\\\"children\\\\\":\\\\\"Toggle navigation\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"span\\\\\",null,{\\\\\"className\\\\\":\\\\\"icon-bar\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"span\\\\\",null,{\\\\\"className\\\\\":\\\\\"icon-bar\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"span\\\\\",null,{\\\\\"className\\\\\":\\\\\"icon-bar\\\\\"}\\]\\]}\\],\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"/\\\\\",\\\\\"className\\\\\":\\\\\"navbar-brand home push-link\\\\\",\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"strong\\\\\",null,{\\\\\"children\\\\\":\\\\\"OpenReview\\\\\"}\\],\\\\\".net\\\\\"\\]}\\]\\]}\\],\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"id\\\\\":\\\\\"navbar\\\\\",\\\\\"className\\\\\":\\\\\"navbar-collapse collapse\\\\\",\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"$L4\\\\\",null,{}\\],\\\\\"$L5\\\\\"\\]}\\]\\]}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"id\\\\\":\\\\\"flash-message-container\\\\\",\\\\\"className\\\\\":\\\\\"alert alert-danger fixed-overlay\\\\\",\\\\\"role\\\\\":\\\\\"alert\\\\\",\\\\\"style\\\\\":{\\\\\"display\\\\\":\\\\\"none\\\\\"},\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"container\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"row\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"col-xs-12\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"alert-content\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"button\\\\\",null,{\\\\\"type\\\\\":\\\\\"button\\\\\",\\\\\"className\\\\\":\\\\\"close\\\\\",\\\\\"aria-label\\\\\":\\\\\"Close\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"span\\\\\",null,{\\\\\"aria-hidden\\\\\":\\\\\"true\\\\\",\\\\\"children\\\\\":\\\\\"\u00d7\\\\\"}\\]}\\]}\\]}\\]}\\]}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"$L6\\\\\",null,{}\\],\\[\\\\\"$\\\\\",\\\\\"$L7\\\\\",null,{\\\\\"parallelRouterKey\\\\\":\\\\\"children\\\\\",\\\\\"error\\\\\":\\\\\"$8\\\\\",\\\\\"errorStyles\\\\\":\\[\\],\\\\\"errorScripts\\\\\":\\[\\],\\\\\"template\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L9\\\\\",null,{}\\],\\\\\"templateStyles\\\\\":\\\\\"$undefined\\\\\",\\\\\"templateScripts\\\\\":\\\\\"$undefined\\\\\",\\\\\"notFound\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"$La\\\\\",null,{\\\\\"statusCode\\\\\":404,\\\\\"message\\\\\":\\\\\"Please check that the URL is spelled correctly and try again.\\\\\"}\\],\\[\\]\\],\\\\\"forbidden\\\\\":\\\\\"$undefined\\\\\",\\\\\"unauthorized\\\\\":\\\\\"$undefined\\\\\"}\\]\\]}\\]}\\]}\\],\\[\\[\\\\\"$\\\\\",\\\\\"$Lb\\\\\",null,{\\\\\"src\\\\\":\\\\\"https://www.googletagmanager.com/gtag/js?id=G-GTB25PBMVL\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"$Lb\\\\\",null,{\\\\\"id\\\\\":\\\\\"ga-script\\\\\",\\\\\"dangerouslySetInnerHTML\\\\\":{\\\\\"\\_\\_html\\\\\":\\\\\"window.dataLayer = window.dataLayer || \\[\\];\\\\\\\\nfunction gtag() { dataLayer.push(arguments); }\\\\\\\\ngtag('js', new Date());\\\\\\\\ngtag('config', 'G-GTB25PBMVL', {\\\\\\\\npage\\_location: location.origin + location.pathname + location.search,\\\\\\\\n});\\\\\"}}\\]\\]\\]}\\]\\]}\\],{\\\\\"children\\\\\":\\[\\\\\"forum\\\\\",\\[\\\\\"$\\\\\",\\\\\"$1\\\\\",\\\\\"c\\\\\",{\\\\\"children\\\\\":\\[null,\\[\\\\\"$\\\\\",\\\\\"$L7\\\\\",null,{\\\\\"parallelRouterKey\\\\\":\\\\\"children\\\\\",\\\\\"error\\\\\":\\\\\"$undefined\\\\\",\\\\\"errorStyles\\\\\":\\\\\"$undefined\\\\\",\\\\\"errorScripts\\\\\":\\\\\"$undefined\\\\\",\\\\\"template\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L9\\\\\",null,{}\\],\\\\\"templateStyles\\\\\":\\\\\"$undefined\\\\\",\\\\\"templateScripts\\\\\":\\\\\"$undefined\\\\\",\\\\\"notFound\\\\\":\\\\\"$undefined\\\\\",\\\\\"forbidden\\\\\":\\\\\"$undefined\\\\\",\\\\\"unauthorized\\\\\":\\\\\"$undefined\\\\\"}\\]\\]}\\],{\\\\\"children\\\\\":\\[\\\\\"\\_\\_PAGE\\_\\_\\\\\",\\[\\\\\"$\\\\\",\\\\\"$1\\\\\",\\\\\"c\\\\\",{\\\\\"children\\\\\":\\[\\\\\"$Lc\\\\\",\\\\\"$undefined\\\\\",\\[\\[\\\\\"$\\\\\",\\\\\"link\\\\\",\\\\\"0\\\\\",{\\\\\"rel\\\\\":\\\\\"stylesheet\\\\\",\\\\\"href\\\\\":\\\\\"/\\_next/static/css/db97134c9c085326.css\\\\\",\\\\\"precedence\\\\\":\\\\\"next\\\\\",\\\\\"crossOrigin\\\\\":\\\\\"$undefined\\\\\",\\\\\"nonce\\\\\":\\\\\"$undefined\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"link\\\\\",\\\\\"1\\\\\",{\\\\\"rel\\\\\":\\\\\"stylesheet\\\\\",\\\\\"href\\\\\":\\\\\"/\\_next/static/css/3ca9945321ffa69b.css\\\\\",\\\\\"precedence\\\\\":\\\\\"next\\\\\",\\\\\"crossOrigin\\\\\":\\\\\"$undefined\\\\\",\\\\\"nonce\\\\\":\\\\\"$undefined\\\\\"}\\]\\],\\[\\\\\"$\\\\\",\\\\\"$Ld\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$Le\\\\\",\\\\\"$Lf\\\\\",null\\]}\\]\\]}\\],{},null,false\\]},null,false\\]},null,false\\],\\[\\\\\"$\\\\\",\\\\\"$1\\\\\",\\\\\"h\\\\\",{\\\\\"children\\\\\":\\[null,\\[\\\\\"$\\\\\",\\\\\"$1\\\\\",\\\\\"e6YD0Xf3OPcn5K7rNDzUT\\\\\",{\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"$L10\\\\\",null,{\\\\\"children\\\\\":\\\\\"$L11\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",null,{\\\\\"name\\\\\":\\\\\"next-size-adjust\\\\\",\\\\\"content\\\\\":\\\\\"\\\\\"}\\]\\]}\\],\\[\\\\\"$\\\\\",\\\\\"$L12\\\\\",null,{\\\\\"children\\\\\":\\\\\"$L13\\\\\"}\\]\\]}\\],false\\]\\],\\\\\"m\\\\\":\\\\\"$undefined\\\\\",\\\\\"G\\\\\":\\[\\\\\"$14\\\\\",\\[\\]\\],\\\\\"s\\\\\":false,\\\\\"S\\\\\":false}\\\\n\"\\])self.\\_\\_next\\_f.push(\\[1,\"5:\\[\\\\\"$\\\\\",\\\\\"ul\\\\\",null,{\\\\\"className\\\\\":\\\\\"nav navbar-nav navbar-right\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"id\\\\\":\\\\\"user-menu\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"/login\\\\\",\\\\\"children\\\\\":\\\\\"Login\\\\\"}\\]}\\]}\\]\\\\n11:\\[\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"0\\\\\",{\\\\\"charSet\\\\\":\\\\\"utf-8\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"1\\\\\",{\\\\\"name\\\\\":\\\\\"viewport\\\\\",\\\\\"content\\\\\":\\\\\"width=device-width, initial-scale=1\\\\\"}\\]\\]\\\\ne:null\\\\n\"\\])self.\\_\\_next\\_f.push(\\[1,\"15:I\\[39677,\\[\\\\\"4935\\\\\",\\\\\"static/chunks/e37a0b60-86dcf540460bd9a6.js\\\\\",\\\\\"6874\\\\\",\\\\\"static/chunks/6874-b5228efe8b8455fa.js\\\\\",\\\\\"3697\\\\\",\\\\\"static/chunks/3697-c0092b2c69fd8d8c.js\\\\\",\\\\\"1141\\\\\",\\\\\"static/chunks/1141-fb44a30f239c6063.js\\\\\",\\\\\"4540\\\\\",\\\\\"static/chunks/4540-d4d9759f532dbe01.js\\\\\",\\\\\"6846\\\\\",\\\\\"static/chunks/6846-e00ebe4cf4673031.js\\\\\",\\\\\"1592\\\\\",\\\\\"static/chunks/1592-be14089f9df98c98.js\\\\\",\\\\\"6325\\\\\",\\\\\"static/chunks/6325-93a1b42c84bba41c.js\\\\\",\\\\\"9032\\\\\",\\\\\"static/chunks/9032-c4156b261f2c50b7.js\\\\\",\\\\\"6504\\\\\",\\\\\"static/chunks/6504-00ef5b949820536b.js\\\\\",\\\\\"3882\\\\\",\\\\\"static/chunks/3882-68311d71c6e6d2c2.js\\\\\",\\\\\"9433\\\\\",\\\\\"static/chunks/9433-2895bfe8ab854f41.js\\\\\",\\\\\"2882\\\\\",\\\\\"static/chunks/2882-44eb1c7e8844e014.js\\\\\",\\\\\"4745\\\\\",\\\\\"static/chunks/4745-b7bef6bfd1f2ca78.js\\\\\",\\\\\"1399\\\\\",\\\\\"static/chunks/1399-1fff5e65c29b20ed.js\\\\\",\\\\\"4757\\\\\",\\\\\"static/chunks/4757-809c6800572665a9.js\\\\\",\\\\\"3474\\\\\",\\\\\"static/chunks/3474-b41b675fe285039e.js\\\\\",\\\\\"5262\\\\\",\\\\\"static/chunks/5262-c565f8d56db6f340.js\\\\\",\\\\\"5300\\\\\",\\\\\"static/chunks/app/forum/page-e528e5f0f4f935b7.js\\\\\"\\],\\\\\"default\\\\\"\\]\\\\n16:I\\[73775,\\[\\\\\"4935\\\\\",\\\\\"static/chunks/e37a0b60-86dcf540460bd9a6.js\\\\\",\\\\\"6874\\\\\",\\\\\"static/chunks/6874-b5228efe8b8455fa.js\\\\\",\\\\\"3697\\\\\",\\\\\"static/chunks/3697-c0092b2c69fd8d8c.js\\\\\",\\\\\"1141\\\\\",\\\\\"static/chunks/1141-fb44a30f239c6063.js\\\\\",\\\\\"4540\\\\\",\\\\\"static/chunks/4540-d4d9759f532dbe01.js\\\\\",\\\\\"6846\\\\\",\\\\\"static/chunks/6846-e00ebe4cf4673031.js\\\\\",\\\\\"1592\\\\\",\\\\\"static/chunks/1592-be14089f9df98c98.js\\\\\",\\\\\"6325\\\\\",\\\\\"static/chunks/6325-93a1b42c84bba41c.js\\\\\",\\\\\"9032\\\\\",\\\\\"static/chunks/9032-c4156b261f2c50b7.js\\\\\",\\\\\"6504\\\\\",\\\\\"static/chunks/6504-00ef5b949820536b.js\\\\\",\\\\\"3882\\\\\",\\\\\"static/chunks/3882-68311d71c6e6d2c2.js\\\\\",\\\\\"9433\\\\\",\\\\\"static/chunks/9433-2895bfe8ab854f41.js\\\\\",\\\\\"2882\\\\\",\\\\\"static/chunks/2882-44eb1c7e8844e014.js\\\\\",\\\\\"4745\\\\\",\\\\\"static/chunks/4745-b7bef6bfd1f2ca78.js\\\\\",\\\\\"1399\\\\\",\\\\\"static/chunks/1399-1fff5e65c29b20ed.js\\\\\",\\\\\"4757\\\\\",\\\\\"static/chunks/4757-809c6800572665a9.js\\\\\",\\\\\"3474\\\\\",\\\\\"static/chunks/3474-b41b675fe285039e.js\\\\\",\\\\\"5262\\\\\",\\\\\"static/chunks/5262-c565f8d56db6f340.js\\\\\",\\\\\"5300\\\\\",\\\\\"static/chunks/app/forum/page-e528e5f0f4f935b7.js\\\\\"\\],\\\\\"default\\\\\"\\]\\\\n17:T53f,Mathematical reasoning is a challenging task for large language models (LLMs), while the scaling relationship of it with respect to LLM capa\"\\])self.\\_\\_next\\_f.push(\\[1,\"city is under-explored.\\\\nIn this paper, we investigate how the pre-training loss, supervised data amount, and augmented data amount influence the reasoning performances of a supervised LLM.\\\\nWe find that pre-training loss is a better indicator of the model's performance than the model's parameter count.\\\\nWe apply supervised fine-tuning (SFT) with different amounts of supervised data and empirically find a log-linear relation between data amount and model performance, and we find better models improve less with enlarged supervised datasets.\\\\nTo augment more data samples for improving model performances without any human effort, we propose to apply Rejection sampling Fine-Tuning (RFT).\\\\nRFT uses supervised models to generate and collect correct reasoning paths as augmented fine-tuning datasets.\\\\nWe find with augmented samples containing more distinct reasoning paths, RFT improves mathematical reasoning performance more for LLMs.\\\\nWe also find RFT brings more improvement for less performant LLMs.\\\\nFurthermore, we combine rejection samples from multiple models which push LLaMA-7B to an accuracy of 49.3\\\\\\\\% on GSM8K which outperforms the supervised fine-tuning (SFT) accuracy of 35.9\\\\\\\\% significantly.\"\\])self.\\_\\_next\\_f.push(\\[1,\"c:\\[\\[\\\\\"$\\\\\",\\\\\"$L15\\\\\",null,{\\\\\"banner\\\\\":\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"id\\\\\":\\\\\"or-banner\\\\\",\\\\\"className\\\\\":\\\\\"banner\\\\\",\\\\\"style\\\\\":null,\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"container\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"row\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"col-xs-12\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"/group?id=ICLR.cc/2024/Conference\\\\\",\\\\\"title\\\\\":\\\\\"Venue Homepage\\\\\",\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"img\\\\\",null,{\\\\\"className\\\\\":\\\\\"icon\\\\\",\\\\\"src\\\\\":\\\\\"/images/arrow\\_left.svg\\\\\",\\\\\"alt\\\\\":\\\\\"back arrow\\\\\"}\\],\\\\\"Go to \\\\\",\\[\\\\\"$\\\\\",\\\\\"strong\\\\\",null,{\\\\\"children\\\\\":\\\\\"ICLR 2024 Conference\\\\\"}\\],\\\\\" \\\\\",\\\\\"homepage\\\\\"\\]}\\]}\\]}\\]}\\]}\\]}\\],\\\\\"$undefined\\\\\",\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"container\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"row\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"main\\\\\",null,{\\\\\"id\\\\\":\\\\\"content\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"Forum\\_forum\\_\\_wS8Fw\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L16\\\\\",null,{\\\\\"forumNote\\\\\":{\\\\\"content\\\\\":{\\\\\"title\\\\\":{\\\\\"value\\\\\":\\\\\"Scaling Relationship on Learning Mathematical Reasoning with Large Language Models\\\\\"},\\\\\"authors\\\\\":{\\\\\"value\\\\\":\\[\\\\\"Zheng Yuan\\\\\",\\\\\"Hongyi Yuan\\\\\",\\\\\"Chengpeng Li\\\\\",\\\\\"Guanting Dong\\\\\",\\\\\"Keming Lu\\\\\",\\\\\"Chuanqi Tan\\\\\",\\\\\"Chang Zhou\\\\\",\\\\\"Jingren Zhou\\\\\"\\]},\\\\\"authorids\\\\\":{\\\\\"value\\\\\":\\[\\\\\"~Zheng\\_Yuan2\\\\\",\\\\\"~Hongyi\\_Yuan1\\\\\",\\\\\"~Chengpeng\\_Li1\\\\\",\\\\\"~Guanting\\_Dong1\\\\\",\\\\\"~Keming\\_Lu1\\\\\",\\\\\"~Chuanqi\\_Tan3\\\\\",\\\\\"~Chang\\_Zhou2\\\\\",\\\\\"~Jingren\\_Zhou1\\\\\"\\]},\\\\\"keywords\\\\\":{\\\\\"value\\\\\":\\[\\\\\"Mathematical Reasoning\\\\\",\\\\\"Scaling Relationship\\\\\",\\\\\"Large Language Model\\\\\"\\]},\\\\\"abstract\\\\\":{\\\\\"value\\\\\":\\\\\"$17\\\\\"},\\\\\"pdf\\\\\":{\\\\\"value\\\\\":\\\\\"/pdf/a27e58f230a48ebbb5a9ba53a5855f572e91782b.pdf\\\\\"},\\\\\"primary\\_area\\\\\":{\\\\\"value\\\\\":\\\\\"representation learning for computer vision, audio, language, and other modalities\\\\\"},\\\\\"code\\_of\\_ethics\\\\\":{\\\\\"value\\\\\":\\\\\"I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.\\\\\"},\\\\\"submission\\_guidelines\\\\\":{\\\\\"value\\\\\":\\\\\"I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.\\\\\"},\\\\\"anonymous\\_url\\\\\":{\\\\\"value\\\\\":\\\\\"I certify that there is no URL (e.g., github page) that could be used to find authors' identity.\\\\\"},\\\\\"no\\_acknowledgement\\_section\\\\\":{\\\\\"value\\\\\":\\\\\"I certify that there is no acknowledgement section in this submission for double blind review.\\\\\"},\\\\\"venue\\\\\":{\\\\\"value\\\\\":\\\\\"Submitted to ICLR 2024\\\\\"},\\\\\"venueid\\\\\":{\\\\\"value\\\\\":\\\\\"ICLR.cc/2024/Conference/Rejected\\_Submission\\\\\"},\\\\\"supplementary\\_material\\\\\":{\\\\\"value\\\\\":\\\\\"/attachment/35f51711060e734769499f82128aed9e3e41d355.zip\\\\\"},\\\\\"\\_bibtex\\\\\":{\\\\\"value\\\\\":\\\\\"@misc{\\\\\\\\nyuan2024scaling,\\\\\\\\ntitle={Scaling Relationship on Learning Mathematical Reasoning with Large Language Models},\\\\\\\\nauthor={Zheng Yuan and Hongyi Yuan and Chengpeng Li and Guanting Dong and Keming Lu and Chuanqi Tan and Chang Zhou and Jingren Zhou},\\\\\\\\nyear={2024},\\\\\\\\nurl={https://openreview.net/forum?id=cijO0f8u35}\\\\\\\\n}\\\\\"},\\\\\"paperhash\\\\\":{\\\\\"value\\\\\":\\\\\"yuan|scaling\\_relationship\\_on\\_learning\\_mathematical\\_reasoning\\_with\\_large\\_language\\_models\\\\\"}},\\\\\"id\\\\\":\\\\\"cijO0f8u35\\\\\",\\\\\"forum\\\\\":\\\\\"cijO0f8u35\\\\\",\\\\\"number\\\\\":1254,\\\\\"cdate\\\\\":1695029839074,\\\\\"tcdate\\\\\":1695029839074,\\\\\"mdate\\\\\":1707625668604,\\\\\"tmdate\\\\\":1707625668604,\\\\\"signatures\\\\\":\\[\\\\\"ICLR.cc/2024/Conference/Submission1254/Authors\\\\\"\\],\\\\\"readers\\\\\":\\[\\\\\"everyone\\\\\"\\],\\\\\"writers\\\\\":\\[\\\\\"ICLR.cc/2024/Conference\\\\\",\\\\\"ICLR.cc/2024/Conference/Submission1254/Authors\\\\\"\\],\\\\\"odate\\\\\":1697213872796,\\\\\"invitations\\\\\":\\[\\\\\"ICLR.cc/2024/Conference/-/Submission\\\\\",\\\\\"ICLR.cc/2024/Conference/-/Post\\_Submission\\\\\",\\\\\"ICLR.cc/2024/Conference/Submission1254/-/Revision\\\\\",\\\\\"ICLR.cc/2024/Conference/Submission1254/-/Rebuttal\\_Revision\\\\\",\\\\\"ICLR.cc/2024/Conference/-/Edit\\\\\"\\],\\\\\"domain\\\\\":\\\\\"ICLR.cc/2024/Conference\\\\\",\\\\\"version\\\\\":2,\\\\\"details\\\\\":{\\\\\"writable\\\\\":false,\\\\\"presentation\\\\\":\\[{\\\\\"name\\\\\":\\\\\"title\\\\\",\\\\\"order\\\\\":1,\\\\\"type\\\\\":\\\\\"string\\\\\"},{\\\\\"name\\\\\":\\\\\"primary\\_area\\\\\",\\\\\"order\\\\\":2,\\\\\"type\\\\\":\\\\\"string\\\\\",\\\\\"input\\\\\":\\\\\"select\\\\\",\\\\\"value\\\\\":\\\\\"representation learning for computer vision, audio, language, and other modalities\\\\\",\\\\\"description\\\\\":null},{\\\\\"name\\\\\":\\\\\"authors\\\\\",\\\\\"order\\\\\":3},{\\\\\"name\\\\\":\\\\\"code\\_of\\_ethics\\\\\",\\\\\"order\\\\\":3,\\\\\"type\\\\\":\\\\\"string\\\\\",\\\\\"input\\\\\":\\\\\"checkbox\\\\\",\\\\\"value\\\\\":\\\\\"I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.\\\\\",\\\\\"description\\\\\":null},{\\\\\"name\\\\\":\\\\\"authorids\\\\\",\\\\\"order\\\\\":4},{\\\\\"name\\\\\":\\\\\"keywords\\\\\",\\\\\"order\\\\\":4,\\\\\"type\\\\\":\\\\\"string\\[\\]\\\\\"},{\\\\\"name\\\\\":\\\\\"submission\\_guidelines\\\\\",\\\\\"order\\\\\":4,\\\\\"type\\\\\":\\\\\"string\\\\\",\\\\\"input\\\\\":\\\\\"checkbox\\\\\",\\\\\"value\\\\\":\\\\\"I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.\\\\\",\\\\\"description\\\\\":null},{\\\\\"name\\\\\":\\\\\"TLDR\\\\\",\\\\\"order\\\\\":5,\\\\\"type\\\\\":\\\\\"string\\\\\",\\\\\"fieldName\\\\\":\\\\\"TL;DR\\\\\"},{\\\\\"name\\\\\":\\\\\"resubmission\\\\\",\\\\\"order\\\\\":5,\\\\\"type\\\\\":\\\\\"string\\\\\",\\\\\"input\\\\\":\\\\\"radio\\\\\"},{\\\\\"name\\\\\":\\\\\"abstract\\\\\",\\\\\"order\\\\\":6,\\\\\"type\\\\\":\\\\\"string\\\\\",\\\\\"input\\\\\":\\\\\"textarea\\\\\",\\\\\"markdown\\\\\":true},{\\\\\"name\\\\\":\\\\\"student\\_author\\\\\",\\\\\"order\\\\\":6,\\\\\"type\\\\\":\\\\\"string\\\\\",\\\\\"input\\\\\":\\\\\"radio\\\\\"},{\\\\\"name\\\\\":\\\\\"pdf\\\\\",\\\\\"order\\\\\":7,\\\\\"type\\\\\":\\\\\"file\\\\\"},{\\\\\"name\\\\\":\\\\\"anonymous\\_url\\\\\",\\\\\"order\\\\\":7,\\\\\"type\\\\\":\\\\\"string\\\\\",\\\\\"input\\\\\":\\\\\"checkbox\\\\\",\\\\\"value\\\\\":\\\\\"I certify that there is no URL (e.g., github page) that could be used to find authors' identity.\\\\\",\\\\\"description\\\\\":null},{\\\\\"name\\\\\":\\\\\"supplementary\\_material\\\\\",\\\\\"order\\\\\":8,\\\\\"type\\\\\":\\\\\"file\\\\\"},{\\\\\"name\\\\\":\\\\\"no\\_acknowledgement\\_section\\\\\",\\\\\"order\\\\\":8,\\\\\"type\\\\\":\\\\\"string\\\\\",\\\\\"input\\\\\":\\\\\"checkbox\\\\\",\\\\\"value\\\\\":\\\\\"I certify that there is no acknowledgement section in this submission for double blind review.\\\\\",\\\\\"description\\\\\":null},{\\\\\"name\\\\\":\\\\\"large\\_language\\_models\\\\\",\\\\\"order\\\\\":9,\\\\\"type\\\\\":\\\\\"string\\[\\]\\\\\",\\\\\"input\\\\\":\\\\\"checkbox\\\\\"},{\\\\\"name\\\\\":\\\\\"other\\_comments\\_on\\_LLMs\\\\\",\\\\\"order\\\\\":10,\\\\\"type\\\\\":\\\\\"string\\\\\",\\\\\"input\\\\\":\\\\\"textarea\\\\\"},{\\\\\"name\\\\\":\\\\\"venue\\\\\",\\\\\"hidden\\\\\":true},{\\\\\"name\\\\\":\\\\\"venueid\\\\\",\\\\\"hidden\\\\\":true},{\\\\\"name\\\\\":\\\\\"\\_bibtex\\\\\",\\\\\"type\\\\\":\\\\\"string\\\\\",\\\\\"input\\\\\":\\\\\"textarea\\\\\"},{\\\\\"name\\\\\":\\\\\"other\\_comments\\\\\"}\\]},\\\\\"apiVersion\\\\\":2},\\\\\"selectedNoteId\\\\\":\\\\\"$undefined\\\\\",\\\\\"selectedInvitationId\\\\\":\\\\\"$undefined\\\\\",\\\\\"prefilledValues\\\\\":{},\\\\\"query\\\\\":{\\\\\"id\\\\\":\\\\\"cijO0f8u35\\\\\"}}\\]}\\]}\\]}\\]}\\],\\[\\[\\\\\"$\\\\\",\\\\\"footer\\\\\",null,{\\\\\"className\\\\\":\\\\\"sitemap\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"container\\\\\",\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"row hidden-xs\\\\\",\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"col-sm-4\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"ul\\\\\",null,{\\\\\"className\\\\\":\\\\\"list-unstyled\\\\\",\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"/about\\\\\",\\\\\"children\\\\\":\\\\\"About OpenReview\\\\\"}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"/group?id=OpenReview.net/Support\\\\\",\\\\\"children\\\\\":\\\\\"Hosting a Venue\\\\\"}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"/venues\\\\\",\\\\\"children\\\\\":\\\\\"All Venues\\\\\"}\\]}\\]\\]}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"col-sm-4\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"ul\\\\\",null,{\\\\\"className\\\\\":\\\\\"list-unstyled\\\\\",\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"/contact\\\\\",\\\\\"children\\\\\":\\\\\"Contact\\\\\"}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"/sponsors\\\\\",\\\\\"children\\\\\":\\\\\"Sponsors\\\\\"}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"https://donate.stripe.com/eVqdR8fP48bK1R61fi0oM00\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"strong\\\\\",null,{\\\\\"children\\\\\":\\\\\"Donate\\\\\"}\\]}\\]}\\]\\]}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"col-sm-4\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"ul\\\\\",null,{\\\\\"className\\\\\":\\\\\"list-unstyled\\\\\",\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"a\\\\\",null,{\\\\\"href\\\\\":\\\\\"https://docs.openreview.net/getting-started/frequently-asked-questions\\\\\",\\\\\"children\\\\\":\\\\\"Frequently Asked Questions\\\\\"}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"/legal/terms\\\\\",\\\\\"children\\\\\":\\\\\"Terms of Use\\\\\"}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"/legal/privacy\\\\\",\\\\\"children\\\\\":\\\\\"Privacy Policy\\\\\"}\\]}\\]\\]}\\]}\\]\\]}\\],\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"row visible-xs-block\\\\\",\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"col-xs-6\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"ul\\\\\",null,{\\\\\"className\\\\\":\\\\\"list-unstyled\\\\\",\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"/about\\\\\",\\\\\"children\\\\\":\\\\\"About OpenReview\\\\\"}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"/group?id=OpenReview.net/Support\\\\\",\\\\\"children\\\\\":\\\\\"Hosting a Venue\\\\\"}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"/venues\\\\\",\\\\\"children\\\\\":\\\\\"All Venues\\\\\"}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"/sponsors\\\\\",\\\\\"children\\\\\":\\\\\"Sponsors\\\\\"}\\]}\\]\\]}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"col-xs-6\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"ul\\\\\",null,{\\\\\"className\\\\\":\\\\\"list-unstyled\\\\\",\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"a\\\\\",null,{\\\\\"href\\\\\":\\\\\"https://docs.openreview.net/getting-started/frequently-asked-questions\\\\\",\\\\\"children\\\\\":\\\\\"Frequently Asked Questions\\\\\"}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"/contact\\\\\",\\\\\"children\\\\\":\\\\\"Contact\\\\\"}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"https://donate.stripe.com/eVqdR8fP48bK1R61fi0oM00\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"strong\\\\\",null,{\\\\\"children\\\\\":\\\\\"Donate\\\\\"}\\]}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"/legal/terms\\\\\",\\\\\"children\\\\\":\\\\\"Terms of Use\\\\\"}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"li\\\\\",null,{\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"$L3\\\\\",null,{\\\\\"href\\\\\":\\\\\"/legal/privacy\\\\\",\\\\\"children\\\\\":\\\\\"Privacy Policy\\\\\"}\\]}\\]\\]}\\]}\\]\\]}\\]\\]}\\]}\\],\\[\\\\\"$\\\\\",\\\\\"footer\\\\\",null,{\\\\\"className\\\\\":\\\\\"sponsor\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"container\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"row\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"div\\\\\",null,{\\\\\"className\\\\\":\\\\\"col-sm-10 col-sm-offset-1\\\\\",\\\\\"children\\\\\":\\[\\\\\"$\\\\\",\\\\\"p\\\\\",null,{\\\\\"className\\\\\":\\\\\"text-center\\\\\",\\\\\"children\\\\\":\\[\\[\\\\\"$\\\\\",\\\\\"a\\\\\",null,{\\\\\"href\\\\\":\\\\\"/about\\\\\",\\\\\"target\\\\\":\\\\\"\\_blank\\\\\",\\\\\"children\\\\\":\\\\\"OpenReview\\\\\"}\\],\\\\\" \\\\\",\\\\\"is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the\\\\\",\\\\\" \\\\\",\\[\\\\\"$\\\\\",\\\\\"a\\\\\",null,{\\\\\"href\\\\\":\\\\\"/sponsors\\\\\",\\\\\"target\\\\\":\\\\\"\\_blank\\\\\",\\\\\"children\\\\\":\\\\\"OpenReview Sponsors\\\\\"}\\],\\\\\". \u00a9 \\\\\",2025,\\\\\" OpenReview\\\\\"\\]}\\]}\\]}\\]}\\]}\\]\\]\\]\\\\n\"\\])self.\\_\\_next\\_f.push(\\[1,\"f:null\\\\n18:T53f,Mathematical reasoning is a challenging task for large language models (LLMs), while the scaling relationship of it with respect to LLM capacity is under-explored.\\\\nIn this paper, we investigate how the pre-training loss, supervised data amount, and augmented data amount influence the reasoning performances of a supervised LLM.\\\\nWe find that pre-training loss is a better indicator of the model's performance than the model's parameter count.\\\\nWe apply supervised fine-tuning (SFT) with different amounts of supervised data and empirically find a log-linear relation between data amount and model performance, and we find better models improve less with enlarged supervised datasets.\\\\nTo augment more data samples for improving model performances without any human effort, we propose to apply Rejection sampling Fine-Tuning (RFT).\\\\nRFT uses supervised models to generate and collect correct reasoning paths as augmented fine-tuning datasets.\\\\nWe find with augmented samples containing more distinct reasoning paths, RFT improves mathematical reasoning performance more for LLMs.\\\\nWe also find RFT brings more improvement for less performant LLMs.\\\\nFurthermore, we combine rejection samples from multiple models which push LLaMA-7B to an accuracy of 49.3\\\\\\\\% on GSM8K which outperforms the supervised fine-tuning (SFT) accuracy of 35.9\\\\\\\\% significantly.19:T53f,Mathematical reasoning is a challenging task for large language models (LLMs), while the scaling relationship of it with respect to LLM capacity is under-explored.\\\\nIn this paper, we investigate how the pre-training loss, supervised data amount, and augmented data amount influence the reasoning performances of a supervised LLM.\\\\nWe find that pre-training loss is a better indicator of the model's performance than the model's parameter count.\\\\nWe apply supervised fine-tuning (SFT) with different amounts of supervised data and empirically find a log-linear relation between data amount and model performance, and we find better models improve less with enlarged supervised datasets.\"\\])self.\\_\\_next\\_f.push(\\[1,\"\\\\nTo augment more data samples for improving model performances without any human effort, we propose to apply Rejection sampling Fine-Tuning (RFT).\\\\nRFT uses supervised models to generate and collect correct reasoning paths as augmented fine-tuning datasets.\\\\nWe find with augmented samples containing more distinct reasoning paths, RFT improves mathematical reasoning performance more for LLMs.\\\\nWe also find RFT brings more improvement for less performant LLMs.\\\\nFurthermore, we combine rejection samples from multiple models which push LLaMA-7B to an accuracy of 49.3\\\\\\\\% on GSM8K which outperforms the supervised fine-tuning (SFT) accuracy of 35.9\\\\\\\\% significantly.13:\\[\\[\\\\\"$\\\\\",\\\\\"title\\\\\",\\\\\"0\\\\\",{\\\\\"children\\\\\":\\\\\"Scaling Relationship on Learning Mathematical Reasoning with Large Language Models | OpenReview\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"1\\\\\",{\\\\\"name\\\\\":\\\\\"description\\\\\",\\\\\"content\\\\\":\\\\\"$18\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"2\\\\\",{\\\\\"name\\\\\":\\\\\"citation\\_title\\\\\",\\\\\"content\\\\\":\\\\\"Scaling Relationship on Learning Mathematical Reasoning with Large Language Models\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"3\\\\\",{\\\\\"name\\\\\":\\\\\"citation\\_author\\\\\",\\\\\"content\\\\\":\\\\\"Zheng Yuan\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"4\\\\\",{\\\\\"name\\\\\":\\\\\"citation\\_author\\\\\",\\\\\"content\\\\\":\\\\\"Hongyi Yuan\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"5\\\\\",{\\\\\"name\\\\\":\\\\\"citation\\_author\\\\\",\\\\\"content\\\\\":\\\\\"Chengpeng Li\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"6\\\\\",{\\\\\"name\\\\\":\\\\\"citation\\_author\\\\\",\\\\\"content\\\\\":\\\\\"Guanting Dong\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"7\\\\\",{\\\\\"name\\\\\":\\\\\"citation\\_author\\\\\",\\\\\"content\\\\\":\\\\\"Keming Lu\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"8\\\\\",{\\\\\"name\\\\\":\\\\\"citation\\_author\\\\\",\\\\\"content\\\\\":\\\\\"Chuanqi Tan\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"9\\\\\",{\\\\\"name\\\\\":\\\\\"citation\\_author\\\\\",\\\\\"content\\\\\":\\\\\"Chang Zhou\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"10\\\\\",{\\\\\"name\\\\\":\\\\\"citation\\_author\\\\\",\\\\\"content\\\\\":\\\\\"Jingren Zhou\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"11\\\\\",{\\\\\"name\\\\\":\\\\\"citation\\_online\\_date\\\\\",\\\\\"content\\\\\":\\\\\"2023/10/13\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"12\\\\\",{\\\\\"name\\\\\":\\\\\"citation\\_pdf\\_url\\\\\",\\\\\"content\\\\\":\\\\\"https://openreview.net/pdf?id=cijO0f8u35\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"13\\\\\",{\\\\\"name\\\\\":\\\\\"citation\\_abstract\\\\\",\\\\\"content\\\\\":\\\\\"$19\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"14\\\\\",{\\\\\"property\\\\\":\\\\\"og:title\\\\\",\\\\\"content\\\\\":\\\\\"Scaling Relationship on Learning Mathematical Reasoning with Large...\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"15\\\\\",{\\\\\"property\\\\\":\\\\\"og:description\\\\\",\\\\\"content\\\\\":\\\\\"Mathematical reasoning is a challenging task for large language models (LLMs), while the scaling re\"\\])self.\\_\\_next\\_f.push(\\[1,\"lationship of it with respect to LLM capacity is under-explored.\\\\\\\\nIn this paper, we investigate how...\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"16\\\\\",{\\\\\"property\\\\\":\\\\\"og:type\\\\\",\\\\\"content\\\\\":\\\\\"article\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"17\\\\\",{\\\\\"name\\\\\":\\\\\"twitter:card\\\\\",\\\\\"content\\\\\":\\\\\"summary\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"18\\\\\",{\\\\\"name\\\\\":\\\\\"twitter:title\\\\\",\\\\\"content\\\\\":\\\\\"Scaling Relationship on Learning Mathematical Reasoning with Large...\\\\\"}\\],\\[\\\\\"$\\\\\",\\\\\"meta\\\\\",\\\\\"19\\\\\",{\\\\\"name\\\\\":\\\\\"twitter:description\\\\\",\\\\\"content\\\\\":\\\\\"Mathematical reasoning is a challenging task for large language models (LLMs), while the scaling relationship of it with respect to LLM capacity is under-explored.\\\\\\\\nIn this paper, we investigate how...\\\\\"}\\]\\]\\\\n\"\\])"}], "is_error": false, "tool_name": "fetch_fetch_markdown"}, "action_id": "c9f1ae4d-fa72-453a-915c-ea94b18baf1e"}